{"meta":{"title":"VIP","subtitle":null,"description":null,"author":"Mr.Zhuo","url":"https://www.ice5.vip"},"pages":[{"title":"categories","date":"2018-12-01T16:00:19.000Z","updated":"2018-12-01T16:00:19.830Z","comments":true,"path":"categories/index.html","permalink":"https://www.ice5.vip/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"并发编程之生产者消费者模型","slug":"并发编程之生产者消费者模型","date":"2018-12-05T14:00:55.460Z","updated":"2018-12-07T16:45:29.213Z","comments":true,"path":"/并发编程之生产者消费者模型/","link":"","permalink":"https://www.ice5.vip/并发编程之生产者消费者模型/","excerpt":"生产者消费者模式就是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。这个阻塞队列就是用来给生产者和消费者解耦的。","text":"生产者消费者模式就是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。这个阻塞队列就是用来给生产者和消费者解耦的。 一、使用生产者消费者模式的原因在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这种生产消费能力不均衡的问题，于是引入了生产者和消费者模式 二、生产者/消费者模型的优点 解耦，即降低生产者和消费者之间的依赖关系。 例如平常生活中寄信的例子，如果我们不适用邮筒（也就是缓区），于是我们就必须得把信直接交给邮递员。大概有的人会说，直接给邮递员这不是挺简单的嘛？其实不然，首先你得认识邮递员，其次该邮递员的身份是真实的吗？这就产生了你和邮递员之间的依赖（相当于生产者和消费者的强耦合）。万一某天邮递员换人了，你还要重新认识一下（相当于消费者变化导致修改生产者代码）。而邮筒相对来说比较固定，你依赖它的成本就比较低（相当于和缓冲区之间的弱耦合）。 支持并发，即生产者和消费者可以是两个独立的并发主体，互不干扰的运行。 从寄信的例子来看。如果没有邮筒，你得拿着信傻站在路口等邮递员过来收（相当于生产者阻塞）；又或者邮递员得挨家挨户问，谁要寄信（相当于消费者轮询）。不管是哪种方法，效率都比较低。 支持忙闲不均，如果制造数据的速度时快时慢，缓冲区可以对其进行适当缓冲。当数据制造快的时候，消费者来不及处理，未处理的数据可以暂时存在缓冲区中。等生产者的制造速度慢下来，消费者再慢慢处理掉。 假设邮递员一次只能带走1000封信。万一某次碰上情人节（也可能是圣诞节）送贺卡，需要寄出去的信超过1000封，这时候邮筒这个缓冲区就派上用场了。邮递员把来不及带走的信暂存在邮筒中，等下次过来时再拿走。 三、基于队列实现生产者消费者模型123456789101112131415161718192021222324252627from multiprocessing import Process,Queueimport time,random,osdef consumer(q): while True: res=q.get() time.sleep(random.randint(1,3)) print('\\033[45m%s 吃 %s\\033[0m' %(os.getpid(),res))def producer(q): for i in range(10): time.sleep(random.randint(1,3)) res='包子%s' %i q.put(res) print('\\033[44m%s 生产了 %s\\033[0m' %(os.getpid(),res))if __name__ == '__main__': q=Queue() #生产者们:即厨师们 p1=Process(target=producer,args=(q,)) #消费者们:即吃货们 c1=Process(target=consumer,args=(q,)) #开始 p1.start() c1.start() print('主') 1.生产者消费者模型总结 程序中有两类角色 一类负责生产数据（生产者） 一类负责处理数据（消费者） 引入生产者消费者模型为了解决的问题是 平衡生产者与消费者之间的工作能力，从而提高程序整体处理数据的速度 如何实现 生产者队列(缓冲区)&lt;——&gt;消费者 2.此时遇到的问题 主进程永远不会结束，原因是：生产者p在生产完后就结束了，但是消费者c在取空了q之后，则一直处于死循环中且卡在q.get()这一步。 解决方式无非是让生产者在生产完毕后，往队列中再发一个结束信号，这样消费者在接收到结束信号后就可以break出死循环。 注意：结束信号None，不一定要由生产者发，主进程里同样可以发，但主进程需要等生产者结束后才应该发送该信号 。 123456789101112131415161718192021222324252627282930313233from multiprocessing import Process,Queueimport time,random,osdef consumer(q): while True: res=q.get() if res is None:break #收到结束信号则结束 time.sleep(random.randint(1,3)) print('\\033[45m%s 吃 %s\\033[0m' %(os.getpid(),res))def producer(q): for i in range(2): time.sleep(random.randint(1,3)) res='包子%s' %i q.put(res) print('\\033[44m%s 生产了 %s\\033[0m' %(os.getpid(),res)) # 生产者发送结束信号 # q.put(None) #发送结束信号if __name__ == '__main__': q=Queue() #生产者们:即厨师们 p1=Process(target=producer,args=(q,)) #消费者们:即吃货们 c1=Process(target=consumer,args=(q,)) #开始 p1.start() c1.start() p1.join() q.put(None) #发送结束信号 print('主') 3.多个生产者和多个消费者 有几个消费者就需要发送几次结束信号：这种方式非常的low。 其实我们的思路无非是发送结束信号而已，有另外一种队列提供了这种机制 JoinableQueue([maxsize])：这就像是一个Queue对象，但队列允许项目的使用者通知生成者项目已经被成功处理。通知进程是使用共享的信号和条件变量来实现的。 参数介绍 maxsize是队列中允许最大项数，省略则无大小限制。 方法介绍 JoinableQueue的实例p除了与Queue对象相同的方法之外还具有： q.task_done()：使用者使用此方法发出信号，表示q.get()的返回项目已经被处理。如果调用此方法的次数大于从队列中删除项目的数量，将引发ValueError异常 q.join():生产者调用此方法进行阻塞，直到队列中所有的项目均被处理。阻塞将持续到队列中的每个项目均调用q.task_done（）方法为止 12345678910111213141516171819202122232425262728293031323334353637383940414243from multiprocessing import Process,JoinableQueueimport time,random,osdef consumer(q): while True: res=q.get() time.sleep(random.randint(1,3)) print('\\033[45m%s 吃 %s\\033[0m' %(os.getpid(),res)) q.task_done() #向q.join()发送一次信号,证明一个数据已经被取走了def producer(name,q): for i in range(10): time.sleep(random.randint(1,3)) res='%s%s' %(name,i) q.put(res) print('\\033[44m%s 生产了 %s\\033[0m' %(os.getpid(),res)) q.join() if __name__ == '__main__': q=JoinableQueue() #生产者们:即厨师们 p1=Process(target=producer,args=('包子',q)) p2=Process(target=producer,args=('骨头',q)) p3=Process(target=producer,args=('泔水',q)) #消费者们:即吃货们 c1=Process(target=consumer,args=(q,)) c2=Process(target=consumer,args=(q,)) c1.daemon=True c2.daemon=True #开始 p_l=[p1,p2,p3,c1,c2] for p in p_l: p.start() p1.join() p2.join() p3.join() print('主') #主进程等---&gt;p1,p2,p3等----&gt;c1,c2 #p1,p2,p3结束了,证明c1,c2肯定全都收完了p1,p2,p3发到队列的数据 #因而c1,c2也没有存在的价值了,应该随着主进程的结束而结束,所以设置成守护进程","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.ice5.vip/categories/并发编程/"}],"tags":[{"name":"Producer-consumer model","slug":"Producer-consumer-model","permalink":"https://www.ice5.vip/tags/Producer-consumer-model/"},{"name":"Message queue","slug":"Message-queue","permalink":"https://www.ice5.vip/tags/Message-queue/"}]},{"title":"并发编程之协程","slug":"并发编程之协程","date":"2018-12-04T21:14:04.066Z","updated":"2018-12-07T16:48:10.145Z","comments":true,"path":"/并发编程之协程/","link":"","permalink":"https://www.ice5.vip/并发编程之协程/","excerpt":"协程的本质就是在单线程下，由用户自己控制一个任务遇到IO阻塞了就切换另外一个任务去执行，以此来提升效率。 为了实现它，我们需要找寻一种可以满足以下条件的解决方案条件的解决方案 。","text":"协程的本质就是在单线程下，由用户自己控制一个任务遇到IO阻塞了就切换另外一个任务去执行，以此来提升效率。 为了实现它，我们需要找寻一种可以满足以下条件的解决方案条件的解决方案 。 可以控制多个任务之间的切换，切换之前将任务的状态保存下来，以便重新运行时，可以基于暂停的位置继续执行。作为上述条件的补充：可以检测IO操作，在遇到IO操作的情况下才发生切换 对于单线程下，我们不可避免程序中出现IO操作，但如果我们能在自己的程序中（即用户程序级别，而非操作系统级别）控制单线程下的多个任务能在一个任务遇到IO阻塞时就切换到另外一个任务去计算，这样就保证了该线程能够最大限度地处于就绪态，即随时都可以被CPU执行的状态，相当于我们在用户程序级别将自己的IO操作最大限度地隐藏起来，从而可以迷惑操作系统，让其看到：该线程好像是一直在计算，IO比较少，从而更多的将CPU的执行权限分配给我们的线程。 一、协程介绍1.协程​ 单线程下的并发，又称微线程，纤程。英文名Coroutine。总的来说：协程是一种用户态的轻量级线程，即协程是由用户程序自己控制调度的。 Python的线程属于内核级别的，即由操作系统控制调度（如单线程遇到IO或执行时间过长就会被迫交出CPU执行权限，切换其他线程运行） 单线程内开启协程，一旦遇到IO，就会从应用程序级别（而非操作系统）控制切换，以此来提升效率（非IO操作的切换与效率无关）。 2.单线程内控制协程的切换的优缺点 和操作系统控制线程的切换对比，用户在单线程内控制协程的切换的优点： 协程的切换开销更小，属于程序级别的切换，操作系统完全感知不到，因而更加轻量级 单线程内就可以实现并发的效果，最大限度地利用CPU 和操作系统控制线程的切换对比，用户在单线程内控制协程的切换的缺点： 协程的本质是单线程下，无法利用多核，可以是一个程序开启多个进程，每个进程内开启多个线程，每个线程内开启协程 协程指的是单个线程，因而一旦协程出现阻塞，将会阻塞整个线程 3.协程的特点 必须在只有一个单线程里实现并发 修改共享数据不需加锁 用户程序里自己保存多个控制流的上下文栈 一个协程遇到IO操作自动切换到其它协程（如何实现检测IO，yield、greenlet都无法实现，就用到了gevent模块（select机制）） 4.Greenlet介绍如果在单个线程内有多个个任务，若要实现在多个任务之间切换，使用yield生成器的方式过于麻烦（需要先得到初始化一次的生成器，然后再调用send。。。非常麻烦），而使用greenlet模块可以非常简单地实现这20个任务直接的切换 。 123456789101112131415161718# pip install greeletfrom greenlet import greenletdef eat(name): print('%s eat 1' %name) g2.switch('Namy') print('%s eat 2' %name) g2.switch()def play(name): print('%s play 1' %name) g1.switch() print('%s play 2' %name)g1=greenlet(eat)g2=greenlet(play)# 可以在第一次switch时传入参数，以后都不需要g1.switch('Luffy') greenlet只是提供了一种比generator更加便捷的切换方式，当切到一个任务执行时如果遇到IO，那就原地阻塞，仍然是没有解决遇到IO自动切换来提升效率的问题。 单线程里的这多个任务的代码通常会既有计算操作又有阻塞操作，我们完全可以在执行任务1时遇到阻塞，就利用阻塞的时间去执行任务2。。。。如此，才能提高效率，这就用到了gevent模块。 5.Gevent介绍 gevent是一个第三方库，可以轻松通过gevent实现并发同步或异步编程，在gevent中用到的主要模式是gevent , 它是以C扩展模块形式接入Python的轻量级协程。 greenlet全部运行在主程序操作系统进程的内部，但它们被协作式地调度。 用法 123456g1=gevent.spawn(func,1,,2,3,x=4,y=5)创建一个协程对象g1，spawn括号内第一个参数是函数名，如eat，后面可以有多个参数，可以是位置实参或关键字实参，都是传给函数eat的g2=gevent.spawn(func2)g1.join() # 等待g1结束g2.join() # 等待g2结束# 或者上述两步合作一步：gevent.joinall([g1,g2])g1.value # 拿到func1的返回值 遇到IO阻塞时会自动切换任务 1234567891011121314151617import geventdef eat(name): print('%s eat 1' %name) gevent.sleep(2) print('%s eat 2' %name)def play(name): print('%s play 1' %name) gevent.sleep(1) print('%s play 2' %name)g1=gevent.spawn(eat,'Luffy')g2=gevent.spawn(play,name='Namy')g1.join()g2.join()# 或者gevent.joinall([g1,g2])print('主') 上例gevent.sleep(2)模拟的是gevent可以识别的IO阻塞,而time.sleep(2)或其他的阻塞,gevent是不能直接识别的需要用下面一行代码,打补丁,就可以识别了。 from gevent import monkey;monkey.patch_all()必须放到被打补丁者的前面，如time，socket模块之前 或者我们干脆记忆成：要用gevent，需要将from gevent import monkey;monkey.patch_all()放到文件的开头。 123456789101112131415161718from gevent import monkey;monkey.patch_all()import geventimport timedef eat(): print('eat food 1') time.sleep(2) print('eat food 2')def play(): print('play 1') time.sleep(1) print('play 2')g1=gevent.spawn(eat)g2=gevent.spawn(play_phone)gevent.joinall([g1,g2])print('主') 我们可以用threading.current_thread().getName()来查看每个g1和g2，查看的结果为DummyThread-n，即假线程。 二、Gevent之同步与异步 改代码中的重要部分是将task函数封装到greenlet内部线程的gevent.spawn。 初始化的greenlet列表存放在数组threads中，此数组被传给gevent.joinall 函数，后者阻塞当前流程，并执行所有给定的greenlet。执行流程只会在 所有greenlet执行完后才会继续向下走。 123456789101112131415161718192021222324from gevent import spawn,joinall,monkey;monkey.patch_all()import timedef task(pid): \"\"\" Some non-deterministic task \"\"\" time.sleep(0.5) print('Task %s done' % pid)def synchronous(): for i in range(10): task(i)def asynchronous(): g_l=[spawn(task,i) for i in range(10)] joinall(g_l)if __name__ == '__main__': print('Synchronous:') synchronous() print('Asynchronous:') asynchronous() 三、 Gevent之应用举例1.爬虫1234567891011121314151617181920from gevent import monkey;monkey.patch_all()import geventimport requestsimport timedef get_page(url): print('GET: %s' %url) response=requests.get(url) if response.status_code == 200: print('%d bytes received from %s' %(len(response.text),url))start_time=time.time()gevent.joinall([ gevent.spawn(get_page,'https://www.ice5.vip/'), gevent.spawn(get_page,'https://www.taobao.com/'), gevent.spawn(get_page,'https://www.jd.com/'),])stop_time=time.time()print('run time is %s' %(stop_time-start_time)) 2.单线程下的socket并发再次提醒：通过gevent实现单线程下的socket并发（from gevent import monkey;monkey.patch_all()一定要放到导入socket模块之前，否则gevent无法识别socket的阻塞） 服务端 1234567891011121314151617181920212223242526272829from gevent import monkey;monkey.patch_all()from socket import *import gevent#如果不想用money.patch_all()打补丁,可以用gevent自带的socket# from gevent import socket# s=socket.socket()def server(server_ip,port): s=socket(AF_INET,SOCK_STREAM) s.setsockopt(SOL_SOCKET,SO_REUSEADDR,1) s.bind((server_ip,port)) s.listen(5) while True: conn,addr=s.accept() gevent.spawn(talk,conn,addr)def talk(conn,addr): try: while True: res=conn.recv(1024) print('client %s:%s msg: %s' %(addr[0],addr[1],res)) conn.send(res.upper()) except Exception as e: print(e) finally: conn.close()if __name__ == '__main__': server('127.0.0.1',8080) 客户端 123456789101112from socket import *client=socket(AF_INET,SOCK_STREAM)client.connect(('127.0.0.1',8080))while True: msg=input('&gt;&gt;: ').strip() if not msg:continue client.send(msg.encode('utf-8')) msg=client.recv(1024) print(msg.decode('utf-8') 多个线程并发客户端 123456789101112131415161718from threading import Threadfrom socket import *import threadingdef client(server_ip,port): c=socket(AF_INET,SOCK_STREAM) #套接字对象一定要加到函数内，即局部名称空间内，放在函数外则被所有线程共享，则大家公用一个套接字对象，那么客户端端口永远一样了 c.connect((server_ip,port)) count=0 while True: c.send(('%s say hello %s' %(threading.current_thread().getName(),count)).encode('utf-8')) msg=c.recv(1024) print(msg.decode('utf-8')) count+=1if __name__ == '__main__': for i in range(500): t=Thread(target=client,args=('127.0.0.1',8080)) t.start()","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.ice5.vip/categories/并发编程/"}],"tags":[{"name":"Association","slug":"Association","permalink":"https://www.ice5.vip/tags/Association/"}]},{"title":"并发编程之 IO模型","slug":"并发编程之IO模型","date":"2018-12-04T21:13:52.125Z","updated":"2018-12-07T16:44:43.368Z","comments":true,"path":"/并发编程之IO模型/","link":"","permalink":"https://www.ice5.vip/并发编程之IO模型/","excerpt":"","text":"","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.ice5.vip/categories/并发编程/"}],"tags":[{"name":"IO Model","slug":"IO-Model","permalink":"https://www.ice5.vip/tags/IO-Model/"}]},{"title":"并发编程之多线程","slug":"并发编程之多线程","date":"2018-12-04T21:13:40.719Z","updated":"2018-12-08T11:57:03.350Z","comments":true,"path":"/并发编程之多线程/","link":"","permalink":"https://www.ice5.vip/并发编程之多线程/","excerpt":"在传统操作系统中，每个进程有一个地址空间，而且默认就有一个控制线程。线程顾名思义，就是一条流水线工作的过程，一条流水线必须属于一个车间，一个车间的工作过程是一个进程。车间负责把资源整合到一起，是一个资源单位，而一个车间内至少有一个流水线。流水线的工作需要电源，电源就相当于CPU。所以，进程只是用来把资源集中到一起（进程只是一个资源单位，或者说资源集合），而线程才是CPU上的执行单位。","text":"在传统操作系统中，每个进程有一个地址空间，而且默认就有一个控制线程。线程顾名思义，就是一条流水线工作的过程，一条流水线必须属于一个车间，一个车间的工作过程是一个进程。车间负责把资源整合到一起，是一个资源单位，而一个车间内至少有一个流水线。流水线的工作需要电源，电源就相当于CPU。所以，进程只是用来把资源集中到一起（进程只是一个资源单位，或者说资源集合），而线程才是CPU上的执行单位。 一、线程的理论基础1.线程的概念 在一个进程中存在多个控制线程，多个控制线程共享该进程的地址空间，相当于一个车间内有多条流水线，都共用一个车间的资源。 2.创建线程的开销 创建进程的开销要远大于线程？ 如果我们的软件是一个工厂，该工厂有多条流水线，流水线工作需要电源，电源只有一个即CPU（单核CPU） 一个车间就是一个进程，一个车间至少一条流水线（一个进程至少一个线程） 创建一个进程，就是创建一个车间（申请空间，在该空间内建至少一条流水线） 而建线程，就只是在一个车间内造一条流水线，无需申请空间，所以创建开销小 进程之间是竞争关系，线程之间是协作关系？ 车间直接是竞争/抢电源的关系，竞争（不同的进程直接是竞争关系，是不同的程序员写的程序运行的，迅雷抢占其他进程的网速，360把其他进程当做病毒干死） 一个车间的不同流水线式协同工作的关系（同一个进程的线程之间是合作关系，是同一个程序写的程序内开启动，迅雷内的线程是合作关系，不会自己干自己） 3.线程与进程的区别 Threads share the address space of the process that created it; processes have their own address space. 创建线程的进程的地址空间在该进程内是共享的；相反的各个进程有自己的地址空间。 Threads have direct access to the data segment of its process; processes have their own copy of the data segment of the parent process. 线程可以直接访问其进程的数据；但是进程有它们自己的父进程的数据的副本。 Threads can directly communicate with other threads of its process; processes must use interprocess communication to communicate with sibling processes. 线程可以直接与自己进程内的其他线程通信；但是不同的进程间必须使用进程间通信来与兄弟进程通信。 New threads are easily created; new processes require duplication of the parent process. 线程的创建很容易；但是创建新的进程赋值父进程。 Threads can exercise considerable control over threads of the same process; processes can only exercise control over child processes. 线程可以对同一个进程内的其他线程进行控制；但是进程只能对子进程执行控制。 Changes to the main thread (cancellation, priority change, etc.) may affect the behavior of the other threads of the process; changes to the parent process does not affect child processes. 主线程的任何变动（取消、优先级更改等）可能会影响到进程内其他线程的行为；父进程的更改不影响子进程。 4.为何要用多线程多线程指的是，在一个进程中开启多个线程，简单的讲：如果多个任务共用一块地址空间，那么必须在一个进程内开启多个线程。详细的讲分为4点： 1. 多线程共享一个进程的地址空间 ​ 2. 线程比进程更轻量级，线程比进程更容易创建可撤销，在许多操作系统中，创建一个线程比创建一个进程要快10-100倍，在有大量线程需要动态和快速修改时，这一特性很有用 ​ 3. 若多个线程都是CPU密集型的，那么并不能获得性能上的增强，但是如果存在大量的计算和大量的I/O处理，拥有多个线程允许这些活动彼此重叠运行，从而会加快程序执行的速度。 ​ 4. 在多CPU系统中，为了最大限度的利用多核，可以开启多个线程，比开进程开销要小的多。（这一条并不适用于Python） 5.多线程的应用举例开启一个字处理软件进程，该进程肯定需要办不止一件事情，比如监听键盘输入，处理文字，定时自动将文字保存到硬盘，这三个任务操作的都是同一块数据，因而不能用多进程。只能在一个进程里并发地开启三个线程,如果是单线程，那就只能是，键盘输入时，不能处理文字和自动保存，自动保存时又不能输入和处理文字。 以下知识了解即可 6. 经典的线程模型多个线程共享同一个进程的地址空间中的资源，是对一台计算机上多个进程的模拟，有时也称线程为轻量级的进程，而对一台计算机上多个进程，则共享物理内存、磁盘、打印机等其他物理资源。多线程的运行也多进程的运行类似，是cpu在多个线程之间的快速切换。 不同的进程之间是充满敌意的，彼此是抢占、竞争CPU的关系，如果迅雷会和QQ抢资源。而同一个进程是由一个程序员的程序创建，所以同一进程内的线程是合作关系，一个线程可以访问另外一个线程的内存地址，大家都是共享的，一个线程干死了另外一个线程的内存，那纯属程序员脑子有问题。 不同于进程，线程库无法利用时钟中断强制线程让出CPU，可以调用thread_yield运行线程自动放弃cpu，让另外一个线程运行。 线程通常是有益的，但是带来了不小程序设计难度，线程的问题是： 1. 父进程有多个线程，那么开启的子线程是否需要同样多的线程 如果是，那么附近中某个线程被阻塞，那么copy到子进程后，copy版的线程也要被阻塞吗，想一想nginx的多线程模式接收用户连接。 2. 在同一个进程中，如果一个线程关闭了问题，而另外一个线程正准备往该文件内写内容呢？ ​ 如果一个线程注意到没有内存了，并开始分配更多的内存，在工作一半时，发生线程切换，新的线程也发现内存不够用了，又开始分配更多的内存，这样内存就被分配了多次，这些问题都是多线程编程的典型问题，需要仔细思考和设计。 7. POSIX线程 为了实现可移植的线程程序,IEEE在IEEE标准1003.1c中定义了线程标准，它定义的线程包叫Pthread。大部分UNIX系统都支持该标准，简单介绍如下 8.在用户空间实现的线程线程的实现可以分为两类：用户级线程(User-Level Thread)和内核线线程(Kernel-Level Thread)，后者又称为内核支持的线程或轻量级进程。在多线程操作系统中，各个系统的实现方式并不相同，在有的系统中实现了用户级线程，有的系统中实现了内核级线程。 ​ 用户级线程内核的切换由用户态程序自己控制内核切换,不需要内核干涉，少了进出内核态的消耗，但不能很好的利用多核CPU,目前Linux pthread大体是这么做的。 ​ 在用户空间模拟操作系统对进程的调度，来调用一个进程中的线程，每个进程中都会有一个运行时系统，用来调度线程。此时当该进程获取CPU时，进程内再调度出一个线程去执行，同一时刻只有一个线程执行。 9.在内核空间实现的线程 内核级线程:切换由内核控制，当线程进行切换的时候，由用户态转化为内核态。切换完毕要从内核态返回用户态；可以很好的利用smp，即利用多核CPI。windows线程就是这样的。 10.用户级与内核级线程的对比 一： 以下是用户级线程和内核级线程的区别： 内核支持线程是OS内核可感知的，而用户级线程是OS内核不可感知的。 用户级线程的创建、撤消和调度不需要OS内核的支持，是在语言（如Java）这一级处理的；而内核支持线程的创建、撤消和调度都需OS内核提供支持，而且与进程的创建、撤消和调度大体是相同的。 用户级线程执行系统调用指令时将导致其所属进程被中断，而内核支持线程执行系统调用指令时，只导致该线程被中断。 在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，由用户程序控制线程的轮换运行；在有内核支持线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度。 用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序。 ​ 二： 内核线程的优缺点 优点： 当有多个处理机时，一个进程的多个线程可以同时执行。 缺点： 由内核进行调度。 ​ 三： 用户进程的优缺点 优点： 线程的调度不需要内核直接参与，控制简单。 可以在不支持线程的操作系统中实现。 创建和销毁线程、线程切换代价等线程管理的代价比内核线程少得多。 允许每个进程定制自己的调度算法，线程管理比较灵活。 线程能够利用的表空间和堆栈空间比内核级线程多。 同一进程中只能同时有一个线程在运行，如果有一个线程使用了系统调用而阻塞，那么整个进程都会被挂起。另外，页面失效也会产生同样的问题。 缺点： 资源调度按照进程进行，多个处理机下，同一个进程中的线程只能在同一个处理机下分时复用 11.混合实现用户级与内核级的多路复用，内核同一调度内核线程，每个内核线程对应n个用户线程 以上知识了解即可 二、多线程的代码实现1.threading模块介绍multiprocess模块的完全模仿了threading模块的接口，二者在使用层面，有很大的相似性。 Threading模块官网介绍 2.开启线程的两种方式 方式一 12345678910from threading import Threadimport timedef sayhi(name): time.sleep(2) print('%s say hello' %name)if __name__ == '__main__': t=Thread(target=sayhi,args=('egon',)) t.start() print('主线程') 方式二 1234567891011121314from threading import Threadimport timeclass Sayhi(Thread): def __init__(self,name): super().__init__() self.name=name def run(self): time.sleep(2) print('%s say hi' % self.name)if __name__ == '__main__': t = Sayhi('Luffy') t.start() print('主线程') 3.一个进程下开启多个线程与一个进程下开启多个子进程的区别3.1 开启速度12345678910111213141516171819202122232425262728from threading import Threadfrom multiprocessing import Processimport osdef work(): print('hello')if __name__ == '__main__': #在主进程下开启线程 t=Thread(target=work) t.start() print('主线程/主进程') ''' 打印结果: hello 主线程/主进程 ''' #在主进程下开启子进程 t=Process(target=work) t.start() print('主线程/主进程') ''' 打印结果: 主线程/主进程 hello ''' 3.2 pid123456789101112131415161718192021from threading import Threadfrom multiprocessing import Processimport osdef work(): print('hello',os.getpid())if __name__ == '__main__': #part1:在主进程下开启多个线程,每个线程都跟主进程的pid一样 t1=Thread(target=work) t2=Thread(target=work) t1.start() t2.start() print('主线程/主进程pid',os.getpid()) #part2:开多个进程,每个进程都有不同的pid p1=Process(target=work) p2=Process(target=work) p1.start() p2.start() print('主线程/主进程pid',os.getpid()) 3.3 数据共享问题12345678910111213141516171819from threading import Threadfrom multiprocessing import Processimport osdef work(): global n n=0if __name__ == '__main__': # n=100 # p=Process(target=work) # p.start() # p.join() # print('主',n) # 毫无疑问子进程p已经将自己的全局的n改成了0,但改的仅仅是它自己的,查看父进程的n仍然为100 n=1 t=Thread(target=work) t.start() t.join() print('主',n) # 查看结果为0,因为同一进程内的线程之间共享进程内的数据 4.线程相关的其他方法 Thread实例对象的方法 isAlive(): 返回线程是否活动的 getName(): 返回线程名 setName(): 设置线程名 threading模块提供的一些方法 threading.currentThread(): 返回当前的线程变量 threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程 threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果 123456789101112131415161718192021222324252627282930from threading import Threadimport threadingfrom multiprocessing import Processimport osdef work(): import time time.sleep(3) print(threading.current_thread().getName())if __name__ == '__main__': #在主进程下开启线程 t=Thread(target=work) t.start() print(threading.current_thread().getName()) print(threading.current_thread()) #主线程 print(threading.enumerate()) #连同主线程在内有两个运行的线程 print(threading.active_count()) print('主线程/主进程') ''' 打印结果: MainThread &lt;_MainThread(MainThread, started 140735268892672)&gt; [&lt;_MainThread(MainThread, started 140735268892672)&gt;, &lt;Thread(Thread-1, started 123145307557888)&gt;] 主线程/主进程 Thread-1 ''' 主线程等待子线程结束 1234567891011121314151617from threading import Threadimport timedef sayhi(name): time.sleep(2) print('%s say hello' %name)if __name__ == '__main__': t=Thread(target=sayhi,args=('egon',)) t.start() t.join() print('主线程') print(t.is_alive()) ''' Luffy say hello 主线程 False ''' 5.守护线程 无论是进程还是线程，都遵循：守护进/线程会等待主进/线运行完毕后被销毁 需要强调的是：运行完毕并非终止运行 对主进程来说，运行完毕指的是主进程代码运行完毕 对主线程来说，运行完毕指的是主线程所在的进程内所有非守护线程统统运行完毕，主线程才算运行完毕 5.1 详细解释 主进程在其代码结束后就已经算运行完毕了（守护进程在此时就被回收）,然后主进程会一直等非守护的子进程都运行完毕后回收子进程的资源(否则会产生僵尸进程)，才会结束。 主线程在其他非守护线程运行完毕后才算运行完毕（守护线程在此时就被回收）。因为主线程的结束意味着进程的结束，进程整体的资源都将被回收，而进程必须保证非守护线程都运行完毕后才能结束。 1234567891011121314151617from threading import Threadimport timedef sayhi(name): time.sleep(2) print('%s say hello' %name)if __name__ == '__main__': t=Thread(target=sayhi,args=('egon',)) t.setDaemon(True) #必须在t.start()之前设置 t.start() print('主线程') print(t.is_alive()) ''' 主线程 True ''' 6.Python GIL(Global Interpreter Lock)Python GIL详解 http://www.dabeaz.com/python/UnderstandingGIL.pdf 7.同步锁 需要注意的是： 线程抢的是GIL锁，GIL锁相当于执行权限，拿到执行权限后才能拿到互斥锁Lock，其他线程也可以抢到GIL，但如果发现Lock仍然没有被释放则阻塞，即便是拿到执行权限GIL也要立刻交出来 join是等待所有，即整体串行，而锁只是锁住修改共享数据的部分，即部分串行，要想保证数据安全的根本原理在于让并发变成串行，join与互斥锁都可以实现，毫无疑问，互斥锁的部分串行效率要更高 一定要注意看本小节最后的GIL与互斥锁的经典分析 8.死锁现象与递归锁9.信号量Semaphore10.Event 11.条件Condition12.定时器 定时器，指定n秒后执行某操作 1234567from threading import Timerdef hello(): print(\"hello, world\") t = Timer(1, hello)t.start() # after 1 seconds, \"hello, world\" will be printed 验证码定时器 123456789101112131415161718192021222324252627282930313233from threading import Timerimport random,timeclass Code: def __init__(self): self.make_cache() def make_cache(self,interval=5): self.cache=self.make_code() print(self.cache) self.t=Timer(interval,self.make_cache) self.t.start() def make_code(self,n=4): res='' for i in range(n): s1=str(random.randint(0,9)) s2=chr(random.randint(65,90)) res+=random.choice([s1,s2]) return res def check(self): while True: inp=input('&gt;&gt;: ').strip() if inp.upper() == self.cache: print('验证成功',end='\\n') self.t.cancel() breakif __name__ == '__main__': obj=Code() obj.check() 13.线程queue14.Python标准模块–concurrent.futures","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.ice5.vip/categories/并发编程/"}],"tags":[{"name":"Threading","slug":"Threading","permalink":"https://www.ice5.vip/tags/Threading/"},{"name":"GIL","slug":"GIL","permalink":"https://www.ice5.vip/tags/GIL/"},{"name":"Lock/Rlock","slug":"Lock-Rlock","permalink":"https://www.ice5.vip/tags/Lock-Rlock/"}]},{"title":"网络编程Socket","slug":"网络编程之Socket","date":"2018-12-04T20:00:27.987Z","updated":"2018-12-05T18:50:26.229Z","comments":true,"path":"/网络编程之Socket/","link":"","permalink":"https://www.ice5.vip/网络编程之Socket/","excerpt":"","text":"一、Socket层的位置在网络编程基础中，我们已经了解到Socket层的位置，这边我们来再次回顾一下，加深印象。 二、Socket的概念 Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。 所以，这边我们就暂时无需深入理解tcp/udp协议，socket已经为我们封装好了，我们只需要遵循socket的规定去编程，写出的程序自然就是遵循tcp/udp标准的。 注意： 可能会有人将socket说成ip+port，ip是用来标识互联网中的一台主机的位置，而port是用来标识这台机器上的一个应用程序，ip地址是配置到网卡上的，而port是应用程序开启的，ip与port的绑定就标识了互联网中独一无二的一个应用程序，而程序的pid是同一台机器上不同进程或者线程的标识。 三、套接字家族发展史以及分类 套接字起源于 20 世纪 70 年代加利福尼亚大学伯克利分校版本的 Unix,即人们所说的 BSD Unix。 因此,有时人们也把套接字称为“伯克利套接字”或“BSD 套接字”。一开始,套接字被设计用在同 一台主机上多个应用程序之间的通讯。这也被称进程间通讯,或 IPC。套接字有两种（或者称为有两个种族）,分别是基于文件型的和基于网络型的。 1.基于文件类型的套接字家族 套接字家族的名字：AF_UNIX Unix一切皆文件，基于文件的套接字调用的就是底层的文件系统来取数据，两个套接字进程运行在同一机器，可以通过访问同一个文件系统间接完成通信 。 2.基于网络类型的套接字家族 套接字家族的名字：AF_INET 还有AF_INET6被用于ipv6，还有一些其他的地址家族，不过，他们要么是只用于某个平台，要么就是已经被废弃，或者是很少被使用，或者是根本没有实现，所有地址家族中，AF_INET是使用最广泛的一个，python支持很多种地址家族，但是由于我们只关心网络编程，所以大部分时候我么只使用AF_INET。 四、套接字工作流程 先从服务器端说起。服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束。 1.socket()模块函数用法123456789101112import socketsocket.socket(socket_family,socket_type,protocal=0)socket_family 可以是 AF_UNIX 或 AF_INET。socket_type 可以是 SOCK_STREAM 或 SOCK_DGRAM。protocol 一般不填,默认值为 0。获取tcp/ip套接字tcpSock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)获取udp/ip套接字udpSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)由于 socket 模块中有太多的属性。我们在这里破例使用了'from module import *'语句。使用 'from socket import *',我们就把 socket 模块里的所有属性都带到我们的命名空间里了,这样能 大幅减短我们的代码。例如tcpSock = socket(AF_INET, SOCK_STREAM) 2.服务端套接字函数 函数 说明 s.bind() 绑定(主机,端口号)到套接字 s.listen() 开始TCP监听 s.accept() 被动接受TCP客户的连接,(阻塞式)等待连接的到来 3.客户端套接字函数 函数 说明 s.connect() 主动初始化TCP服务器连接 s.connect_ex() connect()函数的扩展版本,出错时返回出错码,而不是抛出异常 4.公共用途的套接字函数 函数 说明 s.recv() 接收TCP数据 s.send() 发送TCP数据(send在待发送数据量大于己端缓存区剩余空间时,数据丢失,不会发完) s.sendall() 发送完整的TCP数据(本质就是循环调用send,sendall在待发送数据量大于己端缓存区剩余空间时,数据不丢失,循环调用send直到发完) s.recvfrom() 接收UDP数据 s.sendto() 发送UDP数据 s.getpeername() 连接到当前套接字的远端的地址 s.getsockname() 当前套接字的地址 s.getsockopt() 返回指定套接字的参数 s.setsockopt() 设置指定套接字的参数 s.close() 关闭套接字 5.面向锁的套接字方法 函数 说明 s.setblocking() 设置套接字的阻塞与非阻塞模式 s.settimeout() 设置阻塞套接字操作的超时时间 s.gettimeout() 得到阻塞套接字操作的超时时间 6.面向文件的套接字的函数 函数 说明 s.fileno() 套接字的文件描述符 s.makefile() 创建一个与该套接字相关的文件 五、基于TCP的套接字 TCP是基于链接的，必须先启动服务端，然后再启动客户端去链接服务端 1.TCP服务端12345678910import socketss = socket() #创建服务器套接字ss.bind() #把地址绑定到套接字ss.listen() #监听链接inf_loop: #服务器无限循环 cs = ss.accept() #接受客户端链接 comm_loop: #通讯循环 cs.recv()/cs.send() #对话(接收与发送) cs.close() #关闭客户端套接字ss.close() #关闭服务器套接字(可选) 2.TCP客户端123456import socketcs = socket() # 创建客户套接字cs.connect() # 尝试连接服务器comm_loop: # 通讯循环 cs.send()/cs.recv() # 对话(发送/接收)cs.close() # 关闭客户套接字 3.举例 socket通信流程与打电话流程类似，我们就以打电话为例来实现套接字通信 服务端 1234567891011121314151617181920import socketip_port=('127.0.0.1',8081) # 电话卡BUFSIZE=1024s=socket.socket(socket.AF_INET,socket.SOCK_STREAM) # 买手机s.bind(ip_port) # 手机插卡s.listen(5) # 手机待机while True: # 新增接收链接循环,可以不停的接电话 conn,addr=s.accept() # 手机接电话 # print(conn) # print(addr) print('接到来自%s的电话' %addr[0]) while True: # 新增通信循环,可以不断的通信,收发消息 msg=conn.recv(BUFSIZE) # 听消息,听话 # if len(msg) == 0:break # 如果不加,那么正在链接的客户端突然断开,recv便不再阻塞,死循环发生 print(msg,type(msg)) conn.send(msg.upper()) # 发消息,说话 conn.close() # 挂电话s.close() # 手机关机 客户端 12345678910111213import socketip_port=('127.0.0.1',8081)BUFSIZE=1024s=socket.socket(socket.AF_INET,socket.SOCK_STREAM)s.connect_ex(ip_port) # 拨电话while True: # 新增通信循环,客户端可以不断发收消息 msg=input('&gt;&gt;: ').strip() if len(msg) == 0:continue s.send(msg.encode('utf-8')) # 发消息,说话(只能发送字节类型) feedback=s.recv(BUFSIZE) # 收消息,听话 print(feedback.decode('utf-8'))s.close() # 挂电话 在重启服务端时可能会遇到OSError的问题 出现改原因是由于你的服务端仍然存在四次挥手的time_wait状态在占用地址（如果不懂，请深入研究1.tcp三次握手，四次挥手 2.syn洪水攻击 3.服务器高并发情况下会有大量的time_wait状态的优化方法） 解决方法 加入一条socket配置，重用ip和端口 123phone=socket(AF_INET,SOCK_STREAM)phone.setsockopt(SOL_SOCKET,SO_REUSEADDR,1) # 就是它，在bind前加phone.bind(('127.0.0.1',8080)) 发现系统存在大量TIME_WAIT状态的连接，通过调整Linux内核参数解决 1234567891011121314vi /etc/sysctl.conf# 编辑文件，加入以下内容net.ipv4.tcp_syncookies = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_fin_timeout = 30 # 然后执行 /sbin/sysctl -p 让参数生效 net.ipv4.tcp_syncookies = 1 # 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭net.ipv4.tcp_tw_reuse = 1 # 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭net.ipv4.tcp_tw_recycle = 1 # 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭net.ipv4.tcp_fin_timeout # 修改系統默认的 TIMEOUT 时间 六、基于UDP的套接字 UDP是无链接的，先启动哪一端都不会报错 1.UDP服务端123456import socketss = socket() # 创建一个服务器的套接字ss.bind() # 绑定服务器套接字inf_loop: # 服务器无限循环 cs = ss.recvfrom()/ss.sendto() # 对话(接收与发送)ss.close() # 关闭服务器套接字 2.UDP客户端12345import socketcs = socket() # 创建客户套接字comm_loop: # 通讯循环 cs.sendto()/cs.recvfrom() # 对话(发送/接收)cs.close() # 关闭客户套接字 3.举例 服务端 12345678910import socketip_port=('127.0.0.1',9000)BUFSIZE=1024udp_server_client=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)udp_server_client.bind(ip_port)while True: msg,addr=udp_server_client.recvfrom(BUFSIZE) print(msg,addr) udp_server_client.sendto(msg.upper(),addr) 客户端 1234567891011import socketip_port=('127.0.0.1',9000)BUFSIZE=1024udp_server_client=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)while True: msg=input('&gt;&gt;: ').strip() if not msg:continue udp_server_client.sendto(msg.encode('utf-8'),ip_port) back_msg,addr=udp_server_client.recvfrom(BUFSIZE) print(back_msg.decode('utf-8'),addr) 七、粘包现象以及粘包的解决方案 基于TCP的socket，在运行时会发生粘包；基于UDP的socket，在运行时永远不会发生粘包 。所以说粘包是TCP产生的一种特有的现象。 需要注意的是： 1234res=subprocess.Popen(cmd.decode('utf-8'), shell=True, stderr=subprocess.PIPE, stdout=subprocess.PIPE) 上述代码的结果编码是以当前所在的系统为准的，如果是windows，那么res.stdout.read()读出的就是GBK编码的，在接收端需要用GBK解码，且只能从管道里读一次结果。 1.Socket收发消息的原理 发送端可以是一K一K地发送数据，而接收端的应用程序可以两K两K地提走数据，当然也有可能一次提走3K或6K数据，或者一次只提走几个字节的数据，也就是说，应用程序所看到的数据是一个整体，或说是一个流（stream），一条消息有多少字节对应用程序是不可见的，因此TCP协议是面向流的协议，这也是容易出现粘包问题的原因。而UDP是面向消息的协议，每个UDP段都是一条消息，应用程序必须以消息为单位提取数据，不能一次提取任意字节的数据，这一点和TCP是很不同的。怎样定义消息呢？可以认为对方一次性write/send的数据为一个消息，需要明白的是当对方send一条信息的时候，无论底层怎样分段分片，TCP协议层会把构成整条消息的数据段排序完成后才呈现在内核缓冲区。 所谓粘包问题主要还是因为接收方不知道消息之间的界限，不知道一次性提取多少字节的数据所造成的。 此外，发送方引起的粘包是由TCP协议本身造成的。 TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一个TCP段。 若连续几次需要send的数据都很少，通常TCP会根据优化算法把这些数据合成一个TCP段后一次发送出去，这样接收方就收到了粘包数据。 TCP（transport control protocol，传输控制协议）是面向连接的，面向流的，提供高可靠性服务。收发两端（客户端和服务器端）都要有一一成对的socket，因此，发送端为了将多个发往接收端的包，更有效的发到对方，使用了优化方法（Nagle算法），将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样，接收端，就难于分辨出来了，必须提供科学的拆包机制。 即面向流的通信是无消息保护边界的。 UDP（user datagram protocol，用户数据报协议）是无连接的，面向消息的，提供高效率服务。不会使用块的合并优化算法，, 由于UDP支持的是一对多的模式，所以接收端的skbuff(套接字缓冲区）采用了链式结构来记录每一个到达的UDP包，在每个UDP包中就有了消息头（消息来源地址，端口等信息），这样，对于接收端来说，就容易进行区分处理了。 即面向消息的通信是有消息保护边界的。 TCP是基于数据流的，于是收发的消息不能为空，这就需要在客户端和服务端都添加空消息的处理机制，防止程序卡住，而UDP是基于数据报的，即便是你输入的是空内容（直接回车），那也不是空消息，UDP协议会帮你封装上消息头。 UDP的recvfrom是阻塞的，一个recvfrom(x)必须对唯一一个sendinto(y),收完了x个字节的数据就算完成,若是y&gt;x数据就丢失，这意味着UDP根本不会粘包，但是会丢数据，不可靠 TCP的协议数据不会丢，没有收完包，下次接收，会继续上次继续接收，己端总是在收到ack时才会清除缓冲区内容。数据是可靠的，但是会粘包。 2.发生粘包的两种情况 发送端需要等缓冲区满才发送出去，造成粘包（发送数据时间间隔很短，数据了很小，会合到一起，产生粘包） 123456789101112131415# 服务端from socket import *ip_port=('127.0.0.1',8080)tcp_socket_server=socket(AF_INET,SOCK_STREAM)tcp_socket_server.bind(ip_port)tcp_socket_server.listen(5)conn,addr=tcp_socket_server.accept()data1=conn.recv(10)data2=conn.recv(10)print('-----&gt;',data1.decode('utf-8'))print('-----&gt;',data2.decode('utf-8'))conn.close() 12345678910# 客户端import socketBUFSIZE=1024ip_port=('127.0.0.1',8080)s=socket.socket(socket.AF_INET,socket.SOCK_STREAM)res=s.connect_ex(ip_port)s.send('hello'.encode('utf-8'))s.send('feng'.encode('utf-8')) 接收方不及时接收缓冲区的包，造成多个包接收（客户端发送了一段数据，服务端只收了一小部分，服务端下次再收的时候还是从缓冲区拿上次遗留的数据，产生粘包） 12345678910111213141516# 服务端from socket import *ip_port=('127.0.0.1',8080)tcp_socket_server=socket(AF_INET,SOCK_STREAM)tcp_socket_server.bind(ip_port)tcp_socket_server.listen(5)conn,addr=tcp_socket_server.accept()data1=conn.recv(2) #一次没有收完整data2=conn.recv(10)#下次收的时候,会先取旧的数据,然后取新的print('-----&gt;',data1.decode('utf-8'))print('-----&gt;',data2.decode('utf-8'))conn.close() 123456789# 客户端import socketBUFSIZE=1024ip_port=('127.0.0.1',8080)s=socket.socket(socket.AF_INET,socket.SOCK_STREAM)res=s.connect_ex(ip_port)s.send('hello feng'.encode('utf-8')) 3.拆包的发生情况当发送端缓冲区的长度大于网卡的MTU时，tcp会将这次发送的数据拆成几个数据包发送出去。 4.为何TCP是可靠传输，UDP是不可靠传输 TCP在数据传输时，发送端先把数据发送到自己的缓存中，然后协议控制将缓存中的数据发往对端，对端返回一个ack=1，发送端则清理缓存中的数据，对端返回ack=0，则重新发送数据，所以TCP是可靠的。 UDP发送数据，对端是不会返回确认信息的，因此不可靠。 5.send(字节流)和recv(1024)及sendall recv里指定的1024意思是从缓存里一次拿出1024个字节的数据 send的字节流是先放入己端缓存，然后由协议控制将缓存内容发往对端，如果待发送的字节流大小大于缓存剩余空间，那么数据丢失，用sendall就会循环调用send，数据不会丢失 6. 解决粘包的处理方法 为字节流加上自定义固定长度报头，报头中包含字节流长度，然后一次send到对端，对端在接收时，先从缓存中取出定长的报头，然后再取真实数据。 在解决粘包之前，我们先介绍下struct模块： 该模块可以把一个类型，如数字，转成固定长度的bytes 。 123456789101112131415161718192021222324252627import json,struct#假设通过客户端上传1T:1073741824000的文件a.txt#为避免粘包,必须自定制报头header=&#123;'file_size':1073741824000,'file_name':'/a/b/c/d/e/a.txt','md5':'8f6fbf8347faa4924a76856701edb0f3'&#125; #1T数据,文件路径和md5值#为了该报头能传送,需要序列化并且转为byteshead_bytes=bytes(json.dumps(header),encoding='utf-8') #序列化并转成bytes,用于传输#为了让客户端知道报头的长度,用struck将报头长度这个数字转成固定长度:4个字节head_len_bytes=struct.pack('i',len(head_bytes)) #这4个字节里只包含了一个数字,该数字是报头的长度#客户端开始发送conn.send(head_len_bytes) #先发报头的长度,4个bytesconn.send(head_bytes) #再发报头的字节格式conn.sendall(文件内容) #然后发真实内容的字节格式#服务端开始接收head_len_bytes=s.recv(4) #先收报头4个bytes,得到报头长度的字节格式x=struct.unpack('i',head_len_bytes)[0] #提取报头的长度head_bytes=s.recv(x) #按照报头长度x,收取报头的bytes格式header=json.loads(json.dumps(header)) #提取报头#最后根据报头的内容提取真实的数据,比如real_data_len=s.recv(header['file_size'])s.recv(real_data_len) 123456789101112131415161718192021222324252627# 关于struct的详细用法import structimport binasciiimport ctypesvalues1 = (1, 'abc'.encode('utf-8'), 2.7)values2 = ('defg'.encode('utf-8'),101)s1 = struct.Struct('I3sf')s2 = struct.Struct('4sI')print(s1.size,s2.size)prebuffer=ctypes.create_string_buffer(s1.size+s2.size)print('Before : ',binascii.hexlify(prebuffer))# t=binascii.hexlify('asdfaf'.encode('utf-8'))# print(t)s1.pack_into(prebuffer,0,*values1)s2.pack_into(prebuffer,s1.size,*values2)print('After pack',binascii.hexlify(prebuffer))print(s1.unpack_from(prebuffer,0))print(s2.unpack_from(prebuffer,s1.size))s3=struct.Struct('ii')s3.pack_into(prebuffer,0,123,123)print('After pack',binascii.hexlify(prebuffer))print(s3.unpack_from(prebuffer,0)) 服务端（自定制报头） 123456789101112131415161718192021222324252627import socket,struct,jsonimport subprocessphone=socket.socket(socket.AF_INET,socket.SOCK_STREAM)phone.setsockopt(socket.SOL_SOCKET,socket.SO_REUSEADDR,1) #就是它，在bind前加phone.bind(('127.0.0.1',8080))phone.listen(5)while True: conn,addr=phone.accept() while True: cmd=conn.recv(1024) if not cmd:break print('cmd: %s' %cmd) res=subprocess.Popen(cmd.decode('utf-8'), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) err=res.stderr.read() print(err) if err: back_msg=err else: back_msg=res.stdout.read() conn.send(struct.pack('i',len(back_msg))) #先发back_msg的长度 conn.sendall(back_msg) #在发真实的内容 conn.close() 客户端（自定制报头） 12345678910111213141516171819202122import socket,time,structs=socket.socket(socket.AF_INET,socket.SOCK_STREAM)res=s.connect_ex(('127.0.0.1',8080))while True: msg=input('&gt;&gt;: ').strip() if len(msg) == 0:continue if msg == 'quit':break s.send(msg.encode('utf-8') l=s.recv(4) x=struct.unpack('i',l)[0] print(type(x),x) # print(struct.unpack('I',l)) r_s=0 data=b'' while r_s &lt; x: r_d=s.recv(1024) data+=r_d r_s+=len(r_d) # print(data.decode('utf-8')) print(data.decode('gbk')) #windows默认gbk编码 具体思路步骤 我们可以把报头做成字典，字典里包含将要发送的真实数据的详细信息，然后json序列化，然后用struck将序列化后的数据长度打包成4个字节（4个自己足够用了） 发送时： 先发报头长度 再编码报头内容然后发送 最后发真实内容 接收时： 先手报头长度，用struct取出来 根据取出的长度收取报头内容，然后解码，反序列化 从反序列化的结果中取出待取数据的详细信息，然后去取真实的数据内容 服务端复杂一点的报头 123456789101112131415161718192021222324252627282930313233import socket,struct,jsonimport subprocessphone=socket.socket(socket.AF_INET,socket.SOCK_STREAM)phone.setsockopt(socket.SOL_SOCKET,socket.SO_REUSEADDR,1) # 就是它，在bind前加phone.bind(('127.0.0.1',8080))phone.listen(5)while True: conn,addr=phone.accept() while True: cmd=conn.recv(1024) if not cmd:break print('cmd: %s' %cmd) res=subprocess.Popen(cmd.decode('utf-8'), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) err=res.stderr.read() print(err) if err: back_msg=err else: back_msg=res.stdout.read() headers=&#123;'data_size':len(back_msg)&#125; head_json=json.dumps(headers) head_json_bytes=bytes(head_json,encoding='utf-8') conn.send(struct.pack('i',len(head_json_bytes))) # 先发报头的长度 conn.send(head_json_bytes) # 再发报头 conn.sendall(back_msg) # 在发真实的内容 conn.close() 客户端 123456789101112131415161718192021222324from socket import *import struct,jsonip_port=('127.0.0.1',8080)client=socket(AF_INET,SOCK_STREAM)client.connect(ip_port)while True: cmd=input('&gt;&gt;: ') if not cmd:continue client.send(bytes(cmd,encoding='utf-8')) head=client.recv(4) head_json_len=struct.unpack('i',head)[0] head_json=json.loads(client.recv(head_json_len).decode('utf-8')) data_len=head_json['data_size'] recv_size=0 recv_data=b'' while recv_size &lt; data_len: recv_data+=client.recv(1024) recv_size+=len(recv_data) print(recv_data.decode('utf-8')) # print(recv_data.decode('gbk')) #windows默认gbk编码 八、认证客户端的链接合法性 若想要在分布式系统中实现一个简单的客户端链接认证功能，又不像SSL那么复杂，那么利用hmac+加盐的方式来实现 服务端 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647from socket import *import hmac,ossecret_key=b'linhaifeng bang bang bang'def conn_auth(conn): ''' 认证客户端链接 :param conn: :return: ''' print('开始验证新链接的合法性') msg=os.urandom(32) conn.sendall(msg) h=hmac.new(secret_key,msg) digest=h.digest() respone=conn.recv(len(digest)) return hmac.compare_digest(respone,digest)def data_handler(conn,bufsize=1024): if not conn_auth(conn): print('该链接不合法,关闭') conn.close() return print('链接合法,开始通信') while True: data=conn.recv(bufsize) if not data:break conn.sendall(data.upper())def server_handler(ip_port,bufsize,backlog=5): ''' 只处理链接 :param ip_port: :return: ''' tcp_socket_server=socket(AF_INET,SOCK_STREAM) tcp_socket_server.bind(ip_port) tcp_socket_server.listen(backlog) while True: conn,addr=tcp_socket_server.accept() print('新连接[%s:%s]' %(addr[0],addr[1])) data_handler(conn,bufsize)if __name__ == '__main__': ip_port=('127.0.0.1',9999) bufsize=1024 server_handler(ip_port,bufsize) 合法客户端 12345678910111213141516171819202122232425262728293031323334from socket import *import hmac,ossecret_key=b'linhaifeng bang bang bang'def conn_auth(conn): ''' 验证客户端到服务器的链接 :param conn: :return: ''' msg=conn.recv(32) h=hmac.new(secret_key,msg) digest=h.digest() conn.sendall(digest)def client_handler(ip_port,bufsize=1024): tcp_socket_client=socket(AF_INET,SOCK_STREAM) tcp_socket_client.connect(ip_port) conn_auth(tcp_socket_client) while True: data=input('&gt;&gt;: ').strip() if not data:continue if data == 'quit':break tcp_socket_client.sendall(data.encode('utf-8')) respone=tcp_socket_client.recv(bufsize) print(respone.decode('utf-8')) tcp_socket_client.close()if __name__ == '__main__': ip_port=('127.0.0.1',9999) bufsize=1024 client_handler(ip_port,bufsize) 不知道加密方式的非法客户端 12345678910111213141516171819from socket import *def client_handler(ip_port,bufsize=1024): tcp_socket_client=socket(AF_INET,SOCK_STREAM) tcp_socket_client.connect(ip_port) while True: data=input('&gt;&gt;: ').strip() if not data:continue if data == 'quit':break tcp_socket_client.sendall(data.encode('utf-8')) respone=tcp_socket_client.recv(bufsize) print(respone.decode('utf-8')) tcp_socket_client.close()if __name__ == '__main__': ip_port=('127.0.0.1',9999) bufsize=1024 client_handler(ip_port,bufsize) 不知道secret_key 的非法客户端 12345678910111213141516171819202122232425262728293031323334from socket import *import hmac,ossecret_key=b'linhaifeng bang bang bang1111'def conn_auth(conn): ''' 验证客户端到服务器的链接 :param conn: :return: ''' msg=conn.recv(32) h=hmac.new(secret_key,msg) digest=h.digest() conn.sendall(digest)def client_handler(ip_port,bufsize=1024): tcp_socket_client=socket(AF_INET,SOCK_STREAM) tcp_socket_client.connect(ip_port) conn_auth(tcp_socket_client) while True: data=input('&gt;&gt;: ').strip() if not data:continue if data == 'quit':break tcp_socket_client.sendall(data.encode('utf-8')) respone=tcp_socket_client.recv(bufsize) print(respone.decode('utf-8')) tcp_socket_client.close()if __name__ == '__main__': ip_port=('127.0.0.1',9999) bufsize=1024 client_handler(ip_port,bufsize) 九、socketserver 实现并发 基于TCP的套接字，关键就是两个循环，一个链接循环，一个通信循环 。 socketserver模块中分两大类：server类（解决链接问题）和request类（解决通信问题） server类 request类 继承关系 以下述代码为例，分析socketserver源码： 12ftpserver=socketserver.ThreadingTCPServer((&apos;127.0.0.1&apos;,8080),FtpServer)ftpserver.serve_forever() 查找属性的顺序：ThreadingTCPServer-&gt;ThreadingMixIn-&gt;TCPServer-&gt;BaseServer 实例化得到ftpserver，先找类ThreadingTCPServer的__init__,在TCPServer中找到，进而执行server_bind,server_active 找ftpserver下的serve_forever,在BaseServer中找到，进而执行self._handle_request_noblock()，该方法同样是在BaseServer中 执行self._handle_request_noblock()进而执行request, client_address = self.get_request()（就是TCPServer中的self.socket.accept()），然后执行self.process_request(request, client_address) 在ThreadingMixIn中找到process_request，开启多线程应对并发，进而执行process_request_thread，执行self.finish_request(request, client_address) 上述四部分完成了链接循环，本部分开始进入处理通讯部分，在BaseServer中找到finish_request,触发我们自己定义的类的实例化，去找__init__方法，而我们自己定义的类没有该方法，则去它的父类也就是BaseRequestHandler中找…. 源码分析总结： 基于tcp的socketserver我们自己定义的类中的 self.server即套接字对象 self.request即一个链接 self.client_address即客户端地址 基于udp的socketserver我们自己定义的类中的 self.request是一个元组（第一个元素是客户端发来的数据，第二部分是服务端的udp套接字对象），如(b’adsf’, &lt;socket.socket fd=200, family=AddressFamily.AF_INET, type=SocketKind.SOCK_DGRAM, proto=0, laddr=(‘127.0.0.1’, 8080)&gt;) self.client_address即客户端地址","categories":[{"name":"网络编程","slug":"网络编程","permalink":"https://www.ice5.vip/categories/网络编程/"}],"tags":[{"name":"Socket","slug":"Socket","permalink":"https://www.ice5.vip/tags/Socket/"}]},{"title":"WEB服务器之Nginx","slug":"Nginx部署","date":"2018-12-03T15:24:01.818Z","updated":"2018-12-03T15:24:01.819Z","comments":true,"path":"/Nginx部署/","link":"","permalink":"https://www.ice5.vip/Nginx部署/","excerpt":"在传统的Web项目中，并发量小，用户使用的少。 当然，为了解决并发，可以使用负载均衡 ，也就是多加几个服务器。Nginx同Apache一样都是一种WEB服务器。 基于REST架构风格，以统一资源描述符(Uniform Resources Identifier)URI或者统一资源定位符(Uniform Resources Locator)URL作为沟通依据，通过HTTP协议提供各种网络服务。所以什么情况下该使用Nginx呢？或者说Nginx带来的好处有哪些？","text":"在传统的Web项目中，并发量小，用户使用的少。 当然，为了解决并发，可以使用负载均衡 ，也就是多加几个服务器。Nginx同Apache一样都是一种WEB服务器。 基于REST架构风格，以统一资源描述符(Uniform Resources Identifier)URI或者统一资源定位符(Uniform Resources Locator)URL作为沟通依据，通过HTTP协议提供各种网络服务。所以什么情况下该使用Nginx呢？或者说Nginx带来的好处有哪些？ 一、Nginx和Apache1.Apache介绍 Apache相对Nginx的发展历程比较漫长，而且是世界第一大服务器。它有着很多有点：稳定、开源、跨平台等。它兴起的年代，互联网产业远比不上现在，所以它被设计为一个重量级的且不支持高并发的服务器。在Apache上运行数以万计的并发访问，会导致服务器消耗大量内存。操作系统对其进行进程或线程间的切换也消耗了大量的CPU资源，导致HTTP请求的平均响应速度降低。 所以Apache不可能成为高性能WEB服务器，轻量级高并发服务器Nginx就应运而生了。 2.Nginx介绍 Nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器；同时也是一个IMAP、POP3、SMTP代理服务器；Nginx可以作为一个HTTP服务器进行网站的发布处理，另外Nginx可以作为反向代理进行负载均衡的实现。 Nginx常用做静态内容服务和代理服务器，直面外来请求转发给后面的应用服务 (Django)。如今，更加追求效率的环境中 ，Nginx是处理大并发，反向代理，负载均衡需求的优秀选择 Nginx 启动特别容易，并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。你还能够在 不间断服务的情况下进行软件版本的升级。Nginx 安装简单，配置简洁（还能够支持perl语法），Bugs非常少的服务器。 二、Nginx之代理 代理是介于客户端和服务端的一种服务，某些网关、路由器等网络设备具备网络代理功能。一般认为代理服务有利于保障网络终端的隐私或安全，防止攻击。 提供代理服务的电脑系统或其它类型的网络终端称为代理服务器（Proxy Server） 1.正向代理 正向代理发生在 client端，用户能感知到的，并且是用户主动发起的代理。 正向代理也是大家最常接触的到的代理模式 。我们不能访问外网，但是可以访问代理服务器，然后代理服务器帮我们从外网中获取数据。但是在使用之前，用户往往需要主动在client端配置代理。 黑客为了隐藏身份，用的就是正向代理。 正向代理的用途 访问无法访问的资源，如https://www.google.com 可以做缓存，加速访问资源 对客户端访问授权，上网进行认证 代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息 2.反向代理 反向代理发生在 server端，从用户角度看是不知道发生了代理的。用户访问 服务器A，服务器A就给用户返回了数据。但是服务器A上其实并没有数据，它是偷偷从服务器B上获取数据，然后再返回给用户的。这个过程是在 server端发生的，用户并不知道 。 反向代理的用途 负载均衡，通过反向代理服务器来优化网站的负载 保证内网的安全，可以使用反向代理提供WAF功能，阻止web攻击 。有很多大型网站，通常将反向代理作为公网访问地址，Web服务器是内网 Nginx支持配置反向代理，通过反向代理实现网站的负载均衡。 12345678910111213141516upstream www proxy test 80 &#123; server 192.168.10.10:80;&#125;server &#123; listen 80; server_name www.mysite.com; location / &#123; proxy_pass http://www_proxy_test_80; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; proxy_redirect off; &#125;&#125; 3.Nginx配置12345678910111213141516171819202122worker_processes 1; #全局有效events &#123; worker_connections 1024; #events部分有效&#125;http &#123; include mime.types; #http部分有效 default_type applicaiotion/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name localhost; #http的server部分有效 location / &#123; #http/server的location部分有效 root html; index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 三、Nginx、uwsgi、Django1.Nginx安装1234$ sudo apt-get install nginx #安装$ /etc/init.d/nginx start #启动$ /etc/init.d/nginx stop #关闭$ /etc/init.d/nginx restart #重启 2.安装 uwsgi1$ python3 -m pip install uwsgi # 前提是已安装python并设置好环境变量 测试uwsgi，创建index.py文件 123def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return [b\"Hello World\"] 通过uwsgi运行该文件 1$ uwsgi --http :8001 --wsgi-file index.py 配置Django与uwsgi连接 ,Django项目的位置假设是 /home/mysite/ 1$ uwsgi --http :8001 --chdir /home/mysite/ --wsgi-file mysite/wsgi.py --master --processes 4 --threads 2 --stats 127.0.0.1:9191 参数 说明 http 协议类型和端口号 process 开启的进程数量 workers 开启的进程数量，等同于processes chdir 指定运行目录 （chdir to specified directory before apps loading） wsgi-file 载入wsgi-file（load .wsgi file） stats 在指定的地址上，开启状态服务（enable the stats server on the specified address） threads 运行线程。由于GIL的存在，这个好像没啥用 master 允许主进程存在（enable master process） daemonize 使进程在后台运行，并将日志打到指定的日志文件或者udp服务器（daemonize uWSGI）。实际上最常用的，还是把运行记录输出到一个本地文件上 pidfile 指定pid文件的位置，记录主进程的pid号 vacuum 当服务器退出的时候自动清理环境，删除unix socket文件和pid文件（try to remove all of the generated file/sockets） 3.Nginx + uwsgi + Django12345678mysite/├── manage.py├── mysite/│ ├── __init__.py│ ├── settings.py│ ├── urls.py│ └── wsgi.py└── mysite_uwsgi.ini 1.由于子目录mysite下 wsgi.py 已经存在，只需要再创建mysite_uwsgi.ini配置文件即可，当然，uwsgi支持多种类型的配置文件，如xml，ini等。此处，使用ini类型的配置。 123456789101112131415161718192021222324# mysite_uwsgi.ini file[uwsgi]# Django-related settings# 指定项目执行的端口号socket = :8000 # the base directory (full path)# 指定项目的目录chdir = /home/mysite# Django s wsgi filemodule = mysite.wsgi# process-related settings# mastermaster = true# maximum number of worker processesprocesses = 4# ... with appropriate permissions - may be needed# chmod-socket = 664# clear environment on exitvacuum = true 2.切换到mysite项目目录下，通过uwsgi命令读取mysite_uwsgi.ini文件启动项目 12$ cd /home/mysite/$ uwsgi --ini mysite_uwsgi.ini 3.修改nginx.conf配置文件。打开/etc/nginx/nginx.conf文件 123456789101112131415161718192021222324server &#123; # 指定的是nginx代理uwsgi对外的端口号 listen 8099; # 设置的一个网址（例，www.example.com）或者 ip server_name 127.0.0.1 charset UTF-8; access_log /var/log/nginx/mysite_access.log; error_log /var/log/nginx/mysite_error.log; client_max_body_size 75M; location / &#123; # nginx 和 uwsgi 关联 include uwsgi_params; uwsgi_pass 127.0.0.1:8000; uwsgi_read_timeout 2; &#125; location /static &#123; expires 30d; autoindex on; add_header Cache-Control private; alias /home/mysite/; &#125; &#125; 上面设置完成之后，重启Nginx服务器，以使Nginx的配置生效 。可以由Nginx来处理静态文件(/static/ 和 /media/ ）。非静态文件请求Nginx会发给 socket 8077，然后让uWSGI来进行处理。 四、负载均衡 服务器的性能达到极限时，可以使用服务器集群来提高网站的整体性能。在该服务器集群中，需要有一台服务器充当调度者的角色，用户发的所有请求都会首先由它接收，调度者再根据每台服务器的负载情况将请求分配给某一台后端服务器去处理。在这个过程中，调度者如何合理分配任务，保证所有后端服务器都将性能充分发挥，从而保持服务器集群的整体性能最优，这就是负载均衡问题。负载均衡实现的方式有哪些呢？ 调度策略 随机分配策略: 当调度服务器收到用户请求后，随机决定使用指定的某台后端服务器，然后将该服务器的IP封装在HTTP响应消息的Location属性中，返回给浏览器即可。 轮询策略(RR): 调度服务器需要维护一个值，用于记录上次分配的后端服务器的IP(需要额外的开销)。那么当新的请求到来时，调度者将请求依次分配给下一台服务器。 假如有多个请求同时到来时，为了避免线程的安全问题，因此需要锁定互斥资源，从而降低了性能。而随机分配策略不需要维护额外的值，也就不存在线程安全问题，因此性能比轮询要高。 1.HTTP重定向实现负载均衡​ 当客户端向后端服务器发起请求时，请求首先被集群调度者截获；调度者会根据某种调度策略，选择一台服务器，并将选中的服务器的IP地址封装在HTTP响应消息头部的Location字段中，并将响应消息的状态码设为302，最后将这个响应消息返回给浏览器。 ​ 当浏览器收到响应消息后，解析Location字段，并向该URL发起请求，然后指定的服务器处理该用户的请求，最后将结果返回给用户。 ​ 在使用HTTP重定向来实现服务器集群负载均衡的过程中，需要一台服务器作为请求调度者。用户的一项操作需要发起两次HTTP请求，一次向调度服务器发送请求，获取后端服务器的IP，第二次向后端服务器发送请求，获取处理结果。 优缺点分析 采用HTTP重定向来实现服务器集群的负载均衡实现起来较为容易，逻辑比较简单，但缺点也较为明显。 在HTTP重定向方法中，调度服务器只在客户端第一次向网站发起请求的时候起作用。当调度服务器向浏览器返回响应信息后，客户端此后的操作都基于新的URL进行的(也就是后端服务器)，此后浏览器就不会与调度服务器产生关系，进而会产生如下几个问题： 由于不同用户的访问时间、访问页面深度有所不同，从而每个用户对各自的后端服务器所造成的压力也不同。而调度服务器在调度时，无法知道当前用户将会对服务器造成多大的压力，因此这种方式无法实现真正意义上的负载均衡，只不过是把请求次数平均分配给每台服务器罢了。 若分配给该用户的后端服务器出现故障，并且如果页面被浏览器缓存，那么当用户再次访问网站时，请求都会发给出现故障的服务器，从而导致访问失败。 2.DNS负载均衡 网络中数据包是采用IP地址在网络中传播，而为了方便，我们使用域名来访问网站。那么，访问网站之前，首先需要将域名解析成IP地址，该工作就是由DNS完成的，也就是域名服务器。 用户提交的请求不会直接发送给想要访问的网站，而是首先发给域名服务器，它将域名解析成IP地址并返回给用户,用户收到IP之后才会向该IP发起请求。 所以，DNS服务器有一个天然的优势，若一个域名指向了多个IP地址，那么每次进行域名解析时，DNS只要选一个IP返回给用户，就能够实现服务器集群的负载均衡。 优缺点分析 DNS负载均衡的优点就是配置简单。服务器集群的调度工作完全由DNS服务器承担，就可以把精力放在后端服务器上，保证它们的稳定性与吞吐量。完全不用担心DNS服务器的性能，即便是使用了轮询策略，它的吞吐率依然卓越。此外，DNS负载均衡具有较强的扩展性，完全可以为一个域名解析较多的IP，而且不用担心性能问题。 由于集群的调度权交给了DNS服务器，没办法随意地控制调度者，无法定制调度策略。DNS服务器也无法了解每台服务器的负载情况，因此无法实现真正意义上的负载均衡。它和HTTP重定向一样，只不过把所有请求平均分配给后端服务器罢了。此外，当我们发现某一台后端服务器发生故障时，即使我们立即将该服务器从域名解析中去除，但由于DNS服务器会有缓存，该IP仍然会在DNS中保留一段时间，那么就会导致一部分用户无法正常访问网站。这是一个致命的问题！好在这个问题可以用动态DNS来解决。 动态DNS能够通过程序动态修改DNS服务器中的域名解析。从而当监控程序发现某台服务器宕了之后，能立即通知DNS将其删掉。 3.反向代理负载均衡优点 隐藏后端服务器： 与HTTP重定向相比，反向代理能够隐藏后端服务器，任何浏览器都不会与后端服务器直接交互，从而能够确保调度者的控制权，提升集群的整体性能。 合理分配任务 ： HTTP重定向和DNS负载均衡都无法实现真正意义上的负载均衡，也就是调度服务器无法根据后端服务器的实际负载情况分配任务。但反向代理服务器支持手动设定每台后端服务器的权重。我们可以根据服务器的配置设置不同的权重，权重的不同会导致被调度者选中的概率的不同。 故障转移： 与DNS负载均衡相比，反向代理能够更快速地移除故障结点。当监控程序发现某一后端服务器出现故障时，能够及时通知反向代理服务器，并立即将其删除。 缺点 调度者压力过大： 由于所有的请求都先由反向代理服务器处理，那么当请求量超过调度服务器的最大负载时，调度服务器的吞吐率降低会直接降低集群的整体性能。 限制扩展： 当后端服务器也无法满足巨大的吞吐量时，就需要增加后端服务器的数量，可没办法无限量地增加，因为会受到调度服务器的最大吞吐量的制约。 粘滞会话 反向代理服务器会引发一个问题。若某台后端服务器处理了用户的请求，并保存了该用户的session或存储了缓存，那么当该用户再次发送请求时，无法保证该请求仍然由保存了其session或缓存的服务器处理，若由其他服务器处理，先前的session或缓存就找不到了。 解决方式 修改反向代理服务器的任务分配策略，以用户IP作为标识较为合适。相同的用户IP会交由同一台后端服务器处理，从而就避免了粘滞会话的问题。 在Cookie中标注请求的服务器ID，当再次提交请求时，调度者将该请求分配给Cookie中标注的服务器处理即可。 4.负载均衡组件 1.Apache 它是Apache软件基金会的一个开放源代码的跨平台的网页服务器，属于老牌的web服务器了，支持基于Ip或者域名的虚拟主机，支持代理服务器，支持安全Socket层(SSL)等等，目前互联网主要使用它做静态资源服务器，也可以做代理服务器转发请求(如：图片链等)，结合tomcat等servlet容器处理jsp。 2.Nginx 俄罗斯人开发的一个高性能的 HTTP和反向代理服务器。由于Nginx 超越 Apache 的高性能和稳定性，使得国内使用 Nginx 作为 Web 服务器的网站也越来越多，其中包括新浪博客、新浪播客、网易新闻、腾讯网、搜狐博客等门户网站频道等，在3w以上的高并发环境下，ngnix处理能力相当于apache的10倍。 3.Keepalived 这里说的keepalived不是apache或者tomcat等某个组件上的属性字段，它也是一个组件，可以实现web服务器的高可用(HA high availably)。它可以检测web服务器的工作状态，如果该服务器出现故障被检测到，将其剔除服务器群中，直至正常工作后，keepalive会自动检测到并加入到服务器群里面。实现主备服务器发生故障时ip瞬时无缝交接。它是LVS集群节点健康检测的一个用户空间守护进程，也是LVS的引导故障转移模块（director failover）。Keepalived守护进程可以检查LVS池的状态。如果LVS服务器池当中的某一个服务器宕机了。keepalived会通过一 个setsockopt呼叫通知内核将这个节点从LVS拓扑图中移除。 4.memcached 它是一个高性能分布式内存对象缓存系统。当初是Danga Interactive为了LiveJournal快速发展开发的系统，用于对业务查询数据缓存，减轻数据库的负载。其守护进程(daemon)是用C写的，但是客户端支持几乎所有语言(客户端基本上有3种版本[memcache client for Java;spymemcached;xMecache])，服务端和客户端通过简单的协议通信；在memcached里面缓存的数据必须序列化。 5.lvs Linux Virtual Server的简写，意即Linux虚拟服务器，是一个虚拟的服务器集群系统。由毕业于国防科技大学的章文嵩博士于1998年5月创立，可以实现LINUX平台下的简单负载均衡。 了解更多，访问官网：http://zh.linuxvirtualserver.org/。 6.HAProxy HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy特别适用于那些负载特大的web站点， 这些站点通常又需要会话保持或七层处理。HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上.。 7.terracotta 一款由美国Terracotta公司开发的著名开源Java集群平台。它在JVM与Java应用之间实现了一个专门处理集群功能的抽象层，允许用户在不改变系统代码的情况下实现java应用的集群。支持数据的持久化、session的复制以及高可用(HA)。","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.ice5.vip/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.ice5.vip/tags/Nginx/"},{"name":"uWSGI","slug":"uWSGI","permalink":"https://www.ice5.vip/tags/uWSGI/"}]},{"title":"MySQL基础知识","slug":"MySQL","date":"2018-12-03T12:28:45.599Z","updated":"2018-12-03T12:28:45.603Z","comments":true,"path":"/MySQL/","link":"","permalink":"https://www.ice5.vip/MySQL/","excerpt":"MySQL是一种关系数据库管理系统，关系数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。Linux作为操作系统，Apache 或Nginx作为 Web 服务器，MySQL 作为数据库，PHP/Perl/Python作为服务器端脚本解释器。由于这四个软件都是免费或开放源码软件（FLOSS)，因此使用这种方式不用花一分钱（除开人工成本）就可以建立起一个稳定、免费的网站系统，被业界称为“LAMP“或“LNMP”组合。","text":"MySQL是一种关系数据库管理系统，关系数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。Linux作为操作系统，Apache 或Nginx作为 Web 服务器，MySQL 作为数据库，PHP/Perl/Python作为服务器端脚本解释器。由于这四个软件都是免费或开放源码软件（FLOSS)，因此使用这种方式不用花一分钱（除开人工成本）就可以建立起一个稳定、免费的网站系统，被业界称为“LAMP“或“LNMP”组合。 一、 Mysql简单认识1.1 数据（Data）的概念123数据是用来描述事物的符号记录,它既可以是数字,也可以是文字、图片、图像、声音等,数据的表现形式多种多样,但它们都可以经过数字化之后存入计算机。&lt;!-- eg --&gt;Luffu,male,18,ONE-PIECE 1.2 数据库（DataBase）的概念1数据库是以某种有组织方式存储的数据集合,即保存有组织的数据的容器(通常是一个文件或者一组文件);可将其想象成一个文件柜,此文件柜是存放数据(不管数据是什么以及如何组织)的物理位置(计算机的存储设备上)。 12&lt;!--注意概念的混淆--&gt;数据库这个属于并不是人们通常使用的数据库软件,数据库软件应称为DBMS(数据库管理系统)。 1.3 表（table）123某种特定类型数据的结构化清单。&lt;!-- 理解 --&gt;存储在表中的数据是一种类型的数据或者一个清单 12&lt;!-- 表名的唯一性 --&gt;表明一般是用来标识自己的,其唯一性取决于多方面,可以是数据库名和表明的结合;虽然在同一个数据库中不能命名两个同样的表明,但是在不同的数据库中却可以使用相同的表明。 1.4 记录1234&lt;!-- 列 --&gt;表中的一个字段,所有的表都是由一个或者多个列组成的,每个列都应该有相应的数据类型(datatype)。&lt;!-- 分解数据 --&gt;可以将多个不同的数据分解成不同的列,这样更易于区分,也有利于对数据的筛选和处理 1234&lt;!-- 行 --&gt;表中的一条记录,经常有人将行(row)称作数据库记录(record),通常来说,这俩术语是可以通用的;但从计数上来说,行才是其正确的术语。&lt;!-- 数据存储 --&gt;表中的数据都是按行存储的,所保存的每个记录存储在自己的行内。 1.5 主键（primary key）123456789一列(或一组列),其值能够唯一的区分表中的每个行;每一行都应该有可以唯一标识自己的一列(或一组列),唯一标识表中每行的这个列(或这组列)称为主键&lt;!-- 主键规则 --&gt;a.任意两行都不具有相同的主键值;b.每个行都必须具有一个主键值(主键列不允许有 NULL 值)。&lt;!-- 选择主键的好习惯 --&gt;a.不更新主键列中的值;b.不重用主键列的值;c.不在逐渐列中使用可能会更改的值 1.6 数据库服务器、数据库管理系统、数据库、表与记录的关系(重点在于理解) 数据库服务器：计算机(对内存要求较高) 数据库管理系统：如MySQL、Oracle、SQLite、Access、MS SQL Server (一个软件) 数据库：product（即文件夹） 表：product_list（文件夹当中的文件） 记录：1 《MySQL必知必会》978-7-115-19112-0 39 （由多个字段组成的信息,即文件中的一行内容） 12345&lt;!-- 总结 --&gt;数据库服务器：运行数据库管理软件数据库管理系统：管理数据库的软件数据库：即文件夹,用来组织文件/表表：即文件,用来存放多行内容/多条记录 2 SQL的概念12&lt;!-- Structured Query Language --&gt;SQL是结构化的查询语言,是一种专门用来与数据库通信的语言。 1234&lt;!-- SQL优点 --&gt;a.不是某个特定供应商专有语言,几乎所有的数据库都适用;b.由描述性很强的英语单词组成,简单易学;c.看上去简单,实际上是一种强有力的语言,灵活使用,可进行非常复杂和高级的数据库操作。 二、 Mysql基础操作1 连接MySQL12345&lt;!--需要信息--&gt;a.主机名（计算机名）,若连接的是本地 MySQL 服务器,为 localhost;b.端口（如果使用默认端口3306之外的端口）;c.合法的用户名d.用户口令（非必须） 2 选择数据库1234&lt;!--use关键字--&gt;use 库名;&lt;!--注意--&gt;一定要加英文状态下的分号,否则进不去,因为在 MySQL 中是用分号来表示结束的 3 常用数据库和表的SQL 语句 SQL语句 解释 showdatabases; 显示数据库名称 show create database 库名; 显示特定数据库的结构以及基本信息 show tables; 获得数据库中的所有表的列表 show create table 表名; 显示特定表的结构以及基本信息 describe 表名(简写成desc 表名); 对每个字段返回一行,行中包括字段名、数据类型、是否允许NULL等信息 show columns from 表名; desc 表名的另一种写法 ———————————————- —————————————————————————————————– show status; 显示广泛的服务器状态信息 show grant; 显示授予用户的安全权限 show error; 显示服务器错误 show warnings; 显示服务器警告 三、 检索数据1 select语句 select语句 解释 select * from 表名; 检索所有的列 select column from 表名; 从表中检索出单个列 select column1,column2 from 表名; 从表中检索出多个列 ——————————————————————– ——————————————————————- select distinct row from 表名; 从表中检索出不同的行 select * from 表名 limit 5; 检索单个列,且只从表开始部分检索出5条数据 select * from 表名 limit 5,5; 表示从表中第五行开始检索出5行的记录 select * from 表名 limit 5 offset 3; 表示从第3行开始去3条记录 select 表名.column from 表名; 从指定的表名中检索出指定的列数据 12345&lt;!--注意--&gt;a.SQL 语句不区分大小写,但是对于 SQL 关键字使用大写,对所有列和表名使用小写,可以是代码易于阅读。b.选择多个列时,注意在列名之间加上逗号,但最后一个列名不加逗号。c.通配符 * 不要随意使用,严重降低检索效率。d.行0检索出来的是第一行而不是行1,所以 limit 1,将检索出第二行而不是第一行,若行数不够则只能返回能得到的行数。 2 排序检索数据1234&lt;!--子句的概念--&gt;SQL语句是由子句构成的,通常由关键字和所提供的数据组成的,有些子句是必须的,有些子句是可选的。&lt;!--排序的子句--&gt;order by:只能位于 from 子句之后,但是在limit之前。 SQL语句 解释 select pro_name from products order by pro_name; 从表products中选取pro_name这一列并按照pro_name排序 select pro_id,pro_name,pro_price from products order by pro_price,pro_name; 从表中选择数据并按照价格姓名排序,若在价格相同的情况下,继续使用姓名排序。 select pro_price from products order by pro_price desc; 从表中检索出数据并按照价格降序进行排序 select pro_price from products order by pro_price asc; 从表中检索出数据并按照价格升序进行排序,一般默认情况就是升序。 12&lt;!--多个列上进行降序排列--&gt;desc只直接作用于其前面的列,若想在多个列上进行降序排序,必须对每个列指定desc关键字。 3 过滤数据123456&lt;!-- where --&gt;只返回指定条件的记录&lt;!-- between ... and ... --&gt;只返回范围内的开始值和结束值(不包括开头和结尾)&lt;!-- 空值 --&gt;NULL:无值,它与字段中包含0,空字符串、或仅仅包含空格不同。 SQL语句 解释 select * from products where id=2; 从表中检索出id=2的记录 select * from poducts where id between 5 and 10; 从表中检索出id在5-10之间的记录 select * from products where email is null; 从表中检索出email是空值的记录 4 数据过滤升级12345678910111213&lt;!-- 操作符 --&gt;用来联结或改变where子句中的子句关键字。&lt;!-- and --&gt;用在where子句中的关键字,用来只是检索满足所有给定条件的行。&lt;!-- or --&gt;用在where子句中的关键字,用来表示检索匹配任一给定条件的行。&lt;!-- in --&gt;where子句中用来指定要匹配值的清单的关键字,功能与or相当。&lt;!-- not --&gt;where子句中用来否定后跟条件的关键字。&lt;!-- and和or的优先级 --&gt;在and和or同时使用时,and的优先级高于or,若想检索出的结果不被打乱,可以加上括号。 SQL语句 解释 select * from products where id=2 and price=123; 检索出同时是id=2和price=123的记录 select * from products where id=2 or price=123; 检索出id=2或者price=123的记录 select pro_name from products where id in (1,2,3,4,5); 检索出id在1-5范围内的pro_name select pro_name from products where id not in (1,2,3,4,5); 检索出id不在1-5范围内的pro_name 5 用通配符进行过滤123456&lt;!--通配符--&gt;用来匹配值的一部分的特殊字符&lt;!--搜索模式--&gt;由字面值、通配符或者两者组合构成的搜索条件&lt;!--注意--&gt;通配符的位置会影响到结果,使用时应注意通配符的位置 通配符 解释 like 严格意义上like是谓词,而不是操作符 % 可以匹配多个任意字符,根据位置不同而不同 _ 可以匹配单个任意字符 6 正则12&lt;!-- 写法 --&gt;select sth from table where sth REGEXP '正则表达式' order by sth; 12345678910&lt;!-- LIKE与REGEXP的区别 --&gt;LIKE匹配整个列,若匹配的文本在列中,LIKE不会找到它,所以就不会有结果返回;REGEXP在列之内进行匹配,若被匹配的文本在列值中出现,REGEXP将会找到并返回这个文本。&lt;!-- '1|2 3'和'[12] 3'的区别 --&gt;'1|2 3' 表示的是匹配 '1' 或者 '2 3';'[12] 3' 表示的是匹配 '1 3' 或者 '2 3'&lt;!-- MySQL中的转义符与其他正则表达式中的转义符 --&gt;MySQL中需要使用两个 \\\\ 来表示转义符,如 \\\\- 表示 - , \\\\. 表示 . ;其他正则表示是用 \\ 来表示转义符。 四、 字段1 字段1234567891011121314&lt;!-- 字段 --&gt;与列的意思基本上相同,不过数据库列一般称为列,而术语字段通常用在计算字段连接上。&lt;!-- 拼接 --&gt;将值联结到一起构成单个值。&lt;!-- MySQL的不同之处 --&gt;多数的DBMS使用 + 或 || 实现字符串拼接,而MySQL是使用Concat()函数来实现。当将SQL语句转成MySQL时需要注意。&lt;!-- Trim()函数 --&gt;去掉两边的空格&lt;!-- 使用别名 --&gt;在实际的表列明包含不符合规定的字符时重新命名它。 五、 聚合函数1 聚合函数12345&lt;!-- 聚合函数 --&gt;运行在行组上,计算和返回单个值的函数。&lt;!-- 列值为NULL的行 --&gt;函数将忽略列值为NULL的行 函数 说明 avg() 返回某列的平均值,若需要多个列的平均值,需要多个avg()函数 count() 返回某列的行数 max() 返回某列的最大值 min() 返回某列的最小值 sum() 返回某列值之和 123&lt;!-- 聚集不同的值 DISTINCT --&gt;a.指定列名,则distinct只能用于count()。distinct不能用于count(*) ,因此不允许使用count(distinct),否则产生错误。b.将distinct用于max()和min()从技术上可用,但是没有实际价值。 12&lt;!-- 组合聚合函数 --&gt;可以同时使用多个聚合函数。 六、 数据分组1 创建分组1234&lt;!-- group by的规定 --&gt;a.group by子句可以包含任意数目的列,可以对分组进行嵌套,为数据分组提供更细致的控制。b.若在group by子句中潜逃了分组,数据将在最后规定的分组上进行汇总。c.group by子句中的每个列都必须是检索列或者有效的表达式(不能是聚合函数)。 2 过滤分组123&lt;!-- having与where的区别 --&gt;where:在数据分组前进行过滤,过滤的是行;having:在数据分组之后进行过滤,过滤的是分组。 3 分组和排序 order by group by 排序产生的输出 分组行,输出的可能不是分组的顺序 任意列都可使用 只可使用选择列或表达式列,而且必须使用每个选择列表达式。 不一定需要 若与聚合函数配合使用,则必须使用 七、 关键词执行顺序汇总 子句 说明 是否必要 select 返回的列或者表达式 √ distinct 去除重复的值 × from 从中检索数据的表 仅在从表中选择数据是使用 where 行级过滤 × group by 分组的说明 仅在按组计算聚合时使用 having 组级过滤 × order by 输出的顺序排序 × limit 需要检索出的具体行数 × 八、 子查询和组合查询1 子查询123456789101112&lt;!-- 子查询 --&gt;将一条select语句的执行结果用于另一条select语句的whereas子句&lt;!-- 注意 --&gt;使用子查询时,列必须匹配。在where子句中使用子查询,应保证select语句具有与where子句中相同数目的列。&lt;!-- 相关子查询 --&gt;涉及外部查询的子查询;如 where table1.id = table2.new_id;&lt;!-- 操作符 --&gt;in = !=select c_name where c_id in (select c_id from table1 where c_id != 0) from table2 roder by c_name; 2 组合查询12345678910111213141516171819202122232425&lt;!-- 组合查询的使用 --&gt;a.在单个查询中从不同的表返回类似结构的数据;b.对单个表执行多个查询,按单个查询返回数据。&lt;!-- union规则 --&gt;a.union必须由两条或者两条以上的select语句组成,语句间用关键字union分隔。b.union中的每个查询必须包含相同列、表达式或聚合函数。c.类数据类型必须兼容：类型不必完全相同,但必须是DBMS可以隐含地转换的类型。&lt;!-- 使用union --&gt;给出每条select语句,在语句之间放上关键字unionselect c_name from table1 where c_id&gt;0;select p_name from table2 where p_id between 5 and 10;select c_name from table1 where c_id&gt;0unionselect p_name from table2 where p_id between 5 and 10;&lt;!-- 包含或取消重复的行 --&gt;可以使用union all来显示出所有的行&lt;!-- 对组合查询结果排序 --&gt;使用union查询时,只能使用一条order by子句,且必须出现在最后一条select语句之后。 九、 联结表和创建高级联结1 联结12345&lt;!-- 外键 --&gt;外键为某个表中的一列,包含另外一个表的主键值,定义了两个表之间的关系。&lt;!-- 可伸缩性 --&gt;能够适应不断增加的工作量而不失败,设计良好的数据库或应用程序称之为可伸缩性好。 12345&lt;!-- 创建联结 --&gt;select c_name,c_addr,p_name from customer,product where customer.c_id = products.p_id;&lt;!-- 内部联结 --&gt;select c_name,p_name,p_price from customer inner join products on customer.c_id = products.p_id; 2 高级联结1234567891011121314&lt;!-- 自联结 --&gt;自联结通常作为外部语句用来替代从相同表中检索数据时使用的子查询语句。子查询解决方案:select p_name from products where c_id in (select c_id from customer where p_id=10);联结查询:select p.p_name from customer as c,products as p where p.p_id = c.c_id and c.c_id=10;&lt;!-- 自然联结 --&gt;无论何时对表进行联结,应至少有一个列出现在不知一个表中(被联结的列)。&lt;!-- 外部联结 --&gt;将一个表中的行与另外一个表中的行相关联,包含没有关联行的那些行。语法与内部联结相似,left outer join 或者 right outer join&lt;!-- 带有聚合函数的联结 --&gt;select c.c_name,c.c_id count(o.order_num) as num_ord from customer as c inner join orders as o on c.c_id = o.c_id; 十、 数据操作1 插入数据1234&lt;!-- 插入数据 --&gt;a.insert into tablename values (value1,value2,...)b.insert into tablename(字段1,字段2,...) values (value1,value2,...)a 的语法虽然简单但是不安全,应尽量避免使用。b 的语法复杂但是更安全,且不用根据表结构来插入数据了。 2 更新数据12345678&lt;!-- 更新数据 --&gt;update tablename set 字段名1 = value1, [字段名2 = value2, ... ] where 字段名 = value;&lt;!-- 注意 --&gt;使用update时应该配合使用where语句,若没有where语句,MySQL将会更细心表中的所有数据。 3 删除数据123456789&lt;!-- 删除数据 --&gt;delete from tablename where 字段名 = value;&lt;!-- 注意 --&gt;delete删除的是行使用delete时应该配合使用where语句,若没有where语句,MySQL将会更细心表中的所有数据。&lt;!-- 快速的删除所有行 --&gt;使用truncate table,实际上是删除原来的表并重新创建一个表,而不是逐行的删除数据。 十一、 表操作1 创建表123456&lt;!-- 创建表 --&gt;create table tablename[if not exists]( id int primary_key auto_increment, name varchar(32) not null, password varchar(64) nul null default=\"123\", ) ENGINE = InnoDB; 1234567&lt;!-- 需要知道的引擎 --&gt;InnoDB:可靠地事物处理引擎,不支持全文本搜索;MEMORY:功能等同于MyISAM,由于数据存储在内存中,速度很快,但是断电就丢失(适合用于临时表);MyISAM:性能极高,支持全文本搜索,但不支持事物处理。&lt;!-- 注意 --&gt;外键不能跨引擎,混用引擎有缺陷,外键不能跨引擎,即一个使用引擎的表不能引用具有不同引擎的表的外键。 2 更新表1234567891011&lt;!-- 添加列 --&gt;alter table tablename add 字段1 类型 [,字段2 类型] ...&lt;!-- 删除列 --&gt;alter table tablename drop column 字段;&lt;!-- alter table常见用途 --&gt;用来定义外键,alter table talbename add constraint fk_tablename1_tablename2 foreign key (tablename2的字段id) refernces tablename2的字段 (tablename2的字段id)alter table orderitems add constraint fk_orderitems_orders foreign key (order_num) references orders(order_num); 3 删除表12&lt;!-- 删除表 --&gt;drop table tablename; 4 重命名表12&lt;!-- 重命名表 --&gt;rename table oldtablename to newtablename; 十二、 视图1 视图1234567891011121314151617181920212223242526272829&lt;!-- 视图 --&gt;视图是一个虚拟的表,与包含数据的表是不一样的,视图只包含使用时动态检索数据的查询。所以,对视图进行增加或者删除操作,实际上是对其基表进行增加或者删除。但是视图一般都是用来检索,而不是用来更新。&lt;!-- 视图的常见应用 --&gt;a.重用SQL语句b.简化复杂的SQL操作。即编写查询之后,可以更方便的重用它而了解它的基本查询细节c.使用的是表的组成部分而不是整个表d.保护数据,可以给用户授予表的特定部分的访问权限而不是整个表的访问权限e.更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。&lt;!--视图的使用--&gt;创建视图：create view viewname as select ... ;查看视图：show create view viewname;更新视图：create or replace view; 或者先 drop 再 create删除视图：drop view viewname;&lt;!-- 更新视图的注意点 --&gt;并非所有的视图都是可以更新的。若MySQL不能准确地确定被更新的 基数据,则不允许更新。则视图定义中有一下操作时,不能进行视图更新：a.分组(group by 和 having)b.联结c.子查询d.并e.聚合函数f.distinctg.导出列上述的限制只限于MySQL5以前,之后可能会更改。 十三、 游标1 游标12345678&lt;!-- 使用游标注意事项 --&gt;游标只能用于存储过程。不像多数DBMS,MySQL游标只能使用于存储过程和函数。&lt;!-- 使用游标的步骤 --&gt;a.先声明(定义)游标,这个过程并没有检索数据,只是定义了使用的SELECT语句。b.打开游标以供使用。这个过程将定义的SELECT语句将数据检索出来。c.对于填有数据的游标,根据需要检索各行。d.结束游标使用时,关闭游标。 2 使用游标2.1 创建游标123456789CREATE PROCEDURE processorders()BEGIN DECLARE ordernumbers CURSOR &lt;!--declare命名游标--&gt; FOR SELECT order_num FROM orders;END;&lt;!-- 注意 --&gt;存储过程处理完成之后,游标就会消失。 2.2 打开和关闭游标1234&lt;!-- 打开 --&gt;OPEN ordernumbers;&lt;!-- 关闭 --&gt;CLOSE ordernumbers; &lt;!--关闭所有内部内存和资源--&gt; 2.3 使用游标数据12345678910111213141516171819202122232425262728293031CREATE PROCEDURE processorder()BEGIN &lt;!--Declare local variable--&gt; DECLARE ordernumers CURSOR DECLARE done BOOLEAN DEFAULT 0; DECLARE o INT; DECLARE t DECIMAL(8,2); &lt;!--Declare the cursor--&gt; DECLARE ordernumbers CURSOR FOR SELECT order_num FORM orders; &lt;!--Declare continue handler--&gt; DECLARE CONTINUE HANDLER FOR SQLSTATE '02000' SET done=1; &lt;!--循环的结束条件--&gt; &lt;!--Create a table to store the results--&gt; CREATE TABLE IF NOT EXISTS ordertotals (order_num INT, total DECIMAL(8,2)); &lt;!--Open the cursor--&gt; OPEN ordernumbers; &lt;!--Loop through all rows--&gt; REPEAT &lt;!--Get order number--&gt; FETCH ordernumvers INTO O; &lt;!--使用fetch检索order_num直至done为真--&gt; &lt;!--Get the total for this order--&gt; CALL ordertotal(o, 1, t); &lt;!--Insert order and total into ordertotals--&gt; INSERT INTO ordertotals(order_num, total) VALUES(o, t); &lt;!--End of loop--&gt; UNTIL done END REPEAT; &lt;!--Close the cursor--&gt; CLOSE ordernumbers;END; 十五、 触发器1 触发器1234567&lt;!-- 触发器 --&gt;在某个表发生变化时另一个表更改时自动处理&lt;!-- 支持语句 --&gt;DELETEINSERTUPDATE其他语句不支持触发器 2 创建触发器12345678&lt;!-- 指定条件 --&gt;a.唯一的触发器名b.触发器关联的表c.触发器应该相应的活动d.触发器何时执行&lt;!-- 语法 --&gt;CREATE TRIGGER newproduct AFTER INSERT ON products FOR EACH ROW SELECT 'Product added';&lt;!-- 触发器支持的只有表,视图不支持 --&gt; 3 删除触发器12&lt;!-- 删除触发器 --&gt;DROP TRIGGER newproduct; 4 INSERT 触发器1CREATE TRIGGER neworder AFTER INSERT ON orders FOR EACH ROW SELECT NEW.order_num; 5 DELETE 触发器12345CREATE TRIGGER deleteorder BEFORE DELETE ON orders FOR EACH ROWBEGIN INSERT INTO archive_orders(order_num, order_date, cust_id) VALUES(OLD.order_num, OLD.order_date, OLD.CUST_ID);END; 6 UPDATE 触发器12CREATE TRIGGER updatevendor BEFORE UPDATE ON vendorsFOR EACH ROW SET.vend_state = Upper(NEW.vend_state); 十六、 事物处理1 事物处理12345678&lt;!-- 事物处理 --&gt;可以用于维护数据库的完整性,即保证同一批次的MySQL操作要么全部操作成功,要么全部操作失败。&lt;!-- 事物处理的几个术语 --&gt;事物(transaction):指的是一组SQL语句;回退(rollback):指的是撤销指定SQL语句的过程;提交(commit):将未存储的SQL语句结果写入数据库表;保留点(savepoint):指事物处理中设置的临时占位符(place-holder),可以对这一操作进行回退。 2 控制事物处理12&lt;!-- 标识事物开始 --&gt;START TRANSACTION 12345678910111213141516&lt;!-- 使用ROLLBACK --&gt;SELECT * FROM ordertotals; &lt;!--显示记录--&gt;START TRANSACTION; &lt;!--开始事物--&gt;DELETE FROM ordertotals; &lt;!--删除记录--&gt;SELECT * FROM ordertotals; &lt;!--显示空的记录表--&gt;ROLLBACK; &lt;!--事物回退--&gt;SELECT * FROM ordertotals; &lt;!--重新显示记录--&gt;&lt;!-- 可以回退的SQL语句 --&gt;INSERTUPDATEDELETE&lt;!-- 不能回退的SQL语句 --&gt;SELECTCREATEDROP 1234567891011MySQL中的SQL语句都是针对数据库表执行和表写的,一般都是隐含提交(implicit commit)。即提交操作自动进行。但是在事物处理中,提交并不会自动执行,所以就需要用到 COMMIT 语句。&lt;!-- 使用COMMIT --&gt;START TRANSACTION;DELETE FROM orderitems WHERE order_num = 10000; &lt;!--删除记录--&gt;DELETE FROM orders WHERE order_num=10000; &lt;!--若上一条记录删除失败,则不会执行COMMIT操作--&gt;COMMIT;&lt;!-- 更改默认的提交行为 --&gt;SET autocommit=0;autocommit针对的是每个连接而不是服务器。 12345678&lt;!-- 使用保留点 --&gt;可以支持回到部分事物处理SAVEPOINT delete1; &lt;!--保留点应取唯一名字--&gt;ROLLBACK TO delete1;&lt;!-- 释放保留点 --&gt;MySQL5之后支持释放保留点RELEASE SAVEPOINT 十七、 存储过程1 使用存储过程的原因1234567891011&lt;!-- 原因 --&gt;优点：a.将接口封装在易于使用的单元中,简化复杂的操作。b.不要求反复建立一系列处理步骤,保证了数据的安全性。因为程序执行的步骤越多,出错的概率也就越大。c.简化对变动的管理。即安全性。d.提高性能。使用存储过程比使用单独的SQL语句要快。e.存在只能用在单个请求中的MySQL元素和特性,存储过程即可以使用他们来编写功能更强更灵活的代码。总结上述：即简单、安全、高性能。缺点：a.编写比SQL语句复杂。b.没有创建存储过程的安全访问权限。 2 存储过程的使用2.1 创建存储过程1234567891011121314&lt;!-- 临时更改MySQL命令行客户机的分隔符 --&gt;DELEMITER // &lt;!--告诉程序使用 // 作为临时结束分隔符--&gt;CREATE PROCEDURE productpricing()BEGIN SELECT Avg(prod_price) AS priceaverage FROM productsEND // &lt;!--标志存储过程结束--&gt;DELIMITER ; &lt;!--恢复原来的分隔符--&gt;&lt;!-- 注意 --&gt;\\ 符号不能作为语句分隔符,其余均可。&lt;!-- 使用存储过程 --&gt;CALL productpricing() 2.2 删除存储过程1234DROP PROCEDURE productpricing;&lt;!-- 注意 --&gt;a.后边没有使用 ()b.过程不存在,则会报错;可使用DROP PROCEDURE IF EXISTS productpricing 2.3 配合参数使用123456789101112131415161718&lt;!-- 创建 --&gt;CREATE PROCEDURE productpricing( OUT pl DECIMAL(8,2), &lt;!--out关键字指出相应参数用来从存储过程传出值给调用者,IN表示传递给存储过程--&gt; OUT ph DECIMAL(8,2), &lt;!--INOUT表示对存储过程传入和传出--&gt; OUT pa DECIMAL(8,2), &lt;!--DECIMAL为数据类型--&gt;)BEGIN SELECT Min(prod_price) INTO pl from products; &lt;!--存储过程代码位于begin与end之间--&gt; SELECT Max(prod_price) INTO ph from products; &lt;!--通过INTO关键字保存至相应的变量--&gt; SELECT Avg(prod_price) INTO pa from products;END;&lt;!-- 使用 --&gt;CALL productpricing(@pricelow, @pricehigh, @priceaverage);这条语句并不会显示任何数据。仅仅是返回以后可以显示的变量;若想要显示数据,可以使用一下语句：SELECT @pricehigh, @pricelow, @priceaverage; 2.4 检查存储过程123SHOW CREATE PROCEDURE ordertotal; &lt;!--显示传建一个存储过程的create语句--&gt;SHOW PROCEDURE STATUS; &lt;!--显示何时、有谁创建等详细信息的存储过程--&gt;SHOW PROCEDURE STATUS LIKE 'ORDERTOTAL'; &lt;!--过滤模式--&gt;","categories":[{"name":"Database","slug":"Database","permalink":"https://www.ice5.vip/categories/Database/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.ice5.vip/tags/MySQL/"},{"name":"sql","slug":"sql","permalink":"https://www.ice5.vip/tags/sql/"}]},{"title":"并发编程之多进程","slug":"并发编程之多进程","date":"2018-12-03T10:47:28.224Z","updated":"2018-12-07T16:17:16.273Z","comments":true,"path":"/并发编程之多进程/","link":"","permalink":"https://www.ice5.vip/并发编程之多进程/","excerpt":"进程简单点说就是一个正在执行的过程。进程是对所有程序中正在运行的程序的一个抽象。进程的概念起源于操作系统，是操作系统最核心的概念，也是操作系统提供的最古老也是最重要的抽象概念之一。操作系统的其他所有内容都是围绕进程的概念展开的。若想要真正了解进程，则必须事先了解操作系统。","text":"进程简单点说就是一个正在执行的过程。进程是对所有程序中正在运行的程序的一个抽象。进程的概念起源于操作系统，是操作系统最核心的概念，也是操作系统提供的最古老也是最重要的抽象概念之一。操作系统的其他所有内容都是围绕进程的概念展开的。若想要真正了解进程，则必须事先了解操作系统。 一、多进程理论基础1.进程的概念正在进行的一个过程或者说一个任务。而负责执行任务则是CPU。 2.进程与程序的区别进程指的是程序的运行过程，程序仅仅只是一堆代码 需要强调的是：同一个程序执行两次，那也是两个进程，比如打开QQ，虽然都是同一个软件，但是一个可以登录248369的账号，一个可以登录13579的账号 3.并发与并行 不管是并行还是并发，在用户看来程序都是”同时”运行的。不管是进程还是线程，都只是一个任务而已，真是干活的是CPU，CPU来做这些任务，而一个CPU同一时刻只能执行一个任务。 并发：是伪并行，即看起来是同时运行。单个CPU &amp; 多道技术就可以实现并发，（并行也属于并发） 并行：同时运行，只有具备多个CPU才能实现并行 单核下，可以利用多道技术，多个核，每个核也都可以利用多道技术（多道技术[^1]是针对单核而言的） 有四个核，六个任务，这样同一时间有四个任务被执行，假设分别被分配给了CPU1，CPU2，CPU3，CPU4，一旦任务1遇到I/O就被迫中断执行，此时任务5就拿到CPU1的时间片去执行，这就是单核下的多道技术，而一旦任务1的I/O结束了，操作系统会重新调用它(需知进程的调度、分配给哪个CPU运行，由操作系统说了算)，可能被分配给四个CPU中的任意一个去执行 4.同步/异步 &amp;阻塞/非阻塞4.1.同步 所谓同步，就是在发出一个功能调用时，在没有得到结果之前，该调用就不会返回。按照这个定义，其实绝大多数函数都是同步调用。但是一般而言，我们在说同步、异步的时候，特指那些需要其他部件协作或者需要一定时间完成的任务。 1234# 举例：1. multiprocessing.Pool下的apply # 发起同步调用后，就在原地等着任务结束，根本不考虑任务是在计算还是在io阻塞，总之就是一股脑地等任务结束2. concurrent.futures.ProcessPoolExecutor().submit(func,).result()3. concurrent.futures.ThreadPoolExecutor().submit(func,).result() 4.2.异步 异步的概念和同步相对。当一个异步功能调用发出后，调用者不能立刻得到结果。当该异步功能完成后，通过状态、通知或回调来通知调用者。如果异步功能用状态来通知，那么调用者就需要每隔一定时间检查一次，效率就很低（有些初学多线程编程的人，总喜欢用一个循环去检查某个变量的值，这其实是一 种很严重的错误）。如果是使用通知的方式，效率则很高，因为异步功能几乎不需要做额外的操作。至于回调函数，其实和通知没太多区别。 1234#举例：1. multiprocessing.Pool().apply_async() #发起异步调用后，并不会等待任务结束才返回，相反，会立即获取一个临时结果（并不是最终的结果，可能是封装好的一个对象）。2. concurrent.futures.ProcessPoolExecutor(3).submit(func,)3. concurrent.futures.ThreadPoolExecutor(3).submit(func,) 4.3.阻塞 阻塞调用是指调用结果返回之前，当前线程会被挂起（如遇到IO操作）。函数只有在得到结果之后才会将阻塞的线程激活。有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回而已。 123#举例：1. 同步调用：apply一个累计1亿次的任务，该调用会一直等待，直到任务返回结果为止，但并未阻塞住（即便是被抢走cpu的执行权限，那也是处于就绪态）;2. 阻塞调用：当socket工作在阻塞模式的时候，如果没有数据的情况下调用recv函数，则当前线程就会被挂起，直到有数据为止。 4.4.非阻塞 非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前也会立刻返回，同时该函数不会阻塞当前线程。 4.5 总结 同步与异步针对的是函数/任务的调用方式：同步就是当一个进程发起一个函数（任务）调用的时候，一直等到函数（任务）完成，而进程继续处于激活状态。而异步情况下是当一个进程发起一个函数（任务）调用的时候，不会等函数返回，而是继续往下执行当，函数返回的时候通过状态、通知、事件等方式通知进程任务完成。 阻塞与非阻塞针对的是进程或线程：阻塞是当请求不能满足的时候就将进程挂起，而非阻塞则不会阻塞当前进程 5.进程的创建与终止5.1 创建 但凡是硬件，都需要有操作系统去管理，只要有操作系统，就有进程的概念，就需要有创建进程的方式，一些操作系统只为一个应用程序设计，比如微波炉中的控制器，一旦启动微波炉，所有的进程都已经存在。而对于通用系统（跑很多应用程序），需要有系统运行过程中创建或撤销进程的能力，主要分为4中形式创建新的进程 1. 系统初始化（查看进程Linux中用ps命令，windows中用任务管理器，前台进程负责与用户交互，后台运行的进程与用户无关，运行在后台并且只在需要时才唤醒的进程，称为守护进程，如电子邮件、web页面、新闻、打印） 2. 一个进程在运行过程中开启了子进程（如nginx开启多进程，os.fork,subprocess.Popen等） 3. 用户的交互式请求，而创建一个新进程（如用户双击暴风影音） 4. 一个批处理作业的初始化（只在大型机的批处理系统中应用） 无论哪一种，新进程的创建都是由一个已经存在的进程执行了一个用于创建进程的系统调用而创建的： 1. 在UNIX中该系统调用是：fork，fork会创建一个与父进程一模一样的副本，二者有相同的存储映像、同样的环境字符串和同样的打开文件（在shell解释器进程中，执行一个命令就会创建一个子进程） 2. 在windows中该系统调用是：CreateProcess，CreateProcess既处理进程的创建，也负责把正确的程序装入新进程。 关于创建的子进程，UNIX和windows 1.相同的是：进程创建后，父进程和子进程有各自不同的地址空间（多道技术要求物理层面实现进程之间内存的隔离），任何一个进程的在其地址空间中的修改都不会影响到另外一个进程。 2.不同的是：在UNIX中，子进程的初始地址空间是父进程的一个副本，提示：子进程和父进程是可以有只读的共享内存区的。但是对于windows系统来说，从一开始父进程与子进程的地址空间就是不同的。 5.2 终止 正常退出（自愿，如用户点击交互式页面的叉号，或程序执行完毕调用发起系统调用正常退出，在Linux中用exit，在windows中用ExitProcess） 2. 出错退出（自愿，python a.py中a.py不存在） 3. 严重错误（非自愿，执行非法指令，如引用不存在的内存，1/0等，可以捕捉异常，try…except…） 4. 被其他进程杀死（非自愿，如kill -9） 6.进程的层次结构无论UNIX还是windows，进程只有一个父进程，不同的是： 1. 在UNIX中所有的进程，都是以init进程为根，组成树形结构。父子进程共同组成一个进程组，这样，当从键盘发出一个信号时，该信号被送给当前与键盘相关的进程组中的所有成员。 2. 在windows中，没有进程层次的概念，所有的进程都是地位相同的，唯一类似于进程层次的暗示，是在创建进程时，父进程得到一个特别的令牌（称为句柄）,该句柄可以用来控制子进程，但是父进程有权把该句柄传给其他子进程，这样就没有层次了。 7.进程的状态1tail -f access.log |grep '404' 执行程序tail，开启一个子进程，执行程序grep，开启另外一个子进程，两个进程之间基于管道’|’通讯，将tail的结果作为grep的输入。 进程grep在等待输入（即I/O）时的状态称为阻塞，此时grep命令都无法运行 其实在两种情况下会导致一个进程在逻辑上不能运行， 1. 进程挂起是自身原因，遇到I/O阻塞，便要让出CPU让其他进程去执行，这样保证CPU一直在工作 2. 与进程无关，是操作系统层面，可能会因为一个进程占用时间过多，或者优先级等原因，而调用其他的进程去使用CPU。 8.进程并发的实现进程并发的实现在于，硬件中断一个正在运行的进程，把此时进程运行的所有状态保存下来，为此，操作系统维护一张表格，即进程表（process table），每个进程占用一个进程表项（这些表项也称为进程控制块）。 该表存放了进程状态的重要信息：程序计数器、堆栈指针、内存分配状况、所有打开文件的状态、帐号和调度信息，以及其他在进程由运行态转为就绪态或阻塞态时，必须保存的信息，从而保证该进程在再次启动时，就像从未被中断过一样。 9.僵尸进程与孤儿进程 僵尸进程(有害)：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。详解如下 在Unix/Linux中，正常情况下子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程到底什么时候结束，如果子进程一结束就立刻回收其全部资源，那么在父进程内将无法获取子进程的状态信息。 因此，UNⅨ提供了一种机制可以保证父进程可以在任意时刻获取子进程结束时的状态信息： 在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。但是仍然为其保留一定的信息（包括进程号the process ID，退出状态the termination status of the process，运行时间the amount of CPU time taken by the process等） 直到父进程通过wait / waitpid来取时才释放. 但这样就导致了问题，如果进程不调用wait / waitpid的话，那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。 任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。这是每个子进程在结束时都要经过的阶段。如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。 如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。 僵尸进程危害场景： 例如有个进程，它定期的产 生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用ps命令查看的话，就会看到很多状态为Z的进程。 严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大 量僵死进程的那个元凶枪毙掉（也就是通过kill发送SIGTERM或者SIGKILL信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进 程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程 就能瞑目而去了。 孤儿进程(无害)：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上，init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤 儿进程的父进程设置为init，而init进程会循环地wait()它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。因此孤儿进程并不会有什么危害。 二、多进程的代码实现1.multiprocessing模块介绍​ 在python中多线程无法利用多核优势，如果想要充分地使用多核CPU的资源（os.cpu_count()查看），在python中大部分情况需要使用多进程。Python提供了multiprocessing。 multiprocessing模块用来开启子进程，并在子进程中执行我们定制的任务（比如函数），该模块与多线程模块threading的编程接口类似。 multiprocessing模块的功能众多：支持子进程、通信和共享数据、执行不同形式的同步，提供了Process、Queue、Pipe、Lock等组件。 ​ 强调：与线程不同，进程没有任何共享状态，进程修改的数据，改动仅限于该进程内。 2.Process类的介绍 创建进程的类 Process([group [, target [, name [, args [, kwargs]]]]])，由该类实例化得到的对象，表示一个子进程中的任务（尚未启动） 强调： 需要使用关键字的方式来指定参数 args指定的为传给target函数的位置参数，是一个元组形式，必须有逗号 参数介绍 group参数如果没有使用，值始终为None target表示调用对象，即子进程要执行的任务 args表示调用对象的位置参数元组，args=(1,) kwargs表示调用对象的字典，kwargs={‘book’:’Magic’,’Price’:99} name为子进程的名称 进程的方法介绍 1 p.start()：启动进程，并调用该子进程中的 p.run() 2 p.run():进程启动时运行的方法，正是它去调用target指定的函数，我们自定义类的类中一定要实现该方法 3 p.terminate():强制终止进程p，不会进行任何清理操作，如果p创建了子进程，该子进程就成了僵尸进程，使用该方法需要特别小心这种情况。如果p还保存了一个锁那么也将不会被释放，进而导致死锁 4 p.is_alive():如果p仍然运行，返回True 5 p.join([timeout]):主线程等待p终止（强调：是主线程处于等的状态，而p是处于运行的状态）。timeout是可选的超时时间，需要强调的是，p.join只能join住start开启的进程，而不能join住run开启的进程 进程的属性介绍 1 p.daemon：默认值为False，如果设为True，代表p为后台运行的守护进程，当p的父进程终止时，p也随之终止，并且设定为True后，p不能创建自己的新进程，必须在p.start()之前设置 2 p.name:进程的名称 3 p.pid：进程的pid 4 p.exitcode:进程在运行时为None、如果为–N，表示被信号N结束(了解即可) 5 p.authkey:进程的身份验证键,默认是由os.urandom()随机生成的32字符的字符串。这个键的用途是为涉及网络连接的底层进程间通信提供安全性，这类连接只有在具有相同的身份验证键时才能成功（了解即可） 创建进程的两种方式 注意：在windows中Process()必须放到if __name__ == &#39;__main__&#39;:下if __name__ == &quot;__main__&quot;since statements inside this if-statement will not get called upon import.由于Windows没有fork，多处理模块启动一个新的Python进程并导入调用模块。如果在导入时调用Process（），那么这将启动无限继承的新进程（或直到机器耗尽资源）。这是隐藏对Process（）内部调用的原，使用if __name__ == “__main __”，这个if语句中的语句将不会在导入时被调用。 123456789101112131415161718# 方式一import timeimport randomfrom multiprocessing import Processdef task(animal): print('%s running' %animal) time.sleep(random.randrange(1,5)) print('%s running end' %animal) # if __name__ == \"__main__\":p1=Process(target=task,args=('dog',)) p2=Process(target=task,args=('cat',))p3=Process(target=task,args=('pig',))p1.start()p2.start()p3.start()print('This is main process...') 1234567891011121314151617181920212223# 方式二import timeimport randomfrom multiprocessing import Processclass Task(Process): def __init__(self,animal): super().__init__() self.animal=animal def run(self): print('%s running' %self.animal) time.sleep(random.randrange(1,5)) print('%s running end' %self.animal) # if __name__ == \"__main__\":p1=Task('dog')p2=Task('cat')p3=Task('pig')p1.start() # start内部会自动调用runp2.start()p3.start()print('This is main process...') 进程之间的内存空间是隔离的: 123456789101112from multiprocessing import Processn=10086 # 在windows系统中应该把全局变量定义在if __name__ == '__main__'之上就可以了def work(): global n n=10000 print('子进程内: ',n)if __name__ == '__main__': p=Process(target=work) p.start() print('主进程内: ',n) Process对象的join方法 主进程等待设有join的子进程运行结束，主进程才可以继续往下执行，其它的子进程还是可以继续执行各自的任务的。 注意和串行区分开来 1234567891011121314151617from multiprocessing import Processimport timeimport randomclass Task(Process): def __init__(self,animal): self.animal=animal super().__init__() def run(self): print('%s is running' %self.animal) time.sleep(random.randrange(1,3)) print('%s running end' %self.animal)p=Task('dog')p.start()p.join(1) # 1指的是主进程等待子进程的时间，超过该时间就不继续等待了print('开始') 3.守护进程守护进程是由主进程创建的 其一：守护进程会在主进程代码执行结束后就终止 其二：守护进程内无法再开启子进程,否则抛出异常：AssertionError: daemonic processes are not allowed to have children 注意：进程之间是互相独立的，主进程代码运行结束，守护进程随即终止 1234567891011121314151617from multiprocessing import Processimport timeimport randomfrom multiprocessing import Processclass Task(Process): def __init__(self,animal): super().__init__() self.animal=animal def run(self): print('%s running' %self.animal) time.sleep(random.randrange(1,3)) print('%s running end' %self.animal)p=Task('dog')p.daemon=True #一定要在p.start()前设置,设置p为守护进程,禁止p创建子进程,并且父进程代码执行结束,p即终止运行p.start()print('main process') 4.进程同步（锁） 进程之间数据会不共享，但是可以共享同一套文件系统，所以访问同一个文件或同一个打印终端，一般没有问题，而共享带来的问题是竞争，竞争带来的结果就是错乱，这时就需要使用加锁来处理数据了。 123456789101112131415# 若不加锁则是并发运行，虽然效率高，但是使用的时候会竞争同一终端，导致打印结果错乱# 加锁之后由并发变成了串行,牺牲了运行效率,但避免了竞争from multiprocessing import Process,Lockimport os,timedef work(lock): lock.acquire() # 加锁 print('%s is running' %os.getpid()) time.sleep(1) print('%s is done' %os.getpid()) lock.release() # 释放锁if __name__ == '__main__': lock=Lock() for i in range(3): p=Process(target=work,args=(lock,)) p.start() 总结： 加锁可以保证多个进程修改同一块数据时，同一时间只能有一个任务可以进行修改，即串行的修改，没错，速度是慢了，但牺牲了速度却保证了数据安全。 即使可以用文件共享数据实现进程间通信，但问题是： 效率低（共享数据基于文件，而文件是硬盘上的数据） 需要自己加锁处理 一种能够兼顾的解决方案： 效率高（多个进程共享一块内存的数据） 帮我们处理好锁问题。这就是mutiprocessing模块为我们提供的基于消息的IPC通信机制：队列和管道。 队列和管道都是将数据存放于内存中 队列又是基于（管道+锁）实现的，可以让我们从复杂的锁问题中解脱出来，我们应该尽量避免使用共享数据，尽可能使用消息传递和队列，避免处理复杂的同步和锁问题，而且在进程数目增多时，往往可以获得更好的可获展性。 5.队列 进程彼此之间互相隔离，要实现进程间通信（IPC），multiprocessing模块支持两种形式：队列和管道，这两种方式都是使用消息传递的。 创建队列的类（底层就是以管道和锁定的方式实现） Queue([maxsize]):创建共享的进程队列，Queue是多进程安全的队列，可以使用Queue实现多进程之间的数据传递。 参数介绍 maxsize是队列中允许最大项数，省略则无大小限制。 方法介绍 q.put方法用以插入数据到队列中，put方法还有两个可选参数：blocked和timeout。如果blocked为True（默认值），并且timeout为正值，该方法会阻塞timeout指定的时间，直到该队列有剩余的空间。如果超时，会抛出Queue.Full异常。如果blocked为False，但该Queue已满，会立即抛出Queue.Full异常。 q.get方法可以从队列读取并且删除一个元素。同样，get方法有两个可选参数：blocked和timeout。如果blocked为True（默认值），并且timeout为正值，那么在等待时间内没有取到任何元素，会抛出Queue.Empty异常。如果blocked为False，有两种情况存在，如果Queue有一个值可用，则立即返回该值，否则，如果队列为空，则立即抛出Queue.Empty异常。 q.get_nowait():同q.get(False)。 q.put_nowait():同q.put(False)。 q.empty():调用此方法时q为空则返回True，该结果不可靠，比如在返回True的过程中，如果队列中又加入了项目。 q.full()：调用此方法时q已满则返回True，该结果不可靠，比如在返回True的过程中，如果队列中的项目被取走。 q.qsize():返回队列中目前项目的正确数量，结果也不可靠，理由同q.empty()和q.full()一样。 q.cancel_join_thread():不会在进程退出时自动连接后台线程。可以防止join_thread()方法阻塞。 q.close():关闭队列，防止队列中加入更多数据。调用此方法，后台线程将继续写入那些已经入队列但尚未写入的数据，但将在此方法完成时马上关闭。如果q被垃圾收集，将调用此方法。关闭队列不会在队列使用者中产生任何类型的数据结束信号或异常。例如，如果某个使用者正在被阻塞在get()操作上，关闭生产者中的队列不会导致get()方法返回错误。 q.join_thread()：连接队列的后台线程。此方法用于在调用q.close()方法之后，等待所有队列项被消耗。默认情况下，此方法由不是q的原始创建者的所有进程调用。调用q.cancel_join_thread方法可以禁止这种行为。 生产者消费者模型 6.管道 创建管道的类 Pipe([duplex]):在进程之间创建一条管道，并返回元组（conn1,conn2）,其中conn1，conn2表示管道两端的连接对象，强调一点：必须在产生Process对象之前产生管道 参数介绍 dumplex:默认管道是全双工的，如果将duplex射成False，conn1只能用于接收，conn2只能用于发送。 主要方法 conn1.recv():接收conn2.send(obj)发送的对象。如果没有消息可接收，recv方法会一直阻塞。如果连接的另外一端已经关闭，那么recv方法会抛出EOFError。 conn1.send(obj):通过连接发送对象。obj是与序列化兼容的任意对象 其他方法 conn1.close():关闭连接。如果conn1被垃圾回收，将自动调用此方法 conn1.fileno():返回连接使用的整数文件描述符 conn1.poll([timeout]):如果连接上的数据可用，返回True。timeout指定等待的最长时限。如果省略此参数，方法将立即返回结果。如果将timeout射成None，操作将无限期地等待数据到达。 conn1.recv_bytes([maxlength]):接收c.send_bytes()方法发送的一条完整的字节消息。maxlength指定要接收的最大字节数。如果进入的消息，超过了这个最大值，将引发IOError异常，并且在连接上无法进行进一步读取。如果连接的另外一端已经关闭，再也不存在任何数据，将引发EOFError异常。 conn.send_bytes(buffer [, offset [, size]])：通过连接发送字节数据缓冲区，buffer是支持缓冲区接口的任意对象，offset是缓冲区中的字节偏移量，而size是要发送字节数。结果数据以单条消息的形式发出，然后调用c.recv_bytes()函数进行接收。 conn1.recv_bytes_into(buffer [, offset]):接收一条完整的字节消息，并把它保存在buffer对象中，该对象支持可写入的缓冲区接口（即bytearray对象或类似的对象）。offset指定缓冲区中放置消息处的字节位移。返回值是收到的字节数。如果消息长度大于可用的缓冲区空间，将引发BufferTooShort异常。 基于管道实现进程间通信（与队列的方式是类似的，队列就是管道加锁实现的） 12345678910111213141516171819202122232425262728293031323334from multiprocessing import Process,Pipeimport time,osdef consumer(p,name): left,right=p left.close() while True: try: baozi=right.recv() print('%s 收到包子:%s' %(name,baozi)) except EOFError: right.close() breakdef producer(seq,p): left,right=p right.close() for i in seq: left.send(i) # time.sleep(1) else: left.close()if __name__ == '__main__': left,right=Pipe() c1=Process(target=consumer,args=((left,right),'c1')) c1.start() seq=(i for i in range(10)) producer(seq,(left,right)) right.close() left.close() c1.join() print('主进程') 注意：生产者和消费者都没有使用管道的某个端点，就应该将其关闭，如在生产者中关闭管道的右端，在消费者中关闭管道的左端。如果忘记执行这些步骤，程序可能再消费者中的recv()操作上挂起。管道是由操作系统进行引用计数的,必须在所有进程中关闭管道后才能生产EOFError异常。因此在生产者中关闭管道不会有任何效果，付费消费者中也关闭了相同的管道端点。 7.数据共享 基于消息传递的并发编程是未来大势所趋，即便是使用线程，推荐做法也是将程序设计为大量独立的线程集合，通过消息队列交换数据。这样极大地减少了对使用锁定和其他同步手段的需求，还可以扩展到分布式系统中 进程间的通信应该尽量避免使用本节所讲的共享数据的方式：进程间数据是独立的，可以借助于队列或管道实现通信，二者都是基于消息传递的虽然进程间数据独立，但可以通过Manager实现数据共享，事实上Manager的功能远不止于此。 12345678910111213141516171819from multiprocessing import Manager,Process,Lockimport osdef work(d,lock): # with lock: #不加锁而操作共享的数据,肯定会出现数据错乱 d['count']-=1if __name__ == '__main__': lock=Lock() with Manager() as m: dic=m.dict(&#123;'count':100&#125;) p_l=[] for i in range(100): p=Process(target=work,args=(dic,lock)) p_l.append(p) p.start() for p in p_l: p.join() print(dic) #&#123;'count': 94&#125; 8.信号量 互斥锁 同时只允许一个线程更改数据，而Semaphore是同时允许一定数量的线程更改数据 ，比如饭馆有50个座位，那最多只允许50个人共同吃饭，后面的人只能等饭店里面有人吃完才能再进去，如果指定信号量为50，那么来一个人获得一把锁，计数加1，当计数等于50时，后面的人均需要等待。一旦释放，就有人可以获得一把锁 信号量与进程池的概念很像，但是要区分开，信号量涉及到加锁的概念 12345678910111213141516171819from multiprocessing import Process,Semaphoreimport time,randomdef go_wc(sem,user): sem.acquire() print('%s 占了一个座位' %user) time.sleep(random.randint(0,3)) # 模拟每个人吃饭速度不一样，0代表有的人刚坐下就起来了 sem.release()if __name__ == '__main__': sem=Semaphore(5) p_l=[] for i in range(13): p=Process(target=go_wc,args=(sem,'user%s' %i,)) p.start() p_l.append(p) for i in p_l: i.join() print('&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;') 9.事件 python线程的事件用于主线程控制其他线程的执行，事件主要提供了三个方法set、wait、clear。 事件处理的机制：全局定义了一个“Flag”，如果“Flag”值为 False，那么当程序执行 event.wait 方法时就会阻塞，如果“Flag”值为True，那么event.wait 方法时便不再阻塞。 clear：将“Flag”设置为False set：将“Flag”设置为True 12345678910111213141516171819202122232425262728293031323334353637383940414243from multiprocessing import Process,Eventimport time,randomdef car(e,n): while True: if not e.is_set(): #Flase print('\\033[31m红灯亮\\033[0m，car%s等着' %n) e.wait() print('\\033[32m车%s 看见绿灯亮了\\033[0m' %n) time.sleep(random.randint(3,6)) if not e.is_set(): continue print('走你,car', n) breakdef police_car(e,n): while True: if not e.is_set(): print('\\033[31m红灯亮\\033[0m，car%s等着' % n) e.wait(1) print('灯的是%s，警车走了,car %s' %(e.is_set(),n)) breakdef traffic_lights(e,inverval): while True: time.sleep(inverval) if e.is_set(): e.clear() #e.is_set() ----&gt;False else: e.set()if __name__ == '__main__': e=Event() # for i in range(10): # p=Process(target=car,args=(e,i,)) # p.start() for i in range(5): p = Process(target=police_car, args=(e, i,)) p.start() t=Process(target=traffic_lights,args=(e,10)) t.start() print('&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;') 10.进程池在利用Python进行系统管理的时候，特别是同时操作多个文件目录，或者远程控制多台主机，并行操作可以节约大量的时间。多进程是实现并发的手段之一，需要注意的问题是： 很明显需要并发执行的任务通常要远大于核数 一个操作系统不可能无限开启进程，通常有几个核就开几个进程 进程开启过多，效率反而会下降（开启进程是需要占用系统资源的，而且开启多余核数目的进程也无法做到并行） 例如当被操作对象数目不大时，可以直接利用multiprocessing中的Process动态成生多个进程，十几个还好，但如果是上百个，上千个。。。手动的去限制进程数量却又太过繁琐，此时可以发挥进程池的功效。 对于远程过程调用的高级应用程序而言，应该使用进程池，Pool可以提供指定数量的进程，供用户调用，当有新的请求提交到pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，就重用进程池中的进程。 创建进程池的类 如果指定numprocess为3，则进程池会从无到有创建三个进程，然后自始至终使用这三个进程去执行所有任务，不会开启其他进程 Pool([numprocess [,initializer [, initargs]]]) 参数介绍 numprocess:要创建的进程数，如果省略，将默认使用cpu_count()的值 initializer：是每个工作进程启动时要执行的可调用对象，默认为None initargs：是要传给initializer的参数组 方法介绍 p.apply(func [, args [, kwargs]]):在一个池工作进程中执行func(*args,**kwargs),然后返回结果。需要强调的是：此操作并不会在所有池工作进程中并执行func函数。如果要通过不同参数并发地执行func函数，必须从不同线程调用p.apply()函数或者使用p.apply_async() p.apply_async(func [, args [, kwargs]]):在一个池工作进程中执行func(*args,**kwargs),然后返回结果。此方法的结果是AsyncResult类的实例，callback是可调用对象，接收输入参数。当func的结果变为可用时，将理解传递给callback。callback禁止执行任何阻塞操作，否则将接收其他异步操作中的结果。 p.close():关闭进程池，防止进一步操作。如果所有操作持续挂起，它们将在工作进程终止前完成 P.jion():等待所有工作进程退出。此方法只能在close（）或teminate()之后调用 具体应用 123456789101112131415# 同步调用applyfrom multiprocessing import Poolimport os,timedef work(n): print('%s run' %os.getpid()) time.sleep(3) return n**2if __name__ == '__main__': p=Pool(3) #进程池中从无到有创建三个进程,以后一直是这三个进程在执行任务 res_l=[] for i in range(10): res=p.apply(work,args=(i,)) #同步调用，直到本次任务执行完毕拿到res，等待任务work执行的过程中可能有阻塞也可能没有阻塞，但不管该任务是否存在阻塞，同步调用都会在原地等着，只是等的过程中若是任务发生了阻塞就会被夺走cpu的执行权限 res_l.append(res) print(res_l) 1234567891011121314151617181920# 异步调用apply_asyncfrom multiprocessing import Poolimport os,timedef work(n): print('%s run' %os.getpid()) time.sleep(3) return n**2if __name__ == '__main__': p=Pool(3) #进程池中从无到有创建三个进程,以后一直是这三个进程在执行任务 res_l=[] for i in range(10): res=p.apply_async(work,args=(i,)) #同步运行,阻塞、直到本次任务执行完毕拿到res res_l.append(res) #异步apply_async用法：如果使用异步提交的任务，主进程需要使用jion，等待进程池内任务都处理完，然后可以用get收集结果，否则，主进程结束，进程池可能还没来得及执行，也就跟着一起结束了 p.close() p.join() for res in res_l: print(res.get()) #使用get来获取apply_aync的结果,如果是apply,则没有get方法,因为apply是同步执行,立刻获取结果,也根本无需get apply_async与apply 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#一：使用进程池（异步调用,apply_async）#coding: utf-8from multiprocessing import Process,Poolimport timedef func(msg): print( \"msg:\", msg) time.sleep(1) return msgif __name__ == \"__main__\": pool = Pool(processes = 3) res_l=[] for i in range(10): msg = \"hello %d\" %(i) res=pool.apply_async(func, (msg, )) #维持执行的进程总数为processes，当一个进程执行完毕后会添加新的进程进去 res_l.append(res) print(\"==============================&gt;\") #没有后面的join，或get，则程序整体结束，进程池中的任务还没来得及全部执行完也都跟着主进程一起结束了 pool.close() #关闭进程池，防止进一步操作。如果所有操作持续挂起，它们将在工作进程终止前完成 pool.join() #调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束 print(res_l) #看到的是&lt;multiprocessing.pool.ApplyResult object at 0x10357c4e0&gt;对象组成的列表,而非最终的结果,但这一步是在join后执行的,证明结果已经计算完毕,剩下的事情就是调用每个对象下的get方法去获取结果 for i in res_l: print(i.get()) #使用get来获取apply_aync的结果,如果是apply,则没有get方法,因为apply是同步执行,立刻获取结果,也根本无需get#二：使用进程池（同步调用,apply）#coding: utf-8from multiprocessing import Process,Poolimport timedef func(msg): print( \"msg:\", msg) time.sleep(0.1) return msgif __name__ == \"__main__\": pool = Pool(processes = 3) res_l=[] for i in range(10): msg = \"hello %d\" %(i) res=pool.apply(func, (msg, )) #维持执行的进程总数为processes，当一个进程执行完毕后会添加新的进程进去 res_l.append(res) #同步执行，即执行完一个拿到结果，再去执行另外一个 print(\"==============================&gt;\") pool.close() pool.join() #调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束 print(res_l) #看到的就是最终的结果组成的列表 for i in res_l: #apply是同步的，所以直接得到结果，没有get()方法 print(i) 11.回调函数 需要回调函数的场景：进程池中任何一个任务一旦处理完了，就立即告知主进程：我好了额，你可以处理我的结果了。主进程则调用一个函数去处理该结果，该函数即回调函数。 我们可以把耗时间（阻塞）的任务放到进程池中，然后指定回调函数（主进程负责执行），这样主进程在执行回调函数时就省去了I/O的过程，直接拿到的是任务的结果。 爬取猫眼的案例 12345678910111213141516171819202122232425262728293031323334353637383940from multiprocessing import Poolimport time,randomimport requestsimport redef get_page(url,pattern): response=requests.get(url) if response.status_code == 200: return (response.text,pattern)def parse_page(info): page_content,pattern=info res=re.findall(pattern,page_content) for item in res: dic=&#123; 'index':item[0], 'title':item[1], 'actor':item[2].strip()[3:], 'time':item[3][5:], 'score':item[4]+item[5] &#125; print(dic)if __name__ == '__main__': pattern1=re.compile(r'&lt;dd&gt;.*?board-index.*?&gt;(\\d+)&lt;.*?title=\"(.*?)\".*?star.*?&gt;(.*?)&lt;.*?releasetime.*?&gt;(.*?)&lt;.*?integer.*?&gt;(.*?)&lt;.*?fraction.*?&gt;(.*?)&lt;',re.S) url_dic=&#123; 'http://maoyan.com/board/7':pattern1, &#125; p=Pool() res_l=[] for url,pattern in url_dic.items(): res=p.apply_async(get_page,args=(url,pattern),callback=parse_page) res_l.append(res) for i in res_l: i.get() # res=requests.get('http://maoyan.com/board/7') # print(re.findall(pattern,res.text)) 进程池的其他实现方式","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://www.ice5.vip/categories/并发编程/"}],"tags":[{"name":"multiprocessing","slug":"multiprocessing","permalink":"https://www.ice5.vip/tags/multiprocessing/"}]},{"title":"网络编程基础","slug":"网络编程基础","date":"2018-12-03T10:44:07.550Z","updated":"2018-12-04T20:01:02.740Z","comments":true,"path":"/网络编程基础/","link":"","permalink":"https://www.ice5.vip/网络编程基础/","excerpt":"自从互联网诞生以来，现在市场上所有的程序都是基本网络程序，单击版的应用程序几乎不见了。计算机网络就是负责将各个计算机连接到一起，让网络中的计算机可以互相通信。网络编程就是如何在各个程序中实现两台计算机的通信。","text":"自从互联网诞生以来，现在市场上所有的程序都是基本网络程序，单击版的应用程序几乎不见了。计算机网络就是负责将各个计算机连接到一起，让网络中的计算机可以互相通信。网络编程就是如何在各个程序中实现两台计算机的通信。 一、C/S架构和B/S架构1.B/S架构 实际上B/S架构也是C/S架构的一种 2.C/S架构 硬件硬件C/S架构(如打印机) 软件C/S架构 互联网中到处是C/S架构，如你的浏览器就是客户端，你的目标网站就是服务端 二、网络通信原理1.互联网的本质就是一系列的网络协议若将计算机比作动物，互联网协议就可以视成计算机界的英语。只要计算机都学会了并遵守互联网协议（Internet Protocol Suite），则所有的计算机都可以按照统一的标准来实现数据的传递任务了。 2.OSI七层协议互联网协议按照功能不同分为OSI七层或TCP/IP五层 3.TCP/IP五层模型讲解 将应用层，表示层，会话层并作应用层，从TCP/IP五层协议的角度来阐述每层的由来与功能，只要我们搞清楚了每层的主要协议，就可以理解整个互联网通信的过程及原理。首先，在用户感知到的范围是最上面一层应用层，自上而下每层都依赖于下一层，所以我们就从最下一层开始切入，比较好理解每层都运行特定的协议，越往上越靠近用户，越往下越靠近硬件。 物理层 物理层功能：主要是基于电器特性发送高低电压(电信号)，高电压对应数字1，低电压对应数字0 数据链路层 数据链路层出现的原因：单纯的电信号0和1没有任何意义，必须规定电信号多少位一组，每组什么意思 数据链路层的功能：定义了电信号的分组方式 以太网协议： 一组电信号构成一个数据包，叫做 “帧” 每一数据帧分成：报头head和数据data两部分 mac地址： head中包含的源和目标地址由来：ethernet规定接入internet的设备都必须具备网卡，发送端和接收端的地址便是指网卡的地址，即mac地址。每块网卡出厂时都被烧制上一个世界唯一的mac地址，长度为48位2进制，通常由12位16进制数表示（前六位是厂商编号，后六位是流水线号） 广播： ethernet采用最原始的方式，广播的方式进行通信，即计算机通信基本靠吼 网络层 网络层出现的原因：有了ethernet、mac地址、广播的发送方式之后，世界上的所有计算机就可以彼此通信了，但是问题是世界范围的互联网是由一个个彼此互相隔离的局域网组成的，如果所有的通信都采用以太网的广播方式，那么一台机器发送的包全世界都会收到，这个时候就不仅仅是效率低的问题了，这将是计算机界的一场巨大灾难。 IP协议： 规定网络地址的协议叫IP协议，它定义的地址称之为IP地址，广泛采用的v4版本即ipv4，它规定网络地址由32位2进制表示 范围0.0.0.0-255.255.255.255 一个IP地址通常写成四段十进制数，例：192.168.0.0 IP地址分成两部分： 网络部分：标识子网 主机部分：标识主机 子网掩码： 表示子网络特征的一个参数。它在形式上等同于IP地址，也是一个32位二进制数字，它的网络部分全部为1，主机部分全部为0。比如，IP地址172.16.10.1，如果已知网络部分是前24位，主机部分是后8位，那么子网络掩码就是11111111.11111111.11111111.00000000，写成十进制就是255.255.255.0。 知道”子网掩码”，我们就能判断，任意两个IP地址是否处在同一个子网络。方法是将两个IP地址与子网掩码分别进行AND运算（两个数位都为1，运算结果为1，否则为0），然后比较结果是否相同，如果是的话，就表明它们在同一个子网络中，否则就不是。 IP数据包： IP数据包也分为head和data部分，无须为IP包定义单独的栏位，直接放入以太网包的data部分 ARP协议： 计算机通信基本靠吼，即广播的方式，所有上层的包到最后都要封装上以太网头，然后通过以太网协议发送，在谈及以太网协议时候，我们了解到通信是基于mac的广播方式实现，计算机在发包时，获取自身的mac是容易的，如何获取目标主机的mac，就需要通过ARP协议。 ARP协议功能：广播的方式发送数据包，获取目标主机的mac地址 这个包会以广播的方式在发送端所处的自网内传输，所有主机接收后拆开包，发现目标IP为自己的，就响应，返回自己的mac 4.传输层传输层的由来：网络层的IP区分子网，以太网层的mac找到主机，然后大家使用的都是应用程序，但是电脑上可能同时开启QQ，爱奇艺，等多个应用程序，我们通过IP和mac找到了一台特定的主机，如何标识这台主机上的应用程序，答案就是端口，端口即应用程序与网卡关联的编号。 传输层功能：建立端口到端口的通信。 TCP协议： 可靠传输，TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常TCP数据包的长度不会超过IP数据包的长度，以确保单个TCP数据包不必再分割。 UDP协议： 不可靠传输，”报头”部分一共只有8个字节，总长度不超过65,535字节，正好放进一个IP数据包。 5.应用层应用层由来：用户使用的都是应用程序，均工作于应用层，互联网是开发的，大家都可以开发自己的应用程序，数据多种多样，必须规定好数据的组织形式 应用层功能：规定应用程序的数据格式。 6.Socket层 两个进程如果需要进行通讯最基本的一个前提能能够唯一的标示一个进程，在本地进程通讯中我们可以使用PID来唯一标示一个进程，但PID只在本地唯一，网络中的两个进程PID冲突几率很大，这时候我们需要另辟它径了，我们知道IP层的ip地址可以唯一标示主机，而TCP层协议和端口号可以唯一标示主机的一个进程，这样我们可以利用ip地址＋协议＋端口号唯一标示网络中的一个进程。 能够唯一标示网络中的进程后，它们就可以利用socket进行通信了，什么是socket呢？我们经常把socket翻译为套接字，socket是在应用层和传输层之间的一个抽象层，它把TCP/IP层复杂的操作抽象为几个简单的接口供应用层调用已实现进程在网络中通信。 三、网络通信的实现 网络通信实现的四要素 本机的IP地址 子网掩码 网关的IP地址 DNS的IP地址 四要素的获取方式： 静态获取：即手动获取 动态获取 （1）最前面的”以太网标头”，设置发出方（本机）的MAC地址和接收方（DHCP服务器）的MAC地址。前者就是本机网卡的MAC地址，后者这时不知道，就填入一个广播地址：FF-FF-FF-FF-FF-FF。 （2）后面的”IP标头”，设置发出方的IP地址和接收方的IP地址。这时，对于这两者，本机都不知道。于是，发出方的IP地址就设为0.0.0.0，接收方的IP地址设为255.255.255.255。 （3）最后的”UDP标头”，设置发出方的端口和接收方的端口。这一部分是DHCP协议规定好的，发出方是68端口，接收方是67端口。 数据包构造完成后，就可以发出了。以太网是广播发送，同一个子网络的每台计算机都收到了这个包。因为接收方的MAC地址是FF-FF-FF-FF-FF-FF，看不出是发给谁的，所以每台收到这个包的计算机，还必须分析这个包的IP地址，才能确定是不是发给自己的。当看到发出方IP地址是0.0.0.0，接收方是255.255.255.255，于是DHCP服务器知道”这个包是发给我的”，而其他计算机就可以丢弃这个包。 接下来，DHCP服务器读出这个包的数据内容，分配好IP地址，发送回去一个”DHCP响应”数据包。这个响应包的结构也是类似的，以太网标头的MAC地址是双方的网卡地址，IP标头的IP地址是DHCP服务器的IP地址（发出方）和255.255.255.255（接收方），UDP标头的端口是67（发出方）和68（接收方），分配给请求端的IP地址和本网络的具体参数则包含在Data部分。 新加入的计算机收到这个响应包，于是就知道了自己的IP地址、子网掩码、网关地址、DNS服务器等等参数","categories":[{"name":"网络编程","slug":"网络编程","permalink":"https://www.ice5.vip/categories/网络编程/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://www.ice5.vip/tags/TCP/"},{"name":"UDP","slug":"UDP","permalink":"https://www.ice5.vip/tags/UDP/"}]},{"title":"网络编程HTTP协议","slug":"网络编程之HTTP协议","date":"2018-12-03T10:39:26.125Z","updated":"2018-12-04T21:05:11.442Z","comments":true,"path":"/网络编程之HTTP协议/","link":"","permalink":"https://www.ice5.vip/网络编程之HTTP协议/","excerpt":"HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。 HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。","text":"HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。 HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。 一、HTTP协议简介HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过几年的使用与发展，得到不断地完善和扩展。HTTP协议工作于客户端-服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。 二、HTTP协议的特点1.简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 2.基于TCP/IP协议之上的应用层协议。 3.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 4.无状态：HTTP是一种不保存状态, 即无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 HTTP协议 自身不对请求和响应之间的通信状态进行保存。也就是说在HTTP这个 级别,协议对于发送过的请求或响应都不做持久化处理。 5.基于请求－响应模式：HTTP协议规定,请求从客户端发出,最后服务器端响应该请求并 返回。换句话说,肯定是先从客户端开始建立通信的,服务器端在没有 接收到请求之前不会发送响应。 6.灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 三、HTTP请求协议与响应协议 http协议包含由浏览器发送数据到服务器需要遵循的请求协议与服务器发送数据到浏览器需要遵循的请求协议。用于HTTP协议交互的信被为HTTP报文。请求端(客户端)的HTTP报文 做请求报文,响应端(服务器端)的 做响应报文。HTTP报文本身是由多行数据构成的字 文本。 1.请求协议Request 2.1请求方式 GET与POST请求方式的区别 GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&amp;相连，如login?name=yourname&amp;pwd=123456. POST方法是把提交的数据放在HTTP包的请求体中。 GET提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制. GET与POST请求在服务端获取请求数据方式不同。 GET请求头信息 123456789101112131415GET请求# 请求首行 GET / HTTP/1.1\\r\\n# get请求后面的参数GET /?name=lqz&amp;age=18 HTTP/1.1\\r\\n# 请求头Host: 127.0.0.1:8008\\r\\nConnection: keep-alive\\r\\nCache-Control: max-age=0\\r\\nUpgrade-Insecure-Requests: 1\\r\\nUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)Chrome/65.0.3325.181 Safari/537.36\\r\\nAccept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nAccept-Language: zh-CN,zh;q=0.9\\r\\nCookie: csrftoken=7xx6BxQDJ6KB0PM7qS8uTA892ACtooNbnnF4LDwlYk1Y7S7nTS81FBqwruizHsxF\\r\\n\\r\\n'# 请求体（get请求，请求体为空） POST请求头信息 123456# 请求首行POST /?name=lqz&amp;age=18 HTTP/1.1\\r\\n# 请求头Host: 127.0.0.1:8008\\r\\nConnection: keep-alive\\r\\nContent-Length: 21\\r\\nCache-Control: max-age=0\\r\\nOrigin: http://127.0.0.1:8008\\r\\nUpgrade-Insecure-Requests: 1\\r\\nContent-Type: application/x-www-form-urlencoded\\r\\nUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36\\r\\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\\r\\nReferer: http://127.0.0.1:8008/?name=lqz&amp;age=18\\r\\nAccept-Encoding: gzip, deflate, br\\r\\nAccept-Language: zh-CN,zh;q=0.9\\r\\nCookie: csrftoken=7xx6BxQDJ6KB0PM7qS8uTA892ACtooNbnnF4LDwlYk1Y7S7nTS81FBqwruizHsxF\\r\\n\\r\\n# 请求体name=lqz&amp;password=123' 2.响应协议Response 2.1状态码 状态码 说明 1xx 指示信息，表示请求已接收，继续处理 2xx 成功，表示请求已被处理完毕 3xx 重定向，要完成请求必须进行更进一步的操作 4xx 客户端错误，请求有语法错误或请求服务器无法实现 5xx 服务器端错误，服务器处理请求出错 四、HTTP工作原理 HTTP协议定义Web客户端如何从Web服务器请求Web页面，以及服务器如何把Web页面传送给客户端。HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。 1. HTTP 请求/响应的步骤1.1 客户端连接到Web服务器一个HTTP客户端，通常是浏览器，与Web服务器的HTTP端口（默认为80）建立一个TCP套接字连接。例如，https://www.ice5.vip 1.2 发送HTTP请求通过TCP套接字，客户端向Web服务器发送一个文本的请求报文，一个请求报文由请求行、请求头部、空行和请求数据4部分组成。 1.3 服务器接受请求并返回HTTP响应Web服务器解析请求，定位请求资源。服务器将资源复本写到TCP套接字，由客户端读取。一个响应由状态行、响应头部、空行和响应数据4部分组成。 1.4 释放连接TCP连接若connection 模式为close，则服务器主动关闭TCP连接，客户端被动关闭连接，释放TCP连接；若connection 模式为keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求。 1.5 客户端浏览器解析HTML内容客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的HTML文档和文档的字符集。客户端浏览器读取响应数据HTML，根据HTML的语法对其进行格式化，并在浏览器窗口中显示。 例如：在浏览器地址栏键入URL，按下回车之后会经历以下流程： 1.浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址 2.解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立TCP连接 3.浏览器发出读取文件(URL 中域名后面部分对应的文件)的HTTP 请求，该请求报文作为 TCP 三次握手]的第三个报文的数据发送给服务器 4.服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器 5.释放 TCP连接 6.浏览器将该 html 文本并显示内容 五、URL简介 HTTP使用统一资源标识符（Uniform Resource Identifiers, URI）来传输数据和建立连接。URL是一种特殊类型的URI，包含了用于查找某个资源的足够的信息 URL,全称是统一资源定位符(Uniform Resource Locator)，对可以从互联网上得到的资源的位置和访问方法的一种简洁的表示，是互联网上标准资源的地址。互联网上的每个文件都有一个唯一的URL，它包含的信息指出文件的位置以及浏览器应该怎么处理它 1.格式 协议：//IP:端口（80）/路径?name=yourname&amp;pwd=123456 如：https://www.ice5.vip/name=myname&amp;pwd=123 ？之前的是请求路径，？之后的是 GET请求数据部分","categories":[{"name":"网络编程","slug":"网络编程","permalink":"https://www.ice5.vip/categories/网络编程/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://www.ice5.vip/tags/HTTP/"}]},{"title":"Python实现23种设计模式","slug":"Python实现23种设计模式","date":"2018-12-02T21:43:16.883Z","updated":"2018-12-02T21:43:16.885Z","comments":true,"path":"/Python实现23种设计模式/","link":"","permalink":"https://www.ice5.vip/Python实现23种设计模式/","excerpt":"","text":"一、创建类设计模式（5种）1.单利模式 单例模式是所有设计模式中比较简单的一类，其定义如下：Ensure a class has only one instance, and provide a global point of access to it.（保证某一个类只有一个实例，而且在全局只有一个访问点） settings.pyIP=’1.1.1.1’PORT=3306 方式一:自定义元类来实现实例化 123456789101112131415161718192021222324252627import settingsclass Mymeta(type): def __init__(self,class_name,class_bases,class_dic): super(Mymeta, self).__init__(class_name,class_bases,class_dic) # 造出一个Mysql的空对象 self.__instance=self.__new__(self) # 为空对象从文件中读取数据并完成初始化 self.__init__(self.__instance,settings.IP,settings.PORT) # 在调用时会自动触发__call__方法 def __call__(self, *args, **kwargs): if len(args)==0 and len(kwargs)==0: return self.__instance obj=self.__new__(self) self.__init__(obj,*args,**kwargs) return objclass Mysql(object,metaclass=Mymeta): def __init__(self,ip,port): self.ip=ip self.port=port obj1=Mysql()obj2=Mysql()print(id(obj1)) # 2028744394680print(id(obj2)) # 2028744394680 方式二:自定义装饰器来实现 12345678910111213141516171819202122import settingsdef singleton(cls): cls.__instance=cls(settings.IP,settings.PORT) def wrapper(*args,**kwargs): if len(args)==0 and len(kwargs)==0: return cls.__instance return cls(*args,**kwargs) return wrapper@singletonclass Mysql: def __init__(self,ip,port): self.ip=ip self.port=portobj1=Mysql()obj2=Mysql()print(obj1.__dict__)print(id(obj1)) # 1452804392832print(id(obj2)) # 1452804392832 方式三:普通方式 1234567891011121314151617181920212223242526272829import settingsclass Mysql: __instance=None def __init__(self,ip,port): self.ip=ip self.port=port @classmethod def get_info_from_conf(cls): if cls.__instance is None: cls.__instance=cls(settings.IP,settings.PORT) return cls.__instance# 正常实例化一次即占用一份内存资源# obj1=Mysql('192.168.0.0',3306)# obj2=Mysql('192.168.0.0',3306)# obj3=Mysql('192.168.0.0',3306)## print(id(obj1)) #2362806290360# print(id(obj2)) # 2362806290416# print(id(obj3)) #2362806290528# 使用单例模式之后占用同一份内存资源obj1=Mysql.get_info_from_conf()obj2=Mysql.get_info_from_conf()obj3=Mysql.get_info_from_conf()print(obj1.__dict__)print(id(obj1)) # 1591701587896print(id(obj2)) # 1591701587896print(id(obj3)) # 1591701587896 1.1单利模式的优缺点 优点 由于单例模式要求在全局内只有一个实例，因而可以节省比较多的内存空间 全局只有一个接入点，可以更好地进行数据同步控制，避免多重占用 单例可长驻内存，减少系统开销。 缺点 单例模式的扩展是比较困难的 赋于了单例以太多的职责，某种程度上违反单一职责原则（六大原则在《设计模式》中普及） 单例模式是并发协作软件模块中需要最先完成的，因而其不利于测试 单例模式在某种情况下会导致“资源瓶颈”。 1.2单利模式的应用 生成全局惟一的序列号 访问全局复用的惟一资源，如磁盘、总线等 单个对象占用的资源过多，如数据库等 系统全局统一管理，如Windows下的Task Manager 网站计数器。 2.工厂模式(简单工厂模式、抽象工厂模式) 快餐点餐系统想必大家都是用过的。在一个大的触摸显示屏上，有三类可以选择的上餐品：汉堡等主餐、小食、饮料。当我们选择好自己需要的食物，支付完成后，订单就生成了。下面，我们用今天的主角–工厂模式–来生成这些食物的逻辑主体。 首先，来看主餐的生成（仅以两种汉堡为例） 1234567891011121314151617class Burger(): name=\"\" price=0.0 def getPrice(self): return self.price def setPrice(self,price): self.price=price def getName(self): return self.nameclass cheeseBurger(Burger): def __init__(self): self.name=\"cheese burger\" self.price=10.0class spicyChickenBurger(Burger): def __init__(self): self.name=\"spicy chicken burger\" self.price=15.0 其次，是小食（内容基本一致） 123456789101112131415161718class Snack(): name = \"\" price = 0.0 type = \"SNACK\" def getPrice(self): return self.price def setPrice(self, price): self.price = price def getName(self): return self.nameclass chips(Snack): def __init__(self): self.name = \"chips\" self.price = 6.0class chickenWings(Snack): def __init__(self): self.name = \"chicken wings\" self.price = 12.0 然后，是饮料 123456789101112131415161718class Beverage(): name = \"\" price = 0.0 type = \"BEVERAGE\" def getPrice(self): return self.price def setPrice(self, price): self.price = price def getName(self): return self.nameclass coke(Beverage): def __init__(self): self.name = \"coke\" self.price = 4.0class milk(Beverage): def __init__(self): self.name = \"milk\" self.price = 5.0 接下来，“工厂”就要出现了 123456789101112131415class foodFactory(): type=\"\" def createFood(self,foodClass): print self.type,\" factory produce a instance.\" foodIns=foodClass() return foodInsclass burgerFactory(foodFactory): def __init__(self): self.type=\"BURGER\"class snackFactory(foodFactory): def __init__(self): self.type=\"SNACK\"class beverageFactory(foodFactory): def __init__(self): self.type=\"BEVERAGE\" 同样，foodFactory为抽象的工厂类，而burgerFactory，snackFactory，beverageFactory为具体的工厂类。在业务场景中，工厂模式是如何“生产”产品的呢？ 12345678910if __name__==\"__main__\": burger_factory=burgerFactory() snack_factorry=snackFactory() beverage_factory=beverageFactory() cheese_burger=burger_factory.createFood(cheeseBurger) print cheese_burger.getName(),cheese_burger.getPrice() chicken_wings=snack_factorry.createFood(chickenWings) print chicken_wings.getName(),chicken_wings.getPrice() coke_drink=beverage_factory.createFood(coke) print coke_drink.getName(),coke_drink.getPrice() 12345678业务中先生成了工厂，然后用工厂中的createFood方法和对应的参数直接生成产品实例。打印结果如下：BURGER factory produce a instance.cheese burger 10.0SNACK factory produce a instance.chicken wings 12.0BEVERAGE factory produce a instance.coke 4.0 定义一个用于创建对象的接口，让子类决定实例化哪个类。工厂方法使一个类的实例化延迟到其子类。其通用类图如下。其产品类定义产品的公共属性和接口，工厂类定义产品实例化的“方式”。 在上述例子中，工厂在使用前必须实例化。如果，把工厂加个类方法，写成如下形式： 123456class simpleFoodFactory(): @classmethod def createFood(cls,foodClass): print \"Simple factory produce a instance.\" foodIns = foodClass() return foodIns 在场景中写成如下形式： 省去将工厂实例化的过程.这种模式就叫做简单工厂模式 1spicy_chicken_burger=simpleFoodFactory.createFood(spicyChickenBurger) burgerFactory就是具体食物工厂的一层抽象。这种模式，就是抽象工厂模式 1createFood方法中必须传入foodClass才可以指定生成的food实例种类，如果，将每一个细致的产品都建立对应的工厂（如cheeseBurger建立对应一个cheeseBurgerFactory），这样，生成食物时，foodClass也不必指定。 2.1工厂模式的优缺点 优点 工厂模式巨有非常好的封装性，代码结构清晰；在抽象工厂模式中，其结构还可以随着需要进行更深或者更浅的抽象层级调整，非常灵活 屏蔽产品类，使产品的被使用业务场景和产品的功能细节可以分而开发进行，是比较典型的解耦框架 缺点 工厂模式相对于直接生成实例过程要复杂一些，所以，在小项目中，可以不使用工厂模式 抽象工厂模式中，产品类的扩展比较麻烦。毕竟，每一个工厂对应每一类产品，产品扩展，就意味着相应的抽象工厂也要扩展 2.2工厂模式的应用 当系统实例要求比较灵活和可扩展时，可以考虑工厂模式或者抽象工厂模式实现。比如，在通信系统中，高层通信协议会很多样化，同时，上层协议依赖于下层协议，那么就可以对应建立对应层级的抽象工厂，根据不同的“产品需求”去生产定制的实例。 3.建造者模式4.原型模式二、结构类设计模式（7种）1.代理模式2.装饰器模式3.适配器模式4.门面模式5.组合模式6.享元模式7.桥梁模式三、行为类设计模式（11种）1.策略模式2.责任链模式3.命令模式4.中介者模式5.模板模式6.迭代器模式7.访问者模式8.观察者模式9.解释器模式10.备忘录模式11.状态模式","categories":[{"name":"Python","slug":"Python","permalink":"https://www.ice5.vip/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.ice5.vip/tags/Python/"}]},{"title":"设计模式","slug":"设计模式","date":"2018-12-02T20:25:42.622Z","updated":"2018-12-02T20:25:42.624Z","comments":true,"path":"/设计模式/","link":"","permalink":"https://www.ice5.vip/设计模式/","excerpt":"设计模式是面对各种问题进行提炼和抽象而形成的解决方案。这些设计方案是前人不断试验，考虑了封装性、复用性、效率、可修改、可移植等各种因素的高度总结。模式不是代码，而是某类问题的通用设计解决方案。","text":"设计模式是面对各种问题进行提炼和抽象而形成的解决方案。这些设计方案是前人不断试验，考虑了封装性、复用性、效率、可修改、可移植等各种因素的高度总结。模式不是代码，而是某类问题的通用设计解决方案。 一、设计模式与架构、框架的关系 1.软件框架与设计模式的关系 软件框架随着软件工程的发展而出现，所谓的软件框架，是提取了特定领域的软件的共性部分所形成的软件体系，它并不是一个成熟的软件，而更像是一个“半成品”，程序员在框架之上，可以很方便地某些特定领域实现又快又可靠的二次开发。设计模式和软件框架在软件设计中是两个不同的研究领域：A、设计模式如前边的定义所讲，它指的是针对一类问题的解决方法，一个设计模式可应用于不同的框架和被不同的语言所实现；而框架则是一个应用的体系结构，是一种或多种设计模式和代码的混合体；B、设计模式相较于框架更容易移植，并且可以用各种语言实现，而软件框架则受限于领域大环境。虽然设计模式和软件框架有很多不同，但在某些方面他们二者是统一的，即重视软件复用，提高开发效率。 2.软件架构与设计模式的关系 软件架构是个比较大的概念，架构要考虑软件的整体结构、层次划分以及不同部分间的协作和交互等，架构的着眼点偏整体。相比之下，框架和设计模式的范围则具体很多，框架着眼于领域内的解决方法，而设计模式则针对一类问题的解决方案和设计思路。总体来说，软件架构可以由不同的框架和不同的设计模式，再加上特定的构件组合来实现；框架可以根据设计模式结合特定编程语言和环境来实现。设计模式就是解决单一问题的设计思路和解决方法。 二、设计模式的意义 由于公司人事的变动，代码非常有可能会被移交，即代码的编写者和维护者很有可能会是不同的人。那么代码的可读性就显得非常重要了。由于高级语言的出现，让机器读懂你的意图已经不是最主要的“矛盾”，而让人读懂你的意图才是最重要。按照设计模式编写的代码，其可读性也会大大提升，利于团队项目的继承和扩展 三、设计模式的种类 1.创建类设计模式（5种） 单例模式、工厂模式（简单工厂模式、抽象工厂模式）、建造者模式、原型模式 2.结构类设计模式（7种） 代理模式、装饰器模式、适配器模式、门面模式、组合模式、享元模式、桥梁模式 3.行为类设计模式（11种） 策略模式、责任链模式、命令模式、中介者模式、模板模式、迭代器模式、访问者模式、观察者模式、解释器模式、备忘录模式、状态模式 四、设计模式遵循的六大原则 设计模式与设计原则，基本符合规则与原则的关系，设计模式是一个个具体问题的解决方案，设计原则则反映了这些设计模式的指导思想；同时，设计原则可衍生出的设计模式也不仅限于上述介绍到了23种设计模式，任何一种针对特定业务场景中的解决方法，虽然找不到对应的设计模式与之匹配，但若符合设计原则，也可以认为是一种全新的设计模式。从这个意义上来说，设计模式是程序设计方法的形，而设计原则是程序设计方法的神。 1.开闭原则（Open Close Principle） 开闭原则是非常基础的一个原则，也有人把开闭原则称为“原则的原则”。前面讲到过，模块分原子模块，低层模块，高层模块，业务层可以认为是最高层次的模块。对扩展开放，意味着模块的行为是可以扩展的，当高层模块需求改变时，我们可以对低层模块进行扩展，使其具有满足高层模块的新功能；对修改关闭，即对低层模块行为进行扩展时，不必改动模块的源代码。最理想的情况是，业务变动时，仅修改业务代码，不修改依赖的模块（类、函数等）代码，通过扩展依赖的模块单元来实现业务变化。 1假设一个原始基类水果类，苹果类是它的派生类，苹果中包含水果的各种属性，如形状、颜色等；另有两个类，农民类和花园类，最高层次（业务层次）为农民在花园种苹果。如果此时，农民决定不种苹果了，改种梨，符合OCP原则的设计应该为基于水果类构建一个新的类，即梨类（对扩展开放），而并不应该去修改苹果类，使它成为一个梨类（对修改关闭）。修改应仅在最高层，即业务层中进行。 2.里氏代换原则（Liskov Substitution Principle） 面向对象设计的最为基本原则之一。 里氏替换原则的含义为：任何基类可以出现的地方，子类一定可以出现。 LSP是继承复用的基石，只有当子类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复用，子类也能够在基类的基础上增加新的行为。 1对于一个鸟类，可以衍生出麻雀、喜鹊、布谷等子类，这些子类都可继承鸟类的鸣叫、飞行、吃食等接口。而对于一个鸡类，虽然它在生物学上属于鸟类，但它不会飞，那么符合LSP设计原则的情况下，鸡就不应该是鸟的一个子类：在鸟类调用飞行接口的地方，鸡类并不能出现。如果鸡类要使用鸟类的接口，应该使用关联关系，而不是继承关系。 3.依赖倒转原则（Dependence Inversion Principle） 高层模块不应该依赖于低层模块，两者都应该依赖其抽象。抽象不应该依赖于细节，细节应该依赖于抽象。我们将每个不可细分的逻辑叫作原子逻辑，原子逻辑组装，形成低层模块，低层模块组装形成高层模块。依赖倒置原则的含义为，高层模块和低层模块都应该由各自的抽象模块派生而来，同时接口设计应该依赖于抽象，而非具体模块。 1司机与汽车是依赖的关系，司机可以有实习司机类、老司机类等派生；汽车可以有轿车、SUV、卡车等派生类。如果司机中设计一个接口drive，汽车是其参数，符合DIP设计原则的参数，应该是在基类司机类中，将基类汽车类作为参数，而司机的派生类中，drive的参数同样应该为基类汽车类，而不应该是汽车类的任一个派生类。如果规定实习司机只能开轿车等业务逻辑，应该在其接口中进行判断，而不应该将参数替换成子类轿车。 4.接口隔离原则（Interface Segregation Principle） 类间的依赖关系不应该建立一个大的接口，而应该建立其最小的接口，即客户端不应该依赖那些它不需要的接口。这里的接口的概念是非常重要的。从逻辑上来讲，这里的接口可以指一些属性和方法的集合；从业务上来讲，接口就可以指特定业务下的接口（如函数，URL调用等）。接口应该尽量小，同时仅留给客户端必要的接口，弃用没有必要的接口。 1如果要根据具体的数据，生成饼图、直方图、表格，这个类该如何设计？如果将生成饼图、直方图、表格等“接口”（这里的接口就是“操作”的集合的概念），写在一个类中，是不符合接口隔离原则的。符合ISP原则的设计应该是设计三个类，每个类分别实现饼图、直方图、表格的绘制。 5.迪米特法则（最少知识原则）（Demeter Principle）（Least Knowledge Principle） 一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。 1一个公司有多个部门，每个部门有多个员工，如果公司CEO要下发通知给每个员工，是调用接口直接通知所有员工么？其实不然，CEO只需和它的“朋友”类部门Leader交流就好，部门Leader再下发通知信息即可。而CEO类不需要与员工进行“交流”。 6.合成复用原则（Composite Reuse Principle） 尽量使用合成/聚合的方式，而不是使用继承。继承实际上破坏了类的封装性，超类的方法可能会被子类修改。 五、设计模式的优点 设计原则是设计模式的提炼，因而设计原则的好处与设计模式是一致的，即：代码易于理解；更适于团体合作；适应需求变化等。 六、设计模式与设计原则 1.创建类设计模式 工厂模式：工厂方法模式是一种解耦结构，工厂类只需要知道抽象产品类，符合最少知识原则（迪米特法则）；同时符合依赖倒置原则和里氏替换原则； 抽象工厂模式：抽象工厂模式具有工厂模式的优点，但同时，如果产品族要扩展，工厂类也要修改，违反了开闭原则； 模板模式：优秀的扩展能力符合开闭原则。 2.结构类设计模式 代理模式：代理模式在业务逻辑中将对主体对象的操作进行封装，合适的应用会符合开闭原则和单一职责原则；事实上，几乎带有解耦作用的结构类设计模式都多少符合些开闭原则； 门面模式：门面模式不符合开闭原则，有时不符合单一职责原则，如若不注意，也会触碰接口隔离原则； 组合模式：符合开闭原则，但由于一般在拼接树时使用实现类，故不符合依赖倒置原则； 桥梁模式：桥梁模式堪称依赖倒置原则的典范，同时也符合开闭原则。 3.行为类设计模式 策略模式：符合开闭原则，但高层模块调用时，不符合迪米特法则。行为类设计模式多少会符合些单一职责原则，典型的如观察者模式、中介者模式、访问者模式等； 责任链模式：符合单一职责原则和迪米特法则； 命令模式：符合开闭原则。 在不同的业务逻辑中，不同的设计模式也会显示出不同的设计原则特点，从这个意义上来说，设计模式是设计原则的体现，但体现不是固定的，是根据业务而有所不同的。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://www.ice5.vip/categories/设计模式/"}],"tags":[]},{"title":"Git的使用","slug":"Git","date":"2018-12-02T19:06:24.563Z","updated":"2018-12-02T19:06:24.566Z","comments":true,"path":"/Git/","link":"","permalink":"https://www.ice5.vip/Git/","excerpt":"简单地说，Git 究竟是怎样的一个系统呢？GIT是一种版本控制器，更直白的说，团队开发的时候，管理代码使用的软件。Git 有多种使用方式。你可以使用原生的命令行模式，也可以使用 GUI 模式，这些 GUI 软件也能提供多种功能。","text":"简单地说，Git 究竟是怎样的一个系统呢？GIT是一种版本控制器，更直白的说，团队开发的时候，管理代码使用的软件。Git 有多种使用方式。你可以使用原生的命令行模式，也可以使用 GUI 模式，这些 GUI 软件也能提供多种功能。 一、Git 基础1.安装Git 1.1在 Linux 上安装 1sudo yum install git 1.2在 Window 上安装 1访问 [Git官网](https://git-scm.com/) 下载windows版，一路“Next”完毕，安装成功！ 2.Git的配置 2.1 设置账户(需要和github账户设置一致,引号内的内容需要更改)12git config --global user.name \"your-name\" git config --global user.email \"your-email@163.com\" 2.2 查看设置123git config --listuser.name=&quot;your-name&quot;user.email=&quot;your-email@163.com&quot; 3.创建版本库(创建完文件夹,在该文件夹内启动git bash)123cd D:/mkdir mygitgit init 注意.git是一个隐藏的目录，该文件的不要乱动(每一次的操作，都会有记录)仓库建在中文目录下，可能出现问题 4.查看Git的状态1git status 一般来说会显示需要提交的文件(uncommited)和未追踪的文件(untracked) uncommited：已有的，刚被修改尚未提交的;untracked：原先没有的，新建的 5.添加文件至版本库的步骤12git add &lt;your_file_name&gt; # 将 your_file_name 文件保存在暂存区git commit -m \"add your explain for the file\" # 将 your_file_name 提交到版本库 6.Git删除文件（夹）12git rm your_file_name # 删除文件git rm -r folder # 删除文件夹 git rm和直接删除的区别在于git rm会将此文件的操作记录删除，而直接删除仅仅是删除了物理文件，没有删除和此文件相关的记录。git rm后会在版本库产生区别（有操作日志），而直接删除没有。 12git rm test.txt &gt;&gt;&gt; git commit -m 'delete a file'rm test.txt &gt;&gt;&gt; git commit -am 'delete a file' 注意：命令git rm用于删除一个文件。如果一个文件已经被提交到版本库，那么你永远不用担心误删，但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。 二、Git 远程仓库之团队合作1.Git查看操作日志12345678git log # 查看项目日志git log file # 查看某个文件日志git log # 查看本目录日志git reflog # 查看详细做了啥git log --decorate --graph --oneline --all # 显示当前及之前的版本号git log --pretty=oneline # 将版本历史显示为一行，历史版本号全部显示git log --pretty=oneline --abbrev-commit # 将版本历史显示为一行，历史版本号部分显示git log --graph # 查看分支合并图 2.Git版本回退12git reset --hard \"head^^^\"git reset --hard 123abc --hard代表的是当前版本，后面的^符号代表的是退回到第几个版本，几个^符号就代表退回第几个;123abc代表的是版本号，保证版本号是唯一的即可 3.Git还原1git checkout -- myfile.md 4.Git分支1234git branch # 查看分支git branch dev # 创建分支git checkout dev # 切换分支git merge dev # 合并分支 5.Git远程仓库配置12345git remote git remote -v # 查看名称和详细地址git remote remove &lt;远程地址&gt; # 删除远程仓库git remote add &lt;远程仓库别名&gt; &lt;远程仓库地址&gt; # 添加远程仓库git remote rename &lt;旧名称&gt; &lt;新名称&gt; # 修改远程仓库 6.Git推送本地分支代码到远程仓库 6.1创建项目：12https地址:https://github.com/smart1san/smart1san.github.io.gitSSH地址: git@github.com:smart1san/smart1san.github.io.git 6.2将代码推到远程仓库12git remote add origin https://github.com/smart1san.git # 首先为本地库添加远程库git push origin master # 将本地的版本(默认是master)，推到代号为origin的远程库 7.Git团队合作 7.1需要clone一份代码到自己的本地1git clone https://github.com/smart1san/smart1san.github.io.git 7.2在本地创建和远程分支对应的分支1git checkout -b &lt;本地分支名&gt; origin/&lt;远程分支名&gt; 7.3在本地分支完成任务后，可以试图用以下代码推送自己的修改1git push &lt;远程主机名&gt; &lt;本地分支名&gt; 7.4若推送失败，则表明远程分支比本地更新，需要先用git pull试图合并1git pull origin master 7.5若pull失败并提示no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令创建链接1git branch --set-upstream-to=&lt;远程主机名&gt;/&lt;远程分支名&gt; &lt;本地分支名&gt; 7.6若合并有冲突，则解决冲突，并在本地提交（add =&gt; commit）7.7在没有冲突或者解决掉冲突后，再用git push &lt;远程主机名&gt; &lt;本地分支名&gt;推送就能成功 三、配置公钥免密登录1.配置ssh格式的远程仓库1git remote add &lt;远程仓库名&gt; &lt;远程仓库地址&gt; 2.在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa(私钥)和id_rsa.pub(公钥)这两个文件，如果已经有了，可直接跳到下一步。如果没有，打开Shell（Windows下打开Git Bash）,执行下一步 windows位置：‪C:\\Users\\用户名.ssh\\id_rsa.pub Linux位置：cat ~/.ssh/id_rsa.pub 3.创建ssh key1ssh-keygen -t rsa -C \"youremail@163.com\" 4.获得key的内容，复制下来，添加到gitHub的SSH key中 4.1 settings4.2 SSH and GPG keys4.3 ADD SSH key","categories":[{"name":"Git","slug":"Git","permalink":"https://www.ice5.vip/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.ice5.vip/tags/Git/"}]},{"title":"Django基础知识","slug":"Django","date":"2018-12-02T16:29:39.037Z","updated":"2018-12-02T16:29:39.041Z","comments":true,"path":"/Django/","link":"","permalink":"https://www.ice5.vip/Django/","excerpt":"Web框架（Web framework）是一种开发框架，用来支持动态网站、网络应用和网络服务的开发。这大多数的web框架提供了一套开发和部署网站的方式，也为web行为提供了一套通用的方法。Python的WEB框架有Django、Tornado、Flask 等多种，Django相较与其他WEB框架其优势为：大而全，框架本身集成了ORM、模型绑定、模板引擎、缓存、Session等诸多功能。","text":"Web框架（Web framework）是一种开发框架，用来支持动态网站、网络应用和网络服务的开发。这大多数的web框架提供了一套开发和部署网站的方式，也为web行为提供了一套通用的方法。Python的WEB框架有Django、Tornado、Flask 等多种，Django相较与其他WEB框架其优势为：大而全，框架本身集成了ORM、模型绑定、模板引擎、缓存、Session等诸多功能。 一、Django 简介1.Http 协议特性 TCP/IP协议之上的应用层协议 基于Request-Response模式 无状态保存 无连接 2.MVC和MTV① MVC M：Model（存取数据） V：View（取到数据展示给用户） C：Controller（分配工作给M和V） ② MTV M：Model（存取数据） T：Template（取到数据展示给用户） V：View（从M处取数据，返回给T） URL控制器 3.Django请求生命周期Browser — Web服务器（wsgi协议）— Middleware — URL路由 —View === ①从DataBase取数据；②将数据渲染至template 二、路由1.定义本质是URL与要为该URL调用的视图函数之间的映射表 2.简单路由配置123456from django.conf.urls import urlurlpatterns = [ url(r\"pattern\",views.视图函数,&#123;key:value&#125;,name=别名),]注意:urlpatterns从上至下逐行匹配,成功不再往下执行 3.有名分组123456789urlpatterns = [ url(\"index/(?P&lt;num&gt;pattern)\",views.index),]def index(request,num=1): print(num) return HttpResponse('ok') 注意：捕获的值作为关键字参数而不是位置参数传递给视图函数 4. 无名分组5.路由分发① 主URL 123456789from django.conf.urls import url,include# from django.urls import path,re_path,include // 2.+版本from app01 import viewsfrom app01 import urlsurlpatterns = [ path(&apos;app01/&apos;,include(&apos;app01.urls&apos;)), path(&apos;app01/&apos;, include(urls)),]注意:include() 括号中建议写app01.urls的方式,而不是直接写urls ② app01中的URL 12345from django.urls import path,re_path // 2.+版本from app01 import viewsurlpatterns = [ re_path(r\"pattern\",views.视图函数,&#123;key:value&#125;,name=别名),] 6.路由反向解析 应用:获得URL 的最终形式，用于嵌入到生成的内容中（视图中和显示给用户的URL等）或者用于处理服务器端的导航（重定向等）。 ①urls.py 12345from django.urls import path,re_pathfrom app01 import viewsurlpatterns = [ re_path(r\"有名分组\",views.视图函数,&#123;key:value&#125;,name=别名),] ②html代码 1&#123;% url &quot;别名&quot; 参数1 参数2 ... %&#125; ③视图函数 12url=reverse(&apos;test&apos;)url=reverse(&apos;test&apos;,args=(10,20)) 7.名称空间12由于name没有作用域，Django在反解URL时，会在项目全局顺序搜索，当查找到第一个name指定URL时，立即返回在开发项目时，会经常使用name属性反解出URL，当不小心在不同的app的urls中定义相同的name时，可能会导致URL反解错误，为了避免这种事情发生，引入了命名空间。 解决方式：在路由分发时，指定名称空间 12345urls.pyurlpatterns = [ url(r&apos;app01/&apos;,include(&apos;app01.urls&apos;,namespace=&apos;app01&apos;)), url(r&apos;app02/&apos;,include(&apos;app02.urls&apos;,namespace=&apos;app02&apos;))，] 123视图函数url=reverse(&apos;app02:index&apos;)url2=reverse(&apos;app01:index&apos;) 12模板&lt;a href=&quot;&#123;% url &apos;app02:index&apos;%&#125;&quot;&gt;LOL NB&lt;/a&gt; 8.Django 2.+版的path①模板 12345from django.urls import path from app01 import views urlpatterns = [ path(r'index/&lt;int:year&gt;/&lt;slug&gt;/', views.视图函数),] ②基本规则 使用尖括号(&lt;&gt;)从url中捕获值。 捕获值中可以包含一个转化器类型（converter type），比如使用 &lt;int:name&gt; 捕获一个整数变量。若果没有转化器，将匹配任何字符串，当然也包括了 / 字符。 无需添加前导斜杠。 ③path转换器 12345str,匹配除了路径分隔符（/）之外的非空字符串，这是默认的形式int,匹配正整数，包含0slug,匹配字母、数字以及横杠、下划线组成的字符串uuid,匹配格式化的uuid，如 075194d3-6885-417e-a8a8-6c931e272f00path,匹配任何非空字符串，包含了路径分隔符（/）（不能用？） ④自定义注册转换器 12345对于一些复杂或者复用的需要，可以定义自己的转化器。转化器是一个类或接口，它的要求有三点： regex 类属性，字符串类型 to_python(self, value) 方法，value是由类属性 regex 所匹配到的字符串，返回具体的Python变量值，以供Django传递到对应的视图函数中。 to_url(self, value) 方法，和 to_python 相反，value是一个具体的Python变量值，返回其字符串，通常用于url反向引用。 自定义文件 app01/Myconverter.py 123456class MyConverter: regex = \"pattern\" def to_python(self, value): return int(value) def to_url(self, value): return '%04d' % value urls.py 12345678from django.urls import register_converter, path from app01 import converters, views ①注册register_converter(converters.MyConverter, 'type') ②使用urlpatterns = [ path('articles/&lt;type:year&gt;/', views.year_archive),] 三、视图1.三剑客123from django.shortcuts import render, HttpResponse, redirect视图层，熟练掌握两个对象即可：请求对象(request)和响应对象(HttpResponse) 2. HttpRequest对象 Django将请求报文中的请求行、首部信息、内容主体封装成 HttpRequest 类中的属性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859request.GET 类似于字典的对象,包含 HTTP GET 的所有参数;QueryDict request.POST 类似于字典的对象,如果请求中包含表单数据,则将这些数据封装成 QueryDict 对象注意：键值对的值是多个的时候,比如checkbox类型的input标签，select标签，需要用： request.POST.getlist(\"hobby\") request.body 一个字符串，代表请求报文的主体。在处理非 HTTP 形式的报文时非常有用，例如：二进制图片、XML,Json等。但是，如果要处理表单数据的时候，推荐还是使用 HttpRequest.POST request.path 一个字符串，表示请求的路径组件（不含域名）。 例如：\"/music/bands/the_beatles/\" request.method 一个字符串，表示请求使用的HTTP 方法。必须使用大写。 request.FILES 一个类似于字典的对象，包含所有的上传文件信息。FILES 中的每个键为&lt;input type=\"file\" name=\"\" &gt; 中的name，值则为对应的数据。 # 注意，FILES 只有在请求的方法为POST 且提交的&lt;form&gt; 带有enctype=\"multipart/form-data\" 的情况下才会包含数据。否则，FILES 将为一个空的类似于字典的对象。 request.COOKIES 一个标准的Python 字典，包含所有的cookie。键和值都为字符串。 request.session 一个既可读又可写的类似于字典的对象，表示当前的会话。只有当Django 启用会话的支持时才可用。--------------------------------------------------------request.encoding 一个字符串，表示提交的数据的编码方式（如果为 None 则表示使用 DEFAULT_CHARSET 的设置，默认为 'utf-8'）。 这个属性是可写的，你可以修改它来修改访问表单数据使用的编码。 接下来对属性的任何访问（例如从 GET 或 POST 中读取数据）将使用新的 encoding 值。 若你知道表单数据的编码不是 DEFAULT_CHARSET ，则使用它。 request.META 一个标准的 Python 字典，包含所有的 HTTP 首部。具体的头部信息取决于客户端和服务器，下面是一些示例： 取值： CONTENT_LENGTH —— 请求的正文的长度（是一个字符串）。 CONTENT_TYPE —— 请求的正文的MIME 类型。 HTTP_ACCEPT —— 响应可接收的Content-Type。 HTTP_ACCEPT_ENCODING —— 响应可接收的编码。 HTTP_ACCEPT_LANGUAGE —— 响应可接收的语言。 HTTP_HOST —— 客服端发送的HTTP Host 头部。 HTTP_REFERER —— Referring 页面。 HTTP_USER_AGENT —— 客户端的user-agent 字符串。 QUERY_STRING —— 单个字符串形式的查询字符串（未解析过的形式）。 REMOTE_ADDR —— 客户端的IP 地址。 REMOTE_HOST —— 客户端的主机名。 REMOTE_USER —— 服务器认证后的用户。 REQUEST_METHOD —— 一个字符串，例如\"GET\" 或\"POST\"。 SERVER_NAME —— 服务器的主机名。 SERVER_PORT —— 服务器的端口（是一个字符串）。 从上面可以看到，除 CONTENT_LENGTH 和 CONTENT_TYPE 之外，请求中的任何 HTTP 首部转换为 META 的键时， 都会将所有字母大写并将连接符替换为下划线最后加上 HTTP_ 前缀。 所以，一个叫做 X-Bender 的头部将转换成 META 中的 HTTP_X_BENDER 键。 request.user(用户认证组件下使用) 一个 AUTH_USER_MODEL 类型的对象，表示当前登录的用户。 如果用户当前没有登录，user 将设置为 django.contrib.auth.models.AnonymousUser 的一个实例。可以通过 is_authenticated() 区分它们。 request常用方法 123456789101112request.get_full_path() 返回 path，如果可以将加上查询字符串。 例如：\"/music/bands/the_beatles/?print=true\"request.path() 返回：/music/bands/the_beatles request.is_ajax() 若请求是通过 XMLHttpRequest 发起的,则返回 True,方法是检查 HTTP_X_REQUESTED_WITH 相应的首部是否是字符串'XMLHttpRequest' 大部分现代的 JavaScript 库都会发送这个头部。若自己编写的 XMLHttpRequest 调用（在浏览器端），你必须手工设置这个值来让 is_ajax() 可以工作。 如果一个响应需要根据请求是否是通过AJAX 发起的，并且你正在使用某种形式的缓存例如Django 的 cache middleware， 你应该使用 vary_on_headers('HTTP_X_REQUESTED_WITH') 装饰你的视图以让响应能够正确地缓存。 3.HttpResponse 对象 响应三剑客 1from django.shortcuts import render, HttpResponse, redirect HttpResponse() 括号内直接跟上字符串作为响应体 render() 1234567render(request, template_name[, context]） request： 用于生成响应的请求对象。 template_name：要使用的模板的完整名称，可选的参数 context：添加到模板上下文的一个字典。默认是一个空字典。如果字典中的某个值是可调用的，视图将在渲染模板之前调用它。render方法就是将一个模板页面中的模板语法进行渲染，最终渲染成一个html页面作为响应体 redirect() 1跳转至指定的 URL 重定向301和302的异同点 1234567891011相同点：浏览器在拿到服务器返回的这个状态码后会自动跳转到一个新的URL地址不同点： 301表示旧地址A的资源已经被永久地移除了（该资源不可访问了），搜索引擎在抓取新内容的同时也将旧的网址交换为重定向之后的网址； 302表示旧地址A的资源还在（仍然可以访问），这个重定向只是临时地从旧地址A跳转到地址B，搜索引擎会抓取新的内容而保存旧的网址。 SEO302好于301 重定向原因：（1）网站调整（如改变网页目录结构）；（2）网页被移到一个新地址；（3）网页扩展名改变(如应用需要把.php改成.Html或.shtml)。 这种情况下，如果不做重定向，则用户收藏夹或搜索引擎数据库中旧地址只能让访问客户得到一个404页面错误信息，访问流量白白丧失；再者某些注册了多个域名的 网站，也需要通过重定向让访问这些域名的用户自动跳转到主站点等。 4.JsonResponse123456789101112# 第一种方式# import json# data=&#123;'name':'lqz','age':18&#125;# data1=['lqz','egon']# return HttpResponse(json.dumps(data1))# 第二种方式from django.http import JsonResponsedata = &#123;'name': 'lqz', 'age': 18&#125;data1 = ['lqz', 'egon']return JsonResponse(data)return JsonResponse(data1,safe=False) # safe=True(默认) 表示只有字典才可以被序列化向前端返回一个json格式字符串的两种方式 5.CBV和FBV CBV:Class base view —基于类的视图 123456789101112131415from django.views import Viewclass AddPublish(View): def dispatch(self, request, *args, **kwargs): print(request) print(args) print(kwargs) # 可以写类似装饰器的东西，在前后加代码 obj=super().dispatch(request, *args, **kwargs) return obj def get(self,request): return render(request,'index.html') def post(self,request): request return HttpResponse('post') FBV:Function base view 基于函数的视图 123def index(request): pass return HttpResponse(\"hi\") 6.简单文件上传 html 文件 123456&lt;!--不设置 enctype 属性，那么最终就会以 application/x-www-form-urlencoded 方式提交数据--&gt;&lt;form action=\"\" method=\"POST\" enctype=\"multipart/form-data\"&gt; &lt;input type=\"file\"&gt; &lt;button type=\"submit\"&gt;上传&lt;/button&gt;&lt;/form&gt; py 文件 123456789from django.core.files.uploadedfile import InMemoryUploadedFiledef index(request): print(request.FILES) print(type(request.FILES.get('file_name'))) file_name=request.FILES.get('file_name').name with open(file_name,'wb')as f: for i in request.FILES.get('file_name').chunks(): f.write(i) return HttpResponse(\"Ok\") 四、模板1.template.html1234&#123;&#123; 写非逻辑代码 &#125;&#125; ---变量&#123;% 写逻辑代码 %&#125; ---标签---if/for/extract服务器传到前端的数据(data)如果是字典的取值方式(深度查询): data.字段 2.过滤器123456789101112131415161718&#123;&#123; obj | filter__name:param &#125;&#125; 变量名 | 过滤器名:参数&#123;&#123; obj | safe &#125;&#125; 告诉浏览器是安全的,可以直接进行渲染,不必转义 xss攻击：跨站脚本攻击 可以在视图函数里处理 from django.utils.safestring import mark_safe obj=mark_safe(obj)&#123;&#123; value|default:\"nothing\" &#125;&#125; 变量是false或者为空,使用给定的默认值&#123;&#123; value|length &#125;&#125; 返回值的长度.它对字符串和列表都起作用&#123;&#123; value|filesizeformat &#125;&#125; 将值格式化为\"人类可读的\"文件尺寸&#123;&#123; value|date:\"Y-m-d\" &#125;&#125; 显示value的时间&#123;&#123; value|slice:\"2:-1\" &#125;&#125; 将value切分&#123;&#123; value|truncatechars:9 &#125;&#125; 如果字符串字符多于指定的字符数量,那么会被截断,截断的字符串将以可翻译的省略号序列（“...”）结尾&#123;&#123; value|truncatewords:2 &#125;&#125;其他过滤器：https://www.cnblogs.com/liuqingzheng/articles/9509806.html 3.标签123456789&#123;% empty %&#125; 只能在for循环当中使用//起别名&#123;% with total=business.employees.count %&#125; &#123;&#123; total &#125;&#125; employee&#123;&#123; total|pluralize &#125;&#125;&#123;% endwith %&#125;跨站请求伪造保护&#123;% csrf_token%&#125; 4.自定义templatetags1234567891011121314151617181920212223242526①在app01写创建templatetags目录(名字不可变动)②创建 my_tags.py 文件 from django import template from django.utils.safestring import mark_safe register=template.Library() //register 名字是固定的 // 自定义标签 // @register.simple_tag // def demo1(v1,v2): // return v1 * v2 @register.simple_tag def my_input(id,arg): result = \"&lt;input type='text'&gt;\" return mark_safe(result) // 自定义过滤器 @register.filter() def demo2(v1,v2): return v1 * v2③在使用自定义simple_tag和filter的html文件中导入之前创建的 my_tags.py &#123;% load my_tags %&#125; &#123;&#123; num|demo2:2 &#125;&#125; &#123;&#123; num|demo2:\"[22,333,4444]\" &#125;&#125; &#123;% demo1 2 5 %&#125; 参数不限,但不能放在if for语句中 &#123;% demo1i num 5 %&#125; ​ 注意：在settings.py中的INSTALLED_APPS配置当前app,不然Django无法找到自定义的simple_tag 5.模板导入和继承①导入 123&#123;% include 'template.html' %&#125;&#123;&#123; block.super &#125;&#125; // 复用模板的 block 组件 ②继承 模板 html 文件 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;link rel=\"stylesheet\" href=\"style.css\"/&gt; &lt;title&gt;&#123;% block title %&#125;My amazing site&#123;% endblock %&#125;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"sidebar\"&gt; &#123;% block sidebar %&#125; &lt;ul&gt; &lt;li&gt;&lt;a href=\"/\"&gt;Home&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=\"/blog/\"&gt;Blog&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &#123;% endblock %&#125;&lt;/div&gt;&lt;div id=\"content\"&gt; &#123;% block content %&#125;&#123;% endblock %&#125;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;base.html 定义了一个可以用于两列排版页面的简单HTML骨架。block 标签定义了三个可以被子模版内容填充的block。block 告诉模版引擎： 子模版可能会覆盖掉模版中的这些位置。 子模板 html 文件 12345678910111213&#123;% extends \"base.html\" %&#125; &#123;% block title %&#125;My amazing blog&#123;% endblock %&#125; &#123;% block content %&#125;&#123;% for entry in blog_entries %&#125; &lt;h2&gt;&#123;&#123; entry.title &#125;&#125;&lt;/h2&gt; &lt;p&gt;&#123;&#123; entry.body &#125;&#125;&lt;/p&gt;&#123;% endfor %&#125;&#123;% endblock %&#125;\"子模版\"的工作是用它们的内容填充空的blocks。extends 它告诉模版引擎，这个模版\"继承\"了另一个模版。当模版系统处理这个模版时,将定位父模板 base.html 使用继承的注意点 1234在模版中使用 &#123;% extends %&#125; 标签，它必须是模版中的第一个标签。其他的任何情况下，模版继承都将无法工作base模版中设置越多的 &#123;% block %&#125; 标签越好当你在大量的模版中复制内容,可能意味着你应该把内容移动到父模版中的一个 &#123;% block %&#125; 中给 &#123;% endblock name %&#125; 标签一个 name,具有更高的可读性 6.静态文件相关12&#123;% load static %&#125;&lt;img src=\"&#123;% static \"images/hi.jpg\" %&#125;\" alt=\"Hi!\" /&gt; 引用JS文件时使用 12&#123;% load static %&#125;&lt;script src=\"&#123;% static \"mytest.js\" %&#125;\"&gt;&lt;/script&gt; get_static_prefix 123456789&#123;% load static %&#125;&lt;img src=\"&#123;% get_static_prefix %&#125;images/hi.jpg\" alt=\"Hi!\" /&gt;or&#123;% load static %&#125;&#123;% get_static_prefix as STATIC_PREFIX %&#125;&lt;img src=\"&#123;&#123; STATIC_PREFIX &#125;&#125;images/hi.jpg\" alt=\"Hi!\" /&gt;&lt;img src=\"&#123;&#123; STATIC_PREFIX &#125;&#125;images/hi2.jpg\" alt=\"Hello!\" /&gt; 7.inclusion_tag 作用：返回 html 代码片段 templatetags / my_inclusion.py 12345678from django import templateregister = template.Library()@register.inclusion_tag('result.html')def show_results(n): n = 1 if n &lt; 1 else int(n) data = [\"第&#123;&#125;项\".format(i) for i in range(1, n+1)] return &#123;\"data\": data&#125; templates / snippets / result.html 12345&lt;ul&gt; &#123;% for choice in data %&#125; &lt;li&gt;&#123;&#123; choice &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125;&lt;/ul&gt; templates / index.html 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta http-equiv=\"x-ua-compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt; &lt;title&gt;my_inclusion&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &#123;% load my_inclusion %&#125; &#123;% show_results 10 %&#125;&lt;/body&gt;&lt;/html&gt; 五、模型(models.py) 单表操作 ①创建表 ②字段 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151AutoField(Field) - int自增列，必须填入参数 primary_key=True BigAutoField(AutoField) - bigint自增列，必须填入参数 primary_key=True 注：当model中如果没有自增列，则自动会创建一个列名为id的列 from django.db import models class UserInfo(models.Model): # 自动创建一个列名为id的且为自增的整数列 username = models.CharField(max_length=32) class Group(models.Model): # 自定义自增列 nid = models.AutoField(primary_key=True) name = models.CharField(max_length=32) SmallIntegerField(IntegerField): - 小整数 -32768 ～ 32767 PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField) - 正小整数 0 ～ 32767 IntegerField(Field) - 整数列(有符号的) -2147483648 ～ 2147483647 PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField) - 正整数 0 ～ 2147483647 BigIntegerField(IntegerField): - 长整型(有符号的) -9223372036854775808 ～ 9223372036854775807 自定义无符号整数字段 class UnsignedIntegerField(models.IntegerField): def db_type(self, connection): return 'integer UNSIGNED' PS: 返回值为字段在数据库中的属性，Django字段默认的值为： 'AutoField': 'integer AUTO_INCREMENT', 'BigAutoField': 'bigint AUTO_INCREMENT', 'BinaryField': 'longblob', 'BooleanField': 'bool', 'CharField': 'varchar(%(max_length)s)', 'CommaSeparatedIntegerField': 'varchar(%(max_length)s)', 'DateField': 'date', 'DateTimeField': 'datetime', 'DecimalField': 'numeric(%(max_digits)s, %(decimal_places)s)', 'DurationField': 'bigint', 'FileField': 'varchar(%(max_length)s)', 'FilePathField': 'varchar(%(max_length)s)', 'FloatField': 'double precision', 'IntegerField': 'integer', 'BigIntegerField': 'bigint', 'IPAddressField': 'char(15)', 'GenericIPAddressField': 'char(39)', 'NullBooleanField': 'bool', 'OneToOneField': 'integer', 'PositiveIntegerField': 'integer UNSIGNED', 'PositiveSmallIntegerField': 'smallint UNSIGNED', 'SlugField': 'varchar(%(max_length)s)', 'SmallIntegerField': 'smallint', 'TextField': 'longtext', 'TimeField': 'time', 'UUIDField': 'char(32)', BooleanField(Field) - 布尔值类型 NullBooleanField(Field): - 可以为空的布尔值 CharField(Field) - 字符类型 - 必须提供max_length参数， max_length表示字符长度 TextField(Field) - 文本类型 EmailField(CharField)： - 字符串类型，Django Admin以及ModelForm中提供验证机制 IPAddressField(Field) - 字符串类型，Django Admin以及ModelForm中提供验证 IPV4 机制 GenericIPAddressField(Field) - 字符串类型，Django Admin以及ModelForm中提供验证 Ipv4和Ipv6 - 参数： protocol，用于指定Ipv4或Ipv6， 'both',\"ipv4\",\"ipv6\" unpack_ipv4， 如果指定为True，则输入::ffff:192.0.2.1时候，可解析为192.0.2.1，开启刺功能，需要protocol=\"both\" URLField(CharField) - 字符串类型，Django Admin以及ModelForm中提供验证 URL SlugField(CharField) - 字符串类型，Django Admin以及ModelForm中提供验证支持 字母、数字、下划线、连接符（减号） CommaSeparatedIntegerField(CharField) - 字符串类型，格式必须为逗号分割的数字 UUIDField(Field) - 字符串类型，Django Admin以及ModelForm中提供对UUID格式的验证 FilePathField(Field) - 字符串，Django Admin以及ModelForm中提供读取文件夹下文件的功能 - 参数： path, 文件夹路径 match=None, 正则匹配 recursive=False, 递归下面的文件夹 allow_files=True, 允许文件 allow_folders=False, 允许文件夹 FileField(Field) - 字符串，路径保存在数据库，文件上传到指定目录 - 参数： upload_to = \"\" 上传文件的保存路径 storage = None 存储组件，默认django.core.files.storage.FileSystemStorage ImageField(FileField) - 字符串，路径保存在数据库，文件上传到指定目录 - 参数： upload_to = \"\" 上传文件的保存路径 storage = None 存储组件，默认django.core.files.storage.FileSystemStorage width_field=None, 上传图片的高度保存的数据库字段名（字符串） height_field=None 上传图片的宽度保存的数据库字段名（字符串） DateTimeField(DateField) - 日期+时间格式 YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] DateField(DateTimeCheckMixin, Field) - 日期格式 YYYY-MM-DD TimeField(DateTimeCheckMixin, Field) - 时间格式 HH:MM[:ss[.uuuuuu]] DurationField(Field) - 长整数，时间间隔，数据库中按照bigint存储，ORM中获取的值为datetime.timedelta类型 FloatField(Field) - 浮点型 DecimalField(Field) - 10进制小数 - 参数： max_digits，小数总长度 decimal_places，小数位长度 BinaryField(Field) - 二进制类型字段 ③参数 12345678910111213141516171819202122232425262728(1)null 如果为 True，Django 将用 NULL 来在数据库中存储空值。 默认值是 False. (1)blank 如果为 True，该字段允许不填。默认为 False。要注意，这与 null 不同。null 纯粹是数据库范畴的，而 blank 是数据验证范畴的。如果一个字段的blank=True，表单的验证将允许该字段是空值。如果字段的blank=False，该字段就是必填的。 (2)default 字段的默认值。可以是一个值或者可调用对象。如果可调用 ，每有新对象被创建它都会被调用。 (3)primary_key 如果为True，那么这个字段就是模型的主键。如果你没有指定任何一个字段的primary_key=True，Django 就会自动添加一个IntegerField字段做为主键，所以除非你想覆盖默认的主键行为，否则没必要设置任何一个字段的primary_key=True。 (4)unique 如果该值设置为 True, 这个数据字段的值在整张表中必须是唯一的 (5)choices由二元组组成的一个可迭代对象（例如，列表或元组），用来给字段提供选择项。 如果设置了choices ，默认的表单将是一个选择框而不是标准的文本框，&lt;br&gt;而且这个选择框的选项就是choices 中的选项。参数 ④元信息 1234567891011121314151617181920class UserInfo(models.Model): nid = models.AutoField(primary_key=True) username = models.CharField(max_length=32) class Meta: # 数据库中生成的表名称 默认 app名称 + 下划线 + 类名 db_table = \"table_name\" # 联合索引 index_together = [ (\"pub_date\", \"deadline\"), ] # 联合唯一索引 unique_together = ((\"driver\", \"restaurant\"),) # admin中显示的表名称 verbose_name # verbose_name加s verbose_name_plural ⑤增加删除字段 1234删除，直接注释掉字段，执行数据库迁移命令即可新增字段，在类里直接新增字段，直接执行数据库迁移命令会提示输入默认值，此时需要设置QuerySet_obj = models.CharField(max_length=12,default='xxx',null=True) ⑥添加表记录 123# create方法的返回值book_obj就是插入book表中的python葵花宝典这本书籍纪录对象QuerySet_obj=Book.objects.create(字段=value,pub_date=\"2012-12-12\")# 注意：时间格式必须是字符串 123obj=Book(字段=value,pub_date=\"2012-12-12\")obj.save()# 注意：该方法必须调用保存 ⑦查询表记录 12345678910111213141516171819202122232425&lt;1&gt; all(): 查询所有结果 &lt;2&gt; filter(**kwargs): 它包含了与所给筛选条件相匹配的对象 &lt;3&gt; get(**kwargs): 返回与所给筛选条件相匹配的对象，返回结果有且只有一个，如果符合筛选条件的对象超过一个或者没有都会抛出错误。 &lt;4&gt; exclude(**kwargs): 它包含了与所给筛选条件不匹配的对象 &lt;5&gt; order_by(*field): 对查询结果排序('-id') &lt;6&gt; reverse(): 对查询结果反向排序 &lt;8&gt; count(): 返回数据库中匹配查询(QuerySet)的对象数量。 &lt;9&gt; first(): 返回第一条记录 &lt;10&gt; last(): 返回最后一条记录 &lt;11&gt; exists(): 如果QuerySet包含数据，就返回True，否则返回False &lt;12&gt; values(*field): 返回一个ValueQuerySet——一个特殊的QuerySet，运行后得到的并不是一系列 model的实例化对象，而是一个可迭代的字典序列&lt;13&gt; values_list(*field): 它与values()非常相似，它返回的是一个元组序列，values返回的是一个字典序列 &lt;14&gt; distinct(): 从返回结果中剔除重复纪录 ⑧基于双下划线的模糊查询 12345678910Book.objects.filter(price__in=[100,200,300])Book.objects.filter(price__gt=100)Book.objects.filter(price__lt=100)Book.objects.filter(price__gte=100)Book.objects.filter(price__lte=100)Book.objects.filter(price__range=[100,200])Book.objects.filter(title__contains=\"python\")Book.objects.filter(title__icontains=\"python\")Book.objects.filter(title__startswith=\"py\")Book.objects.filter(pub_date__year=2012) ⑨删除表记录 12345678910111213model_obj.delete()它运行时立即删除对象而不返回任何值。---------------------------------------------------------可以一次性删除多个对象。每个 QuerySet 都有一个 delete() 方法，它一次性删除 QuerySet 中所有的对象。Entry.objects.filter(pub_date__year=2005).delete()# 注意： Django 2.+版本删除关联字段时，models.py 关联表中的关联字段必须设置 ON_DELETE=models.CASECADE 若不想级联删除，可设置 models.ForeignKey(to='Publisher', on_delete=models.SET_NULL, blank=True, null=True) delete() 方法是 QuerySet 上的方法，但并不适用于 Manager 本身。 ⑩修改表记录 123Book.objects.filter(title__startswith=\"py\").update(price=120） update()方法对于任何结果集（QuerySet）均有效，这意味着你可以同时更新多条记录update()方法会返回一个整型数值，表示受影响的记录条数。 多表操作 添加表记录①一对多 ②多对多 123456book_obj.authors.add(yuan,egon) book_obj.authors.remove() # 将某个特定的对象从被关联对象集合中去除。 ====== book_obj.authors.remove(*[])book_obj.authors.clear() #清空被关联对象集合book_obj.authors.set() #先清空再设置 跨表查询①一对一 123正向查询(按字段：authorDetail)obj=Author.objects.filter(name=\"xxx\").first()print(obj.authorDetail.telephone) 12345反向查询(按表名：author)# 查询所有住址在北京的作者的姓名authorDetail_list=AuthorDetail.objects.filter(addr=\"beijing\")for obj in authorDetail_list: print(obj.author.name) ②一对多 12345正向查询（按字段：publish）# 查询主键为1的书籍的出版社所在的城市book_obj=Book.objects.filter(pk=1).first()# book_obj.publish 是主键为1的书籍对象关联的出版社对象print(book_obj.publish.city) 123456反向查询（按表名：book_set）publish=Publish.objects.get(name=\"苹果出版社\")#publish.book_set.all() : 与苹果出版社关联的所有书籍对象集合book_list=publish.book_set.all() for book_obj in book_list: print(book_obj.title) ③多对多 123456正向查询(按字段：authors)# 所有作者的名字以及手机号book_obj=Book.objects.filter(title=\"眉\").first()authors=book_obj.authors.all()for author_obj in authors: print(author_obj.name,author_obj.authorDetail.telephone) 1234567反向查询(按表名：book_set)# 查询xxx出过的所有书籍的名字 author_obj=Author.objects.get(name=\"xxx\")book_list=author_obj.book_set.all() for book_obj in book_list: print(book_obj.title) 1234567# 注意：可通过在 ForeignKey() 和ManyToManyField的定义中设置 related_name 的值来覆写 FOO_set 的名称。publish = ForeignKey(Book, related_name='bookList')# 查询 人民出版社出版过的所有书籍publish=Publish.objects.get(name=\"人民出版社\")book_list=publish.bookList.all() # 与人民出版社关联的所有书籍对象集合 双下滑下跨表查询①一对多 12# 正向查询 按字段:publishqueryResult=Book.objects.filter(publish__name=\"苹果出版社\").values_list(\"title\",\"price\") 12# 反向查询 按表名:bookqueryResult=Publish.objects.filter(name=\"苹果出版 社\").values_list(\"book__title\",\"book__price\") ②多对多 12# 正向查询 按字段:authors:queryResult=Book.objects.filter(authors__name=\"xxx\").values_list(\"title\") 12# 反向查询 按表名:bookqueryResult=Author.objects.filter(name=\"xxx\").values_list(\"book__title\",\"book__price\") ③一对一 12# 正向查询ret=Author.objects.filter(name=\"xxx\").values(\"authordetail__telephone\") 12# 反向查询ret=AuthorDetail.objects.filter(author__name=\"alex\").values(\"telephone\") 聚合查询和分组查询 aggregate(*args,**kwargs) 12345# 计算所有图书的平均价格from django.db.models import Avg,Max, MinBook.objects.all().aggregate(Avg('price'))Book.objects.aggregate(Avg('price'), Max('price'), Min('price')) annotate() 123annotate()为调用的QuerySet中每一个对象都生成一个独立的统计值（统计方法用聚合函数）。总结 ：跨表分组查询本质就是将关联表join成一张表，再按单表的思路进行分组查询。 F查询和Q查询1234567891011from django.db.models import FDjango 提供 F() 来做这样的比较。F() 的实例可以在查询中引用字段，来比较同一个 model 实例中两个不同字段的值。# 查询评论数大于收藏数的书籍Book.objects.filter(commnetNum__lt=F('keepNum'))Django 支持 F() 对象之间以及 F() 对象和常数之间的加减乘除和取模的操作。# 查询评论数大于收藏数2倍的书籍Book.objects.filter(commnetNum__lt=F('keepNum')*2)修改操作也可以使用F函数,比如将每一本书的价格提高30元Book.objects.all().update(price=F(\"price\")+30) 123from django.db.models import QQ 对象可以使用 &amp; 和 | 操作符组合起来。当一个操作符在两个 Q 对象上使用时，它产生一个新的 Q 对象。bookList=Book.objects.filter(Q(authors__name=\"a\")|Q(authors__name=\"b\")) 六、组件1.Ajax 定义 AJAX（Asynchronous Javascript And XML）翻译成中文就是“异步Javascript和XML”。即使用Javascript语言与服务器进行异步交互，传输的数据为XML（当然，传输的数据不只是XML,现在更多使用json数据）。 ​ 特点：①异步交互—客户端发出请求后,无需等待服务器响应结束,就可以发出第二个请求 ; ②浏览器页面局部刷新 ​ 优点：①使用Javascript技术向服务器发送异步请求②无须刷新整个页面 XMLHttpResponse 方式 12345XMLHttpResponse: ① 生成对象 ② 处理数据 ③ 发送数据 ④ 监听事件 Django 方式（常用） 12345678910ajax(&#123; // 是JQuery最底层的实现原理 url:\"\", type:\"\", data:&#123;&#125;, // dataType:\"json\", //client 向 server指定接收的数据类型 // contentType:\"\", //告诉jQuery不要去设置Content-Type请求头 // processData:boolean，// 告诉浏览器是否处理数据 // data.parse() // 将数据解析成指定格式 // data.Jsonify() // 将接接收的数据变成json类型&#125;) 应用场景:登录验证 文件上传 ①ContentType请求头 12application/x-www-form-urlencoded最常见的 POST 提交数据的方式了。浏览器的原生 &lt;form&gt; 表单，如果不设置 enctype 属性，那么最终就会以 application/x-www-form-urlencoded 方式提交数据 12multipart/form-data常见的 POST 数据提交的方式。我们使用表单上传文件时，必须让 &lt;form&gt; 表单的 enctype 等于 multipart/form-data 12application/json用来告诉服务端消息主体是序列化后的 JSON 字符串。由于 JSON 规范的流行，除了低版本 IE 之外的各大浏览器都原生支持 JSON.stringify，服务端语言也都有处理 JSON 的函数，使用 JSON 不会遇上什么麻烦。 基于Form表单上传文件 html 文件 12345&lt;form action=\"/file_put/\" method=\"post\" enctype=\"multipart/form-data\"&gt; 用户名：&lt;input type=\"text\" name=\"name\"&gt; 头像：&lt;input type=\"file\" name=\"avatar\" id=\"avatar1\"&gt;&lt;input type=\"submit\" value=\"提交\"&gt;&lt;/form&gt; py文件视图函数 12345678910111213141516def file_put(request): if request.method=='GET': return render(request,'file_put.html') else: print(request.body) # 原始的请求体数据 print(request.GET) # GET请求数据 print(request.POST) # POST请求数据 print(request.FILES) # 上传的文件数据 print(request.body.decode('utf-8')) file_obj=request.FILES.get('avatar') print(type(file_obj)) with open(file_obj.name,'wb') as f: for line in file_obj: f.write(line) return HttpResponse('ok') 基于Ajax上传 1234567891011121314151617$(\"#ajax_button\").click(function () &#123; var formdata=new FormData() formdata.append('name',$(\"#id_name2\").val()) formdata.append('avatar',$(\"#avatar2\")[0].files[0]) $.ajax(&#123; url:'', type:'post', processData:false, //告诉jQuery不要去处理发送的数据 contentType:false,// 告诉jQuery不要去设置Content-Type请求头 data:formdata, success:function (data) &#123; console.log(data) &#125; &#125;)&#125;) Ajax提交json格式的数据 12345678910111213141516 $(\"#ajax_test\").click(function () &#123; var dic=&#123;'name':'lqz','age':18&#125; $.ajax(&#123; url:'', type:'post', contentType:'application/json', //一定要指定格式 contentType: 'application/json;charset=utf-8', data:JSON.stringify(dic), //转换成json字符串格式 success:function (data) &#123; console.log(data) &#125; &#125;) &#125;)提交到服务器的数据都在 request.body 里，取出来自行处理 2.分页器12345678910111213141516from django.core.paginator import Paginator,EmptyPage, PageNotAnIntegerPaginator对象： paginator = Paginator(user_list, 10)# paginator.per_page: 每页显示条目数量# paginator.count: 数据总个数# paginator.num_pages: 总页数# paginator.page_range:总页数的索引范围，如: (1,10),(1,200)# paginator.page: page对象 page对象：page=paginator.page(1) #第1页的page对象# page1.has_next 是否有下一页# page1.next_page_number 下一页页码# page1.has_previous 是否有上一页# page1.previous_page_number 上一页页码# page1.object_list 分页之后的数据列表# page1.number 当前页# page1.paginator paginator对象 批量导入数据 1234Booklist=[]for i in range(100): Booklist.append(Book(title=\"book\"+str(i),price=30+i*i))Book.objects.bulk_create(Booklist) View视图函数 123456789101112131415161718from django.shortcuts import render,HttpResponsefrom app01.models import *from django.core.paginator import Paginator, EmptyPage, PageNotAnInteger# Create your views here.def index(request): book_list=Book.objects.all() paginator = Paginator(book_list, 10) page = request.GET.get('page',1) # 从客户端传过来的所显示的当前页面 currentPage=int(page) try: print(page) book_list = paginator.page(page) except PageNotAnInteger: book_list = paginator.page(1) except EmptyPage: book_list = paginator.page(paginator.num_pages) return render(request,\"index.html\",&#123;\"book_list\":book_list,\"paginator\":paginator,\"currentPage\":currentPage&#125;) 模板层 index.html 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;link rel=\"stylesheet\" href=\"https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css\" integrity=\"sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u\" crossorigin=\"anonymous\"&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=\"container\"&gt; &lt;h4&gt;分页器&lt;/h4&gt; &lt;ul&gt; &#123;% for book in book_list %&#125; &lt;li&gt;&#123;&#123; book.title &#125;&#125; -----&#123;&#123; book.price &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; &lt;ul class=\"pagination\" id=\"pager\"&gt; &#123;% if book_list.has_previous %&#125; &lt;li class=\"previous\"&gt;&lt;a href=\"/index/?page=&#123;&#123; book_list.previous_page_number &#125;&#125;\"&gt;上一页&lt;/a&gt;&lt;/li&gt; &#123;% else %&#125; &lt;li class=\"previous disabled\"&gt;&lt;a href=\"#\"&gt;上一页&lt;/a&gt;&lt;/li&gt; &#123;% endif %&#125; &#123;% for num in paginator.page_range %&#125; &#123;% if num == currentPage %&#125; &lt;li class=\"item active\"&gt;&lt;a href=\"/index/?page=&#123;&#123; num &#125;&#125;\"&gt;&#123;&#123; num &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% else %&#125; &lt;li class=\"item\"&gt;&lt;a href=\"/index/?page=&#123;&#123; num &#125;&#125;\"&gt;&#123;&#123; num &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% endif %&#125; &#123;% endfor %&#125; &#123;% if book_list.has_next %&#125; &lt;li class=\"next\"&gt;&lt;a href=\"/index/?page=&#123;&#123; book_list.next_page_number &#125;&#125;\"&gt;下一页&lt;/a&gt;&lt;/li&gt; &#123;% else %&#125; &lt;li class=\"next disabled\"&gt;&lt;a href=\"#\"&gt;下一页&lt;/a&gt;&lt;/li&gt; &#123;% endif %&#125; &lt;/ul&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 核心逻辑 12345678910显示左5，右5，总共11个页，1 如果总页码大于11 1.1 if 当前页码减5小于1，要生成1到12的列表（顾头不顾尾，共11个页码） page_range=range(1,12) 1.2 elif 当前页码+5大于总页码，生成当前页码减10，到当前页码加1的列表（顾头不顾尾，共11个页码） page_range=range(paginator.num_pages-10,paginator.num_pages+1) 1.3 else 生成当前页码-5，到当前页码+6的列表 page_range=range(current_page_num-5,current_page_num+6)2 其它情况，生成的列表就是pageinator的page_range page_range=paginator.page_range 123456789101112131415161718192021222324252627def index(request): book_list=Book.objects.all() paginator = Paginator(book_list, 15) page = request.GET.get('page',1) currentPage=int(page) # 如果页数十分多时，换另外一种显示方式 if paginator.num_pages&gt;11: if currentPage-5&lt;1: pageRange=range(1,11) elif currentPage+5&gt;paginator.num_pages: pageRange=range(currentPage-5,paginator.num_pages+1) else: pageRange=range(currentPage-5,currentPage+5) else: pageRange=paginator.page_range try: print(page) book_list = paginator.page(page) except PageNotAnInteger: book_list = paginator.page(1) except EmptyPage: book_list = paginator.page(paginator.num_pages) return render(request,\"index.html\",locals()) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;link rel=\"stylesheet\" href=\"/static/bootstrap-3.3.7-dist/css/bootstrap.min.css\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;ul&gt; &#123;% for foo in page %&#125; &lt;li&gt;&#123;&#123; foo.name &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125;&lt;/ul&gt;&lt;nav aria-label=\"Page navigation\"&gt; &lt;ul class=\"pagination\"&gt; &#123;% if page.has_previous %&#125; &lt;li&gt; &lt;a href=\"/page_test/?page=&#123;&#123; page.previous_page_number &#125;&#125;\" aria-label=\"Previous\"&gt; &lt;span aria-hidden=\"true\"&gt;上一页&lt;/span&gt; &lt;/a&gt; &lt;/li&gt; &#123;% else %&#125; &lt;li class=\"disabled\"&gt; &lt;a href=\"#\" aria-label=\"Previous\"&gt; &lt;span aria-hidden=\"true\"&gt;上一页&lt;/span&gt; &lt;/a&gt; &lt;/li&gt; &#123;% endif %&#125; &#123;% for foo in page_range %&#125; &#123;% if current_page == foo %&#125; &lt;li class=\"active\"&gt;&lt;a href=\"/page_test/?page=&#123;&#123; foo &#125;&#125;\"&gt;&#123;&#123; foo &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% else %&#125; &lt;li&gt;&lt;a href=\"/page_test/?page=&#123;&#123; foo &#125;&#125;\"&gt;&#123;&#123; foo &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% endif %&#125; &#123;% endfor %&#125; &#123;% if page.has_next %&#125; &lt;li&gt; &lt;a href=\"/page_test/?page=&#123;&#123; page.next_page_number &#125;&#125;\" aria-label=\"Next\"&gt; &lt;span aria-hidden=\"true\"&gt;下一页&lt;/span&gt; &lt;/a&gt; &lt;/li&gt; &#123;% else %&#125; &lt;li class=\"disabled\"&gt; &lt;a href=\"#\" aria-label=\"Next\"&gt; &lt;span aria-hidden=\"true\"&gt;下一页&lt;/span&gt; &lt;/a&gt; &lt;/li&gt; &#123;% endif %&#125; &lt;/ul&gt;&lt;/nav&gt;&lt;/body&gt;&lt;/html&gt; 3.forms组件 校验字段（如用户注册） 123456models.pyclass UserInfo(models.Model): name=models.CharField(max_length=32) pwd=models.CharField(max_length=32) email=models.EmailField() 123456789101112131415161718192021222324252627282930313233模板文件&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;注册&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=\"\" method=\"post\"&gt; &#123;% csrf_token %&#125; &lt;div&gt; &lt;label for=\"user\"&gt;用户名&lt;/label&gt; &lt;p&gt;&lt;input type=\"text\" name=\"name\" id=\"name\"&gt;&lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;label for=\"pwd\"&gt;密码&lt;/label&gt; &lt;p&gt;&lt;input type=\"password\" name=\"pwd\" id=\"pwd\"&gt;&lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;label for=\"r_pwd\"&gt;确认密码&lt;/label&gt; &lt;p&gt;&lt;input type=\"password\" name=\"r_pwd\" id=\"r_pwd\"&gt;&lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;label for=\"email\"&gt;邮箱&lt;/label&gt; &lt;p&gt;&lt;input type=\"text\" name=\"email\" id=\"email\"&gt;&lt;/p&gt; &lt;/div&gt; &lt;input type=\"submit\"&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 1234567891011121314151617181920212223242526272829303132视图函数# forms组件from django.forms import widgetswid_01=widgets.TextInput(attrs=&#123;\"class\":\"form-control\"&#125;)wid_02=widgets.PasswordInput(attrs=&#123;\"class\":\"form-control\"&#125;)class UserForm(forms.Form): name=forms.CharField(max_length=32, widget=wid_01 ) pwd=forms.CharField(max_length=32,widget=wid_02) r_pwd=forms.CharField(max_length=32,widget=wid_02) email=forms.EmailField(widget=wid_01) tel=forms.CharField(max_length=32,widget=wid_01)def register(request): # 此时 request.POST 字典中的数据是未验证过的证据 if request.method==\"POST\": form=UserForm(request.POST) # 验证符合之后的字典形式数据 if form.is_valid(): print(form.cleaned_data) # 所有干净的字段以及对应的值 else: print(form.cleaned_data) print(form.errors.get(\"__all__\")) print(form.errors) # ErrorDict : &#123;\"校验错误的字段\":[\"错误信息\",]&#125; print(form.errors.get(\"name\")) # ErrorList [\"错误信息\",] return HttpResponse(\"OK\") form=UserForm() return render(request,\"register.html\",locals()) 渲染标签 ①方式一（拓展性高） 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;注册&lt;/title&gt; &lt;link rel=\"stylesheet\" href=\"https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css\" integrity=\"sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u\" crossorigin=\"anonymous\"&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;注册页面&lt;/h3&gt;&lt;div class=\"container\"&gt; &lt;div class=\"row\"&gt; &lt;div class=\"col-md-6 col-lg-offset-3\"&gt; &lt;form action=\"\" method=\"post\"&gt; &#123;% csrf_token %&#125; &lt;div&gt; &lt;label for=\"\"&gt;用户名&lt;/label&gt; &#123;&#123; form.name &#125;&#125; &lt;/div&gt; &lt;div&gt; &lt;label for=\"\"&gt;密码&lt;/label&gt; &#123;&#123; form.pwd &#125;&#125; &lt;/div&gt; &lt;div&gt; &lt;label for=\"\"&gt;确认密码&lt;/label&gt; &#123;&#123; form.r_pwd &#125;&#125; &lt;/div&gt; &lt;div&gt; &lt;label for=\"\"&gt; 邮箱&lt;/label&gt; &#123;&#123; form.email &#125;&#125; &lt;/div&gt; &lt;input type=\"submit\" class=\"btn btn-default pull-right\"&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; ②方式二（推荐） 123456789&lt;form action=\"\" method=\"post\"&gt; &#123;% csrf_token %&#125; &#123;% for field in form %&#125; &lt;div&gt; &lt;label for=\"\"&gt;&#123;&#123; field.label &#125;&#125;&lt;/label&gt; &#123;&#123; field &#125;&#125; &lt;/div&gt; &#123;% endfor %&#125; &lt;input type=\"submit\" class=\"btn btn-default pull-right\"&gt;&lt;/form&gt; ③方式三 123456&lt;form action=\"\" method=\"post\"&gt; &#123;% csrf_token %&#125; &#123;&#123; form.as_p &#125; &lt;!-- 直接全部当成p标签渲染 --&gt; &lt;input type=\"submit\" class=\"btn btn-default pull-right\"&gt;&lt;/form&gt; 校验不通过错误信息渲染 1234567891011121314Views.pydef register(request): if request.method==\"POST\": form=UserForm(request.POST) if form.is_valid(): print(form.cleaned_data) # 所有干净的字段以及对应的值 else: print(form.cleaned_data) # print(form.errors) # ErrorDict : &#123;\"校验错误的字段\":[\"错误信息\",]&#125; print(form.errors.get(\"name\")) # ErrorList [\"错误信息\",] return render(request,\"register.html\",locals()) form=UserForm() return render(request,\"register.html\",locals()) 12345678910111213index.html&lt;form action=\"\" method=\"post\" novalidate&gt; &#123;% csrf_token %&#125; &#123;% for field in form %&#125; &lt;div&gt; &lt;label for=\"\"&gt;&#123;&#123; field.label &#125;&#125;&lt;/label&gt; &#123;&#123; field &#125;&#125; &lt;span class=\"pull-right\" style=\"color: red\"&gt;&#123;&#123; field.errors.0 &#125;&#125;&lt;/span&gt; &lt;/div&gt; &#123;% endfor %&#125; &lt;input type=\"submit\" class=\"btn btn-default\"&gt;&lt;/form&gt; 组件参数设置 1234567class Ret(Form): # 这里有label之后,html中可以不用写label标签,可以添加错误信息,也可以控制组件的属性 name = forms.CharField(max_length=10, min_length=2, label='用户名', error_messages=&#123;'required': '该字段不能为空', 'invalid': '格式错误', 'max_length': '太长','min_length': '太短'&#125;, widget=widgets.TextInput(attrs=&#123;'class':'form-control'&#125;)) pwd = forms.CharField(max_length=10, min_length=2, widget=widgets.PasswordInput(attrs= &#123;'class':'form-control'&#125;)) email = forms.EmailField(label='邮箱', error_messages=&#123;'required': '该字段不能为空', 'invalid': '格式错误'&#125;) 局部钩子（校验字段） 123456789101112131415161718from django.core.exceptions import NON_FIELD_ERRORS, ValidationErrordef clean_name(self): val=self.cleaned_data.get(\"name\") ret=UserInfo.objects.filter(name=val) if not ret: return val else: raise ValidationError(\"该用户已注册!\") def clean_tel(self): val=self.cleaned_data.get(\"tel\") if len(val)==11: return val else: raise ValidationError(\"手机号格式错误\") 全局钩子（校验两次密码） 123456789101112def clean(self): pwd=self.cleaned_data.get('pwd') r_pwd=self.cleaned_data.get('r_pwd') if pwd and r_pwd: if pwd==r_pwd: return self.cleaned_data else: raise ValidationError('两次密码不一致') else: return self.cleaned_data 全部文件 ①自定义forms组件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051from django import formsfrom django.forms import widgetsfrom app01.models import UserInfofrom django.core.exceptions import NON_FIELD_ERRORS, ValidationErrorclass UserForm(forms.Form): name=forms.CharField(min_length=4,label=\"用户名\",error_messages=&#123;\"required\":\"该字段不能为空\"&#125;, widget=widgets.TextInput(attrs=&#123;\"class\":\"form-control\"&#125;) ) pwd=forms.CharField(min_length=4,label=\"密码\", widget=widgets.PasswordInput(attrs=&#123;\"class\":\"form-control\"&#125;) ) r_pwd=forms.CharField(min_length=4,label=\"确认密码\",error_messages=&#123;\"required\":\"该字段不能为空\"&#125;,widget=widgets.TextInput(attrs=&#123;\"class\":\"form-control\"&#125;)) email=forms.EmailField(label=\"邮箱\",error_messages=&#123;\"required\":\"该字段不能为空\",\"invalid\":\"格式错误\"&#125;,widget=widgets.TextInput(attrs=&#123;\"class\":\"form-control\"&#125;)) tel=forms.CharField(label=\"手机号\",widget=widgets.TextInput(attrs=&#123;\"class\":\"form-control\"&#125;)) def clean_name(self): val=self.cleaned_data.get(\"name\") ret=UserInfo.objects.filter(name=val) if not ret: return val else: raise ValidationError(\"该用户已注册!\") def clean_tel(self): val=self.cleaned_data.get(\"tel\") if len(val)==11: return val else: raise ValidationError(\"手机号格式错误\") def clean(self): pwd=self.cleaned_data.get('pwd') r_pwd=self.cleaned_data.get('r_pwd') if pwd and r_pwd: if pwd==r_pwd: return self.cleaned_data else: raise ValidationError('两次密码不一致') else: return self.cleaned_data ②视图函数 12345678910111213141516171819202122232425262728293031323334353637from django.shortcuts import render,HttpResponsefrom app01.myforms import *# Create your views here.def reg(request): if request.method==\"POST\": print(request.POST) #form=UserForm(&#123;\"name\":\"yu\",\"email\":\"123@qq.com\",\"xxxx\":\"alex\"&#125;) form=UserForm(request.POST) # form表单的name属性值应该与forms组件字段名称一致 print(form.is_valid()) # 返回布尔值 if form.is_valid(): print(form.cleaned_data) # &#123;\"name\":\"yuan\",\"email\":\"123@qq.com\"&#125; else: print(form.cleaned_data) # &#123;\"email\":\"123@qq.com\"&#125; # print(form.errors) # &#123;\"name\":[\"..........\"]&#125; # print(type(form.errors)) # ErrorDict # print(form.errors.get(\"name\")) # print(type(form.errors.get(\"name\"))) # ErrorList # print(form.errors.get(\"name\")[0]) # 全局钩子错误 #print(\"error\",form.errors.get(\"__all__\")[0]) errors=form.errors.get(\"__all__\") return render(request,\"reg.html\",locals()) ''' form.is_valid() :返回布尔值 form.cleaned_data :&#123;\"name\":\"yuan\",\"email\":\"123@qq.com\"&#125; form.errors :&#123;\"name\":[\"..........\"]&#125; ''' form=UserForm() return render(request,\"reg.html\",locals()) ③模板文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;style&gt; .error&#123; color: red; &#125; &lt;/style&gt; &lt;!-- 最新版本的 Bootstrap 核心 CSS 文件 --&gt; &lt;link rel=\"stylesheet\" href=\"https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css\" integrity=\"sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u\" crossorigin=\"anonymous\"&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=\"container\"&gt; &lt;div class=\"row\"&gt; &lt;div class=\"col-md-6 col-lg-offset-3\"&gt; &#123;#&lt;h3&gt;简单form&lt;/h3&gt;#&#125; &#123;##&#125; &#123;##&#125; &#123;#&lt;form action=\"\" method=\"post\" novalidate&gt;#&#125; &#123;# &#123;% csrf_token %&#125;#&#125; &#123;# &lt;p&gt;用户名&lt;input type=\"text\" name=\"name\"&gt;&lt;/p&gt;#&#125; &#123;# &lt;p&gt;密码 &lt;input type=\"text\" name=\"pwd\"&gt;&lt;/p&gt;#&#125; &#123;# &lt;p&gt;确认密码 &lt;input type=\"text\" name=\"r_pwd\"&gt;&lt;/p&gt;#&#125; &#123;# &lt;p&gt;邮箱 &lt;input type=\"text\" name=\"email\"&gt;&lt;/p&gt;#&#125; &#123;# &lt;p&gt;手机号 &lt;input type=\"text\" name=\"tel\"&gt;&lt;/p&gt;#&#125; &#123;# &lt;input type=\"submit\"&gt;#&#125; &#123;##&#125; &#123;#&lt;/form&gt;#&#125; &lt;hr&gt; &lt;h3&gt;forms组件渲染方式1&lt;/h3&gt; &lt;form action=\"\" method=\"post\" novalidate&gt; &#123;% csrf_token %&#125; &lt;p&gt;&#123;&#123; form.name.label &#125;&#125; &#123;&#123; form.name &#125;&#125; &lt;span class=\"pull-right error\"&gt;&#123;&#123; form.name.errors.0 &#125;&#125;&lt;/span&gt; &lt;/p&gt; &lt;p&gt;&#123;&#123; form.pwd.label &#125;&#125; &#123;&#123; form.pwd &#125;&#125; &lt;span class=\"pull-right error\"&gt;&#123;&#123; form.pwd.errors.0 &#125;&#125;&lt;/span&gt; &lt;/p&gt; &lt;p&gt;确认密码 &#123;&#123; form.r_pwd &#125;&#125; &lt;span class=\"pull-right error\"&gt;&#123;&#123; form.r_pwd.errors.0 &#125;&#125;&lt;/span&gt;&lt;span class=\"pull-right error\"&gt;&#123;&#123; errors.0 &#125;&#125;&lt;/span&gt; &lt;/p&gt; &lt;p&gt;邮箱 &#123;&#123; form.email &#125;&#125; &lt;span class=\"pull-right error\"&gt;&#123;&#123; form.email.errors.0 &#125;&#125;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;手机号 &#123;&#123; form.tel &#125;&#125; &lt;span class=\"pull-right error\"&gt;&#123;&#123; form.tel.errors.0 &#125;&#125;&lt;/span&gt;&lt;/p&gt; &lt;input type=\"submit\"&gt; &lt;/form&gt; &#123;#&lt;h3&gt;forms组件渲染方式2&lt;/h3&gt;#&#125; &#123;##&#125; &#123;#&lt;form action=\"\" method=\"post\" novalidate&gt;#&#125; &#123;# &#123;% csrf_token %&#125;#&#125; &#123;##&#125; &#123;# &#123;% for field in form %&#125;#&#125; &#123;##&#125; &#123;# &lt;div&gt;#&#125; &#123;# &lt;label for=\"\"&gt;&#123;&#123; field.label &#125;&#125;&lt;/label&gt;#&#125; &#123;# &#123;&#123; field &#125;&#125;#&#125; &#123;# &lt;/div&gt;#&#125; &#123;##&#125; &#123;# &#123;% endfor %&#125;#&#125; &#123;##&#125; &#123;# &lt;input type=\"submit\"&gt;#&#125; &#123;#&lt;/form&gt;#&#125; &#123;##&#125; &#123;#&lt;h3&gt;forms组件渲染方式3&lt;/h3&gt;#&#125; &#123;##&#125; &#123;#&lt;form action=\"\" method=\"post\"&gt;#&#125; &#123;# &#123;% csrf_token %&#125;#&#125; &#123;##&#125; &#123;# &#123;&#123; form.as_p &#125;&#125;#&#125; &#123;##&#125; &#123;# &lt;input type=\"submit\"&gt;#&#125; &#123;#&lt;/form&gt;#&#125; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 4.cookie和session COOKIE 123456789101112Cookie：保存在浏览器端的键值对（应用：登录认证）Cookie的工作原理是：由服务器产生内容，浏览器收到请求后保存在本地；当浏览器再次访问时，浏览器会自动带上Cookie，这样服务器就能通过Cookie的内容来判断这个是“谁”了。----------------------------------------------------------obj=HttpResponse() 存cookie: obj.set_cookie(key,value,max_age(IE浏览器版本低不认识)/expires) obj.set_signed_cookie() # 设置加密方式的cookie; 删除COOKIE:obj.delete_cookie() # 删除用户浏览器上之前设置的usercookie值 取COOKIE：request.COOKIES.get(key) request.get_signed_cookie() # 敏感信息还是在前端可以看到----------------------------------------------------------csrf_token 也是在cookie中的，客户端/服务端均可设置 1234Cookie规范 Cookie大小上限为4KB； 一个服务器最多在客户端浏览器上保存20个Cookie； 一个浏览器最多保存300个Cookie； 12345678910cookie参数 ①key, 键 ②value=&apos;&apos;, 值 ④max_age=None, 超时时间 cookie需要延续的时间（以秒为单位）如果参数是\\ None`` ，这个cookie会延续到浏览器关闭为止 ⑤expires=None, 超时时间(IE requires expires, so set it if hasn&apos;t been already.) ⑥path=&apos;/&apos;, Cookie生效的路径，/ 表示根路径，特殊的：根路径的cookie可以被任何url的页面访问，浏览器只会把cookie回传给带有该路径的页面，这样可以避免将cookie传给站点中的其他的应用。 ⑦domain=None, Cookie生效的域名 你可用这个参数来构造一个跨站cookie。如， domain=&quot;.example.com&quot;所构造的cookie对下面这些站点都是可读的：www.example.com 、 www2.example.com 和an.other.sub.domain.example.com 。如果该参数设置为 None ，cookie只能由设置它的站点读取 ⑧secure=False, 浏览器将通过HTTPS来回传cookie ⑨httponly=False 只能http协议传输，无法被JavaScript获取（不是绝对，底层抓包可以获取到也可以被覆盖） 123456789101112131415161718192021222324252627282930313233Cookie登录检验+装饰器def login_auth(func): def inner(request,*args,**kwargs): next_url=request.get_full_path() if request.COOKIES.get('is_login'): return func(request,*args,**kwargs) else: return redirect('cookie_login/?next=%s'%next_url) return inner@login_authdef cookie_order(request): return HttpResponse('我是订单页面')@login_authdef cookie_index(request): name=request.COOKIES.get('username') return render(request,'cookie_index.html',&#123;'name':name&#125;)def cookie_login(request): if request.method =='POST': next_url=request.GET.get('next') name=request.POST.get('name') password=request.POST.get('password') if name == 'lqz' and password == '123': import datetime now=datetime.datetime.now().strftime('%Y-%m-%d %X') print(now) obj=redirect(next_url) obj.set_cookie('is_login',True) obj.set_cookie('username',name) obj.set_cookie('login_time',now) return obj return render(request, 'cookie_login.html') session 1234567891011121314151617181920Session（字典的操作session基本都满足）：保存在服务端的键值对,内部机制依赖于cookieSession一般在很多页面都需要用到,所有可以用装饰器的方式来对多个函数进行装饰,减少重复代码存：request.session[key]=value取：request.session.get(key) request.session.iterkeys(), 不会直接取出值,只会在循环迭代时取值 request.session.session_key, 当前用户session的随机字符串 request.session.clear_expired(), 清除所有session已过期的数据 request.session.exists(\"key\"), 检查当期那用户session是否在数据库中 request.session.delete(\"key\"), 删除当前用户session数据 清除除session：request.session.clear() # 所有 键、值、键值对request.session.keys()request.session.values()request.session.items()request.session.iterkeys()request.session.itervalues()request.session.iteritems() 12345678910111213141516171819202122232425262728settings.py1. 数据库SessionSESSION_ENGINE = 'django.contrib.sessions.backends.db' # 引擎（默认）2. 缓存SessionSESSION_ENGINE = 'django.contrib.sessions.backends.cache' # 引擎SESSION_CACHE_ALIAS = 'default' # 使用的缓存别名（默认内存缓存，也可以是memcache），此处别名依赖缓存的设置3. 文件SessionSESSION_ENGINE = 'django.contrib.sessions.backends.file' # 引擎SESSION_FILE_PATH = None # 缓存文件路径，如果为None，则使用tempfile模块获取一个临时地址tempfile.gettempdir() 4. 缓存+数据库SESSION_ENGINE = 'django.contrib.sessions.backends.cached_db' # 引擎5. 加密Cookie SessionSESSION_ENGINE = 'django.contrib.sessions.backends.signed_cookies' # 引擎其他公用设置项：SESSION_COOKIE_NAME ＝ \"sessionid\" # Session的cookie保存在浏览器上时的key，即：sessionid＝随机字符串（默认）SESSION_COOKIE_PATH ＝ \"/\" # Session的cookie保存的路径（默认）SESSION_COOKIE_DOMAIN = None # Session的cookie保存的域名（默认）SESSION_COOKIE_SECURE = False # 是否Https传输cookie（默认）SESSION_COOKIE_HTTPONLY = True # 是否Session的cookie只支持http传输（默认）SESSION_COOKIE_AGE = 1209600 # Session的cookie失效日期（2周）（默认）SESSION_EXPIRE_AT_BROWSER_CLOSE = False # 是否关闭浏览器使得Session过期（默认）SESSION_SAVE_EVERY_REQUEST = False # 是否每次请求都保存Session，默认修改之后才保存（默认） CBV 加装饰器 12345678910111213141516from django import viewsfrom django.utils.decorators import method_decorator# @method_decorator(login_auth,name='get')# @method_decorator(login_auth,name='post')class UserList(views.View): # @method_decorator(login_auth) def dispatch(self, request, *args, **kwargs): obj=super().dispatch(request, *args, **kwargs) return obj @method_decorator(login_auth) def get(self,request): return HttpResponse('我是用户列表') def post(self,request): return HttpResponse('我是用户列表') 5.中间件1中间件，是介于request与response处理之间的一道处理过程，相对比较轻量级，并且在全局上改变django的输入与输出。 settings.py 12345678MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware',] 自定义中间件（MyMiddlewares.py） 1234567891011121314151617181920from django.utils.deprecation import MiddlewareMixinfrom django.shortcuts import HttpResponseclass MyMiddleware1(MiddlewareMixin): def process_request(self,request): print(\"MyMiddleware1请求\") def process_response(self,request,response): print(\"MyMiddleware1返回\") return responseclass MyMiddleware2(MiddlewareMixin): def process_request(self,request): print(\"MyMiddleware2请求\") #return HttpResponse(\"Md2中断\") def process_response(self,request,response): print(\"MyMiddleware2返回\") return response views.py 123def index(request): print(\"view函数...\") return HttpResponse(\"OK\") settins.py中注册自定义中间件 12345MIDDLEWARE = [ \"...\", \"MyMiddlewares.MyMiddleware1\", \"MyMiddlewares.MyMiddleware2\",] 中间件中的几个方法（主要用到request和response） 123456789process_request(self,request)process_view(self, request, callback, callback_args, callback_kwargs)process_template_response(self,request,response)process_exception(self, request, exception)process_response(self, request, response) 中间件和视图函数的联系 123456 中间件的process_request方法是在执行视图函数之前执行的。 当配置多个中间件时，会按照MIDDLEWARE中的注册顺序，也就是列表的索引值，从前到后依次执行的。 不同中间件之间传递的request都是同一个对象 总结： 多个中间件中的process_response方法是按照MIDDLEWARE中的注册顺序倒序执行的，也就是说第一个中间件的process_request方法首先执行，而它的process_response方法最后执行，最后一个中间件的process_request方法最后一个执行，它的process_response方法是最先执行。 中间件的应用 ① IP频率限制 1某些IP访问服务器的频率过高，进行拦截，比如限制每分钟不能超过20次。 ② URL访问过滤 123456假设用户访问的是login视图（可以通过）但是访问其他视图，需要检测是不是有session认证，已经有了放行，没有返回login，这样就省得在多个视图函数上写装饰器了！&apos;django.contrib.sessions.middleware.SessionMiddleware&apos;,&apos;django.contrib.auth.middleware.AuthenticationMiddleware&apos;, CSRF_TOKEN跨站请求伪造 定义 1一种对网站的恶意利用，尽管听起来像跨站脚本（XSS），但它与XSS非常不同，XSS利用站点内的信任用户，而CSRF则通过伪装来自受信任用户的请求来利用受信任的网站。与XSS攻击相比，CSRF攻击往往不大流行（因此对其进行防范的资源也相当稀少）和难以防范，所以被认为比XSS更具危险性 CSRF攻击防范 ①方式一：验证 HTTP Referer 字段 12345 在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。若 Referer 中记录的不是指向自己网站，则认为是 CSRF 攻击，拒绝该访问。优点： 简单易行，网站的普通开发人员不需要操心 CSRF 的漏洞，只需要在最后给所有安全敏感的请求统一增加一个拦截器来检查 Referer 的值就可以。缺点： Referer 值会记录用户的访问来源，用户认为这样会侵犯到隐私权，特别是有些组织担心 Referer 值会把组织内网中的某些信息泄露到外网中。因此，用户可以设置浏览器使其在发送请求时不再提供 Referer。当他们正常访问银行网站时，网站会因为请求没有 Referer 值而认为是 CSRF 攻击，拒绝合法用户的访问。 ②方式二：在请求地址中添加 token 并验证 1234这种方法要比检查 Referer 要安全一些，token 可以在用户登录后产生并放于 session 之中，然后在每次请求时把 token 从 session 中拿出，与请求中的 token 进行比对，但这种方法的难点在于如何把 token 以参数的形式加入请求。对于 GET 请求，token 将附在请求地址之后，这样 URL 就变成 http://url?csrftoken=tokenvalue。对于 POST 请求来说，要在 form 的最后加上 &lt;input type=”hidden” name=”csrftoken” value=”tokenvalue”/&gt;，这样就把 token 以参数的形式加入请求了。但是，在一个网站中，可以接受请求的地方非常多，要对于每一个请求都加上 token 是很麻烦的，并且很容易漏掉，通常使用的方法就是在每次页面加载时，使用 javascript 遍历整个 dom 树，对于 dom 中所有的 a 和 form 标签后加入 token。这样可以解决大部分的请求，但是对于在页面加载之后动态生成的 html 代码，这种方法就没有作用，还需要程序员在编码时手动添加 token。 ③方式三：在 HTTP 头中自定义属性并验证 1这里并不是把 token 以参数的形式置于 HTTP 请求之中，而是把它放到 HTTP 头中自定义的属性里。通过 XMLHttpRequest 这个类，可以一次性给所有该类请求加上 csrftoken 这个 HTTP 头属性，并把 token 值放入其中。这样解决了上种方法在请求中加入 token 的不便，同时，通过 XMLHttpRequest 请求的地址不会被记录到浏览器的地址栏，也不用担心 token 会透过 Referer 泄露到其他网站中去。 6.Auth模块（Django自带的用户认证模块）1from django.contrib import auth authenticate() 12user = authenticate(username=&apos;usernamer&apos;,password=&apos;password&apos;)用户认证功能，即验证用户名以及密码是否正确，一般需要username 、password两个关键字参数。认证成功（用户名和密码正确有效），便会返回一个 User 对象。authenticate()会在该 User 对象上设置一个属性来标识后端已经认证了该用户，且该信息在后续的登录过程中是需要的。 login(HttpRequest, user) 1函数接受一个HttpRequest对象，以及一个经过认证的User对象。实现一个用户登录的功能。它本质上会在后端为该用户生成相关session数据。 12345678910111213from django.contrib.auth import authenticate, login def my_view(request): username = request.POST['username'] password = request.POST['password'] user = authenticate(username=username, password=password) if user is not None: login(request, user) # Redirect to a success page. ... else: # Return an 'invalid login' error message. ... logout(request) 1函数接受一个HttpRequest对象，无返回值。用该函数时，当前请求的session信息会全部清除。该用户即使没有登录，使用该函数也不会报错。 12345from django.contrib.auth import logout def logout_view(request): logout(request) # Redirect to a success page. is_authenticated() 1用来判断当前请求是否通过了认证。 123def my_view(request): if not request.user.is_authenticated(): return redirect('%s?next=%s' % (settings.LOGIN_URL, request.path)) login_requierd() 123456auth 给我们提供的一个装饰器工具，用来快捷的给某个视图添加登录校验。若用户没有登录，则会跳转到django默认的 登录URL &apos;/accounts/login/ &apos; 并传递当前访问url的绝对路径 (登陆成功后，会重定向到该路径)。如果需要自定义登录的URL，则需要在settings.py文件中通过LOGIN_URL进行修改。LOGIN_URL = &apos;/login/&apos; # 这里配置成你项目登录页面的路由 12345from django.contrib.auth.decorators import login_required @login_requireddef my_view(request): ... create_user() 1auth 提供的一个创建新用户的方法，需要提供必要参数（username、password）等。 12from django.contrib.auth.models import Useruser = User.objects.create_user（username='用户名',password='密码',email='邮箱',...） create_superuser() 1auth 提供的一个创建新的超级用户的方法，需要提供必要参数（username、password）等。 12from django.contrib.auth.models import Useruser = User.objects.create_superuser（username='用户名',password='密码',email='邮箱',...） check_password(password) 1auth 提供的一个检查密码是否正确的方法，需要提供当前请求用户的密码。密码正确返回True，否则返回False。 1res = user.check_password('密码') set_password(password) 1234auth 提供的一个修改密码的方法，接收 要设置的新密码 作为参数。&lt;!-- 注意 --&gt;设置完一定要调用用户对象的save方法！！！ 123456789101112131415161718192021222324@login_requireddef set_password(request): user = request.user err_msg = '' if request.method == 'POST': old_password = request.POST.get('old_password', '') new_password = request.POST.get('new_password', '') repeat_password = request.POST.get('repeat_password', '') # 检查旧密码是否正确 if user.check_password(old_password): if not new_password: err_msg = '新密码不能为空' elif new_password != repeat_password: err_msg = '两次密码不一致' else: user.set_password(new_password) # 设置密码 user.save() # 一定要保存 return redirect(\"/login/\") else: err_msg = '原密码输入错误' content = &#123; 'err_msg': err_msg, &#125; return render(request, 'set_password.html', content) User对象的属性 1234User对象属性：username， passwordis_staff ： 用户是否拥有网站的管理权限.is_active ： 是否允许用户登录, 设置为 False，可以在不删除用户的前提下禁止用户登录。 扩展auth_user表 自定义Model类，继承AbstractUser类，又能使用Django强大的认证系统了 123456789101112131415from django.contrib.auth.models import AbstractUserclass UserInfo(AbstractUser): \"\"\"用户信息表\"\"\" nid = models.AutoField(primary_key=True) phone = models.CharField(max_length=11, null=True, unique=True) def __str__(self): return self.username # 注意 扩展了内置的auth_user表之后，一定要在settings.py中告诉Django，我现在使用我新定义的UserInfo表来做用户认证。 一旦我们指定了新的认证系统所使用的表，我们就需要重新在数据库中创建该表，而不能继续使用原来默认的auth_user表了。# 引用Django自带的User表，继承使用时需要设置AUTH_USER_MODEL = \"app名.UserInfo\" 7.ContentType（Django提供的ContentType表 ） models.py 12345678910111213141516171819202122232425from django.db import modelsfrom django.contrib.contenttypes.models import ContentTypefrom django.contrib.contenttypes.fields import GenericForeignKey, GenericRelationclass Course(models.Model): title = models.CharField(max_length=32) # 不会在数据库中生成字段，只用于数据库操作 # policy = GenericRelation('PricePolicy',object_id_field='object_id',content_type_field='contentType')class DegreeCourse(models.Model): title = models.CharField(max_length=32)class PricePolicy(models.Model): # 跟Django提供的ContentType表做外键关联 contentType = models.ForeignKey(to=ContentType) # 正数 object_id = models.PositiveIntegerField() # 引入一个字段，不会在数据库中创建，只用来做数据库操作 # content_obj = GenericForeignKey('contentType', 'object_id') period = models.CharField(max_length=32) price = models.FloatField() views.py 12345678910111213141516171819202122232425262728293031from app01 import modelsdef test(request): import json # 方式一插入价格规则 # ret=models.ContentType.objects.filter(model='course').first() # course=models.Course.objects.filter(pk=1).first() # print(ret.id) # models.PricePolicy.objects.create(period='30',price=100,object_id=course.id,contentType_id=ret.id) # 方式二插入价格规则 # course=models.Course.objects.filter(pk=1).first() # # content_obj=course 会自动的把课程id放到object_id上，并且去ContentType表中查询课程表的id，放到contentType上 # models.PricePolicy.objects.create(period='60',price=800,content_obj=course) # 增加学位课，价格规则 # degreecourse = models.DegreeCourse.objects.filter(pk=1).first() # models.PricePolicy.objects.create(period='60', price=800, content_obj=degreecourse) # 查询所有价格策略，并且显示对应的课程名称 # ret=models.PricePolicy.objects.all() # for i in ret: # print(i.price) # print(i.period) # # content_obj 就是代指关联的课程，或者学位课程的那个对象 # print(type(i.content_obj)) # print(i.content_obj.title) # 通过课程id，获取课程信息和价格策略 course=models.Course.objects.filter(pk=1).first() print(course.policy.all()) return render(request,'test.html') 七、Rest Framework1.RESTful规范 定义： ①REST是一种软件架构风格，REST是Representational State Transfer的简称，中文翻译为“表征状态转移” ②所有的数据，不过是通过网络获取的还是操作（增删改查）的数据，都是资源，将一切数据视为资源是REST区别与其他架构风格的最本质属性 ③REST从资源的角度类审视整个网络，它将分布在网络中某个节点的资源通过URL进行标识，客户端应用通过URL来获取资源的表征，获得这些表征致使这些应用转变状态 RESTful API设计 ①API与用户的通信协议，总是使用[HTTPs协议 ②域名 ​ https://api.example.com —尽量将API部署在专用域名(会存在跨域问题) ​ https://example.org/api/ —API很简单 ③路径，视网络上任何东西都是资源，均使用名词表示（可复数） https://api.example.com/zoos ④method METHOD Description GET 从服务器取出资源（一项或多项） POST 在服务器新建一个资源 PUT 在服务器更新资源（客户端提供改变后的完整资源） PATCH 在服务器更新资源（客户端提供改变的属性） DELETE 从服务器删除资源 ⑤过滤，通过在url上传参的形式传递搜索条件 https://api.example.com/v1/zoos?limit=10：指定返回记录的数量 https://api.example.com/v1/zoos?offset=10：指定返回记录的开始位置 https://api.example.com/v1/zoos?page=2&amp;per_page=100：指定第几页，以及每页的记录数 ⑥状态码 123456789101112200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务）204 NO CONTENT - [DELETE]：用户删除数据成功。400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。 ⑦返回结果，针对不同操作，服务器向用户返回的结果应该符合以下规范。 123456GET /collection：返回资源对象的列表（数组）GET /collection/resource：返回单个资源对象POST /collection：返回新生成的资源对象PUT /collection/resource：返回完整的资源对象PATCH /collection/resource：返回完整的资源对象DELETE /collection/resource：返回一个空文档 ⑧错误处理，应返回错误信息，error当做key。 123&#123; error: \"Invalid API key\"&#125; ⑨Hypermedia API，RESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。 123456&#123;\"link\": &#123; \"rel\": \"collection https://www.example.com/zoos\", \"href\": \"https://api.example.com/zoos\", \"title\": \"List of zoos\", \"type\": \"application/vnd.yourformat+json\"&#125;&#125; ⑩版本 URL，如：https://api.example.com/v1/ 2.APIView 安装 123方式一：pip3 install djangorestframework方式二：pycharm图形化界面安装方式三：pycharm命令行下安装（装在当前工程所用的解释器下） Djangorestframework的APIView分析 ① as_view() 123456789101112131415161718192021222324@classmethod def as_view(cls, **initkwargs): \"\"\" Store the original class on the view function. This allows us to discover information about the view when we do URL reverse lookups. Used for breadcrumb generation. \"\"\" if isinstance(getattr(cls, 'queryset', None), models.query.QuerySet): def force_evaluation(): raise RuntimeError( 'Do not evaluate the `.queryset` attribute directly, ' 'as the result will be cached and reused between requests. ' 'Use `.all()` or call `.get_queryset()` instead.' ) cls.queryset._fetch_all = force_evaluation view = super(APIView, cls).as_view(**initkwargs) view.cls = cls view.initkwargs = initkwargs # Note: session based authentication is explicitly CSRF validated, # all other authentication is CSRF exempt. return csrf_exempt(view) ②dispatch() 12345678910111213141516171819202122232425262728def dispatch(self, request, *args, **kwargs): \"\"\" `.dispatch()` is pretty much the same as Django's regular dispatch, but with extra hooks for startup, finalize, and exception handling. \"\"\" self.args = args self.kwargs = kwargs request = self.initialize_request(request, *args, **kwargs) self.request = request self.headers = self.default_response_headers # deprecate? try: self.initial(request, *args, **kwargs) # Get the appropriate handler method if request.method.lower() in self.http_method_names: handler = getattr(self, request.method.lower(), self.http_method_not_allowed) else: handler = self.http_method_not_allowed response = handler(request, *args, **kwargs) except Exception as exc: response = self.handle_exception(exc) self.response = self.finalize_response(request, response, *args, **kwargs) return self.response ③initialize_request(重新封装了request对象) 12345678910111213def initialize_request(self, request, *args, **kwargs): \"\"\" Returns the initial request object. \"\"\" parser_context = self.get_parser_context(request) return Request( request, parsers=self.get_parsers(), authenticators=self.get_authenticators(), negotiator=self.get_content_negotiator(), parser_context=parser_context ) ④initial方法（内部调用认证，权限和频率） 1234567891011121314151617181920def initial(self, request, *args, **kwargs): \"\"\" Runs anything that needs to occur prior to calling the method handler. \"\"\" self.format_kwarg = self.get_format_suffix(**kwargs) # Perform content negotiation and store the accepted info on the request neg = self.perform_content_negotiation(request) request.accepted_renderer, request.accepted_media_type = neg # Determine the API version, if versioning is in use. version, scheme = self.determine_version(request, *args, **kwargs) request.version, request.versioning_scheme = version, scheme # Ensure that the incoming request is permitted self.perform_authentication(request) self.check_permissions(request) self.check_throttles(request)initial方法（内部调用认证，权限和频率） 3.序列化组件 Django 自带序列化组件 12345from django.core import serializersdef index(request): book_list = Book.objects.all() ret = serializers.serialize(\"json\", book_list) return HttpResponse(ret) rest-framework序列化之Serializer ① models.py 123456789101112131415161718192021222324from django.db import models# Create your models here.class Book(models.Model): title=models.CharField(max_length=32) price=models.IntegerField() pub_date=models.DateField() publish=models.ForeignKey(\"Publish\") authors=models.ManyToManyField(\"Author\") def __str__(self): return self.titleclass Publish(models.Model): name=models.CharField(max_length=32) email=models.EmailField() def __str__(self): return self.nameclass Author(models.Model): name=models.CharField(max_length=32) age=models.IntegerField() def __str__(self): return self.name ②views.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849from rest_framework.views import APIViewfrom rest_framework.response import Responsefrom app01.models import *from django.shortcuts import HttpResponsefrom django.core import serializersfrom rest_framework import serializersclass BookSerializers(serializers.Serializer): title=serializers.CharField(max_length=32) price=serializers.IntegerField() pub_date=serializers.DateField() publish=serializers.CharField(source=\"publish.name\") #authors=serializers.CharField(source=\"authors.all\") authors=serializers.SerializerMethodField() def get_authors(self,obj): temp=[] for author in obj.authors.all(): temp.append(author.name) return temp #此处可以继续用author的Serializers， # def get_authors(self,obj): # ret=obj.authors.all() # ss=AuthorSerializer(ret,many=True) # return ss.data class BookViewSet(APIView): def get(self,request,*args,**kwargs): book_list=Book.objects.all() # 序列化方式1: # from django.forms.models import model_to_dict # import json # data=[] # for obj in book_list: # data.append(model_to_dict(obj)) # print(data) # return HttpResponse(\"ok\") # 序列化方式2: # data=serializers.serialize(\"json\",book_list) # return HttpResponse(data) # 序列化方式3: bs=BookSerializers(book_list,many=True) #many=True代表有多条数据，如果只有一条数据，many=False return Response(bs.data) # 序列化方式4: # ret=models.Book.objects.all().values('nid','title') # dd=list(ret) # return HttpResponse(json.dumps(dd)) source1234567891011121314151617181920source 如果是字段，会显示字段，如果是方法，会执行方法，不用加括号（authors=serializers.CharField(source='authors.all')）如在模型中定义一个方法，直接可以在在source指定执行class UserInfo(models.Model): user_type_choices = ( (1,'普通用户'), (2,'VIP'), (3,'SVIP'), ) user_type = models.IntegerField(choices=user_type_choices) username = models.CharField(max_length=32,unique=True) password = models.CharField(max_length=64)#视图ret=models.UserInfo.objects.filter(pk=1).first()aa=ret.get_user_type_display()#serializerxx=serializers.CharField(source='get_user_type_display') rest-framework序列化之ModelSerializer 123456789101112131415class BookSerializers(serializers.ModelSerializer): class Meta: model = models.Book # fields = \"__all__\" fields=['nid','title','authors','publish'] # exclude=('nid',) #不能跟fields同时用 # depth = 1 #深度控制，层数越多，响应越慢 publish=serializers.SerializerMethodField() def get_publish(self,obj): return obj.publish.name authors=serializers.SerializerMethodField() def get_authors(self,obj): ret=obj.authors.all() ss=AuthorSerializer(ret,many=True) return ss.data 序列化组件之请求数据校验和保存功能 123456789101112131415class BookSerializers(serializers.ModelSerializer): class Meta: model=Book fields=\"__all__\"class BookView(APIView): def post(self, request): # 添加一条数据 print(request.data) bs=BookSerializers(data=request.data) if bs.is_valid(): bs.save() # 生成记录 return Response(bs.data) else: return Response(bs.errors) 序列化组件源码分析 12345序列化组件，先调用__new__方法，如果many=True，生成ListSerializer对象，如果为False，生成Serializer对象序列化对象.data方法--调用父类data方法---调用对象自己的to_representation（自定义的序列化类无此方法，去父类找）Aerializer类里有to_representation方法，for循环执行attribute = field.get_attribute(instance)再去Field类里去找get_attribute方法，self.source_attrs就是被切分的source，然后执行get_attribute方法，source_attrs当参数传过去，判断是方法就加括号执行，是属性就把值取出来 4.视图组件 基本视图 1234urlpatterns=[ url(r'^publish/$', views.PublishView.as_view()), url(r'^publish/(?P&lt;pk&gt;\\d+)/$', views.PublishDetailView.as_view()),] 1234567891011121314151617181920212223242526272829303132333435363738394041424344class PublishSerializers(serializers.ModelSerializer): class Meta: model=models.Publish fields='__all__'class PublishView(APIView): def get(self, request): publish_list = models.Publish.objects.all() bs = PublishSerializers(publish_list, many=True) # 序列化数据 return Response(bs.data) def post(self, request): # 添加一条数据 print(request.data) bs=PublishSerializers(data=request.data) if bs.is_valid(): bs.save() # 生成记录 return Response(bs.data) else: return Response(bs.errors)class PublishDetailView(APIView): def get(self,request,pk): publish_obj=models.Publish.objects.filter(pk=pk).first() bs=PublishSerializers(publish_obj,many=False) return Response(bs.data) def put(self,request,pk): publish_obj = models.Publish.objects.filter(pk=pk).first() bs=PublishSerializers(data=request.data,instance=publish_obj) if bs.is_valid(): bs.save() # update return Response(bs.data) else: return Response(bs.errors) def delete(self,request,pk): models.Publish.objects.filter(pk=pk).delete() return Response(\"\") mixin类和 generice类编写视图 12345678910111213141516171819202122from rest_framework.mixins import CreateModelMixin,RetrieveModelMixin,ListModelMixin,UpdateModelMixin,DestroyModelMixinfrom rest_framework.generics import GenericAPIViewclass PublishView(ListModelMixin,CreateModelMixin,GenericAPIView): queryset=models.Publish.objects.all() serializer_class=PublishSerializers def get(self, request): return self.list(request) def post(self, request): return self.create(request)class PublishDetailView(RetrieveModelMixin,UpdateModelMixin,DestroyModelMixin,GenericAPIView): queryset=models.Publish.objects.all() serializer_class=PublishSerializers def get(self,request,*args,**kwargs): # retrieve()创建并保存 return self.retrieve(request,*args,**kwargs) def put(self,request,*args,**kwargs): return self.update(request,*args,**kwargs) def delete(self,request,*args,**kwargs): return self.destroy(request,*args,**kwargs) generices 下的ListCreateAPIView，RetieveUpdateDestroyAPIView 12345678from rest_framework.generics import ListCreateAPIView,RetrieveUpdateDestroyAPIViewclass PublishView(ListCreateAPIView): queryset=models.Publish.objects.all() serializer_class=PublishSerializersclass PublishDetailView(RetrieveUpdateDestroyAPIView): queryset=models.Publish.objects.all() serializer_class=PublishSerializers ModelViewSet 12345urlpatterns=[ url(r'^publish/$', views.PublishView.as_view(&#123;'get':'list','post':'create'&#125;)), url(r'^publish/(?P&lt;pk&gt;\\d+)/$', views.PublishView.as_view(&#123;'get':'retrieve','put':'update','delete':'destroy'&#125;)),视图：] 1234from rest_framework.viewsets import ModelViewSetclass PublishView(ModelViewSet): queryset=models.Publish.objects.all() serializer_class=PublishSerializers 5.解析器、认证组件、频率组件、权限组件5.1 解析器 作用 12根据请求头 content-type 选择对应的解析器对请求体内容进行处理。有application/json，x-www-form-urlencoded，form-data等格式 使用解析器 12345678910111213141516171819全局使用在settings.py中配置REST_FRAMEWORK = &#123; # 解析器 'DEFAULT_PARSER_CLASSES':[ 'rest_framework.parsers.JSONParser' 'rest_framework.parsers.FormParser' 'rest_framework.parsers.MultiPartParser' ], # 全局使用认证组件 \"DEFAULT_AUTHENTICATION_CLASSES\":[\"app01.service.auth.Authentication\",], # 全局使用权限组件 \"DEFAULT_AUTHENTICATION_CLASSES\":[\"app01.service.auth.Authentication\",], \"DEFAULT_PERMISSION_CLASSES\":[\"app01.service.permissions.SVIPPermission\",] # 全局使用频率组件,1min访问3次 'DEFAULT_THROTTLE_RATES':&#123; 'luffy':'3/m' &#125;&#125; 12345urls.pyurlpatterns = [ url(r'test/', TestView.as_view()),] 12345678910111213141516171819202122views.pyfrom rest_framework.views import APIViewfrom rest_framework.response import Responsefrom rest_framework.request import Requestfrom rest_framework.parsers import JSONParser,FormParser,MultiPartParserclass TestView(APIView): # 局部解析器,为MultiPartParser时,前端的form表单中必须有enctype=\"multipart/form-data\" parser_classes = [JSONParser,FormParser,MultiPartParser ] def post(self, request, *args, **kwargs): print(request.content_type) # 获取请求的值，并使用对应的JSONParser进行处理 print(request.data) # application/x-www-form-urlencoded 或 multipart/form-data时，request.POST中才有值 print(request.POST) print(request.FILES) return Response('POST请求，响应内容') def put(self, request, *args, **kwargs): return Response('PUT请求，响应内容') 源码分析 123456789101112131415161718192021222324在调用request.data时，才进行解析，由此入手 @property def data(self): if not _hasattr(self, '_full_data'): self._load_data_and_files() return self._full_data查看self._load_data_and_files()方法----&gt;self._data, self._files = self._parse() def _parse(self): #用户请求头里content_type的值 media_type = self.content_type #self.parsers 就是用户配置的parser_classes = [FileUploadParser,FormParser ] #self里就有content_type，传入此函数 parser = self.negotiator.select_parser(self, self.parsers)查看self.negotiator.select_parser(self, self.parsers) def select_parser(self, request, parsers): #同过media_type和request.content_type比较，来返回解析器，然后调用解析器的解析方法 #每个解析器都有media_type = 'multipart/form-data'属性 for parser in parsers: if media_type_matches(parser.media_type, request.content_type): return parser return None最终调用parser的解析方法来解析parsed = parser.parse(stream, media_type, self.parser_context) 123456789101112131415161718192021222324252627282930313233343536373839Request实例化，parsers=self.get_parsers() Request( request, parsers=self.get_parsers(), authenticators=self.get_authenticators(), negotiator=self.get_content_negotiator(), parser_context=parser_context )get_parsers方法，循环实例化出self.parser_classes中类对象 def get_parsers(self): return [parser() for parser in self.parser_classes] self.parser_classes 先从类本身找，找不到去父类找即APIVIew 中的 parser_classes = api_settings.DEFAULT_PARSER_CLASSESapi_settings是一个对象，对象里找DEFAULT_PARSER_CLASSES属性，找不到，会到getattr方法 def __getattr__(self, attr): if attr not in self.defaults: raise AttributeError(\"Invalid API setting: '%s'\" % attr) try: #调用self.user_settings方法，返回一个字典，字典再取attr属性 val = self.user_settings[attr] except KeyError: # Fall back to defaults val = self.defaults[attr] # Coerce import strings into classes if attr in self.import_strings: val = perform_import(val, attr) # Cache the result self._cached_attrs.add(attr) setattr(self, attr, val) return valuser_settings方法 ，通过反射去setting配置文件里找REST_FRAMEWORK属性，找不到，返回空字典 @property def user_settings(self): if not hasattr(self, '_user_settings'): self._user_settings = getattr(settings, 'REST_FRAMEWORK', &#123;&#125;) return self._user_settings 5.2 认证组件 models.py 12345678class User(models.Model): username=models.CharField(max_length=32) password=models.CharField(max_length=32) user_type=models.IntegerField(choices=((1,'超级用户'),(2,'普通用户'),(3,'二笔用户')))class UserToken(models.Model): user=models.OneToOneField(to='User') token=models.CharField(max_length=64) 新建认证类 1234567891011from rest_framework.authentication import BaseAuthenticationclass TokenAuth(): def authenticate(self, request): token = request.GET.get('token') token_obj = models.UserToken.objects.filter(token=token).first() if token_obj: return else: raise AuthenticationFailed('认证失败') def authenticate_header(self,request): pass views.py 1234567891011121314151617181920212223242526272829303132333435def get_random(name): import hashlib import time md=hashlib.md5() md.update(bytes(str(time.time()),encoding='utf-8')) md.update(bytes(name,encoding='utf-8')) return md.hexdigest()class Login(APIView): def post(self,reuquest): back_msg=&#123;'status':1001,'msg':None&#125; try: name=reuquest.data.get('name') pwd=reuquest.data.get('pwd') user=models.User.objects.filter(username=name,password=pwd).first() if user: token=get_random(name) models.UserToken.objects.update_or_create(user=user,defaults=&#123;'token':token&#125;) back_msg['status']='1000' back_msg['msg']='登录成功' back_msg['token']=token else: back_msg['msg'] = '用户名或密码错误' except Exception as e: back_msg['msg']=str(e) return Response(back_msg)class Course(APIView): # 局部使用 authentication_classes = [TokenAuth, ] def get(self, request): return HttpResponse('get') def post(self, request): return HttpResponse('post') token认证：存数据库的—&gt;Redis—&gt;不存数据库的认证源码分析123456789101112131415161718192021222324252627282930#Request对象的user方法@propertydef user(self):# the authentication classes provided to the request. if not hasattr(self, '_user'): with wrap_attributeerrors(): self._authenticate() return self._userdef _authenticate(self): for authenticator in self.authenticators: try: user_auth_tuple = authenticator.authenticate(self) except exceptions.APIException: self._not_authenticated() raise #认证成功，可以返回一个元组，但必须是最后一个验证类才能返回 if user_auth_tuple is not None: self._authenticator = authenticator self.user, self.auth = user_auth_tuple return self._not_authenticated() # self.authenticatorsdef get_authenticators(self): return [auth() for auth in self.authentication_classes]认证类使用顺序：先用视图类中的验证类，再用settings里配置的验证类，最后用默认的验证类 6.2 频率组件 局部使用 1permission_classes = [UserPermission,] 源码分析12345678910def check_permissions(self, request): for permission in self.get_permissions(): if not permission.has_permission(request, self): self.permission_denied( request, message=getattr(permission, 'message', None) ) # self.get_permissions()def get_permissions(self): return [permission() for permission in self.permission_classes] 6.3 权限组件 自定义限制 ip 的访问频率 1234567891011121314151617181920212223242526272829303132333435#（1）取出访问者ip# （2）判断当前ip不在访问字典里，添加进去，并且直接返回True,表示第一次访问，在字典里，继续往下走# （3）循环判断当前ip的列表，有值，并且当前时间减去列表的最后一个时间大于60s，把这种数据pop掉，这样列表中只有60s以内的访问时间，# （4）判断，当列表小于3，说明一分钟以内访问不足三次，把当前时间插入到列表第一个位置，返回True，顺利通过# （5）当大于等于3，说明一分钟内访问超过三次，返回False验证失败class MyThrottles(): VISIT_RECORD = &#123;&#125; def __init__(self): self.history=None def allow_request(self,request, view): #（1）取出访问者ip # print(request.META) ip=request.META.get('REMOTE_ADDR') import time ctime=time.time() # （2）判断当前ip不在访问字典里，添加进去，并且直接返回True,表示第一次访问 if ip not in self.VISIT_RECORD: self.VISIT_RECORD[ip]=[ctime,] return True self.history=self.VISIT_RECORD.get(ip) # （3）循环判断当前ip的列表，有值，并且当前时间减去列表的最后一个时间大于60s，把这种数据pop掉，这样列表中只有60s以内的访问时间， while self.history and ctime-self.history[-1]&gt;60: self.history.pop() # （4）判断，当列表小于3，说明一分钟以内访问不足三次，把当前时间插入到列表第一个位置，返回True，顺利通过 # （5）当大于等于3，说明一分钟内访问超过三次，返回False验证失败 if len(self.history)&lt;3: self.history.insert(0,ctime) return True else: return False def wait(self): import time ctime=time.time() return 60-(ctime-self.history[-1]) 局部使用 1throttle_classes = [MyThrottles,] 错误信息的中文提示 1234567891011121314151617class Course(APIView): authentication_classes = [TokenAuth, ] permission_classes = [UserPermission, ] throttle_classes = [MyThrottles,] def get(self, request): return HttpResponse('get') def post(self, request): return HttpResponse('post') def throttled(self, request, wait): from rest_framework.exceptions import Throttled class MyThrottled(Throttled): default_detail = '傻逼啊' extra_detail_singular = '还有 &#123;wait&#125; second.' extra_detail_plural = '出了 &#123;wait&#125; seconds.' raise MyThrottled(wait) 7.分页器 简单分页 1234567891011121314151617181920212223242526272829303132333435from rest_framework.pagination import PageNumberPagination# 一 基本使用：url=url=http://127.0.0.1:8000/pager/?page=2&amp;size=3，size无效class Pager(APIView): def get(self,request,*args,**kwargs): # 获取所有数据 ret=models.Book.objects.all() # 创建分页对象 page=PageNumberPagination() # 在数据库中获取分页的数据 page_list=page.paginate_queryset(ret,request,view=self) # 对分页进行序列化 ser=BookSerializer1(instance=page_list,many=True) return Response(ser.data)# 二 自定制 url=http://127.0.0.1:8000/pager/?page=2&amp;size=3# size=30，无效，最多5条class Mypage(PageNumberPagination): page_size = 2 page_query_param = 'page' # 定制传参 page_size_query_param = 'size' # 最大一页的数据 max_page_size = 5class Pager(APIView): def get(self,request,*args,**kwargs): # 获取所有数据 ret=models.Book.objects.all() # 创建分页对象 page=Mypage() # 在数据库中获取分页的数据 page_list=page.paginate_queryset(ret,request,view=self) # 对分页进行序列化 ser=BookSerializer1(instance=page_list,many=True) # return Response(ser.data) # 这个也是返回Response对象，但是比基本的多了上一页，下一页，和总数据条数（了解即可） return page.get_paginated_response(ser.data) 123456settings.pyREST_FRAMEWORK = &#123; # 每页显示两条 'PAGE_SIZE':2&#125; 123urlpatterns=[ url(r'^pager/$', views.Pager.as_view()),] 偏移分页 12345678910111213141516在第N个位置,向后查看N条数据# http://127.0.0.1:8000/pager/?offset=4&amp;limit=3from rest_framework.pagination import LimitOffsetPagination# 也可以自定制，同简单分页class Pager(APIView): def get(self,request,*args,**kwargs): # 获取所有数据 ret=models.Book.objects.all() # 创建分页对象 page=LimitOffsetPagination() # 在数据库中获取分页的数据 page_list=page.paginate_queryset(ret,request,view=self) # 对分页进行序列化 ser=BookSerializer1(instance=page_list,many=True) # return page.get_paginated_response(ser.data) return Response(ser.data) CursorPagination加密分页 1234567891011121314151617只能查看上页和下页from rest_framework.pagination import CursorPagination# 看源码，是通过sql查询，大于id和小于idclass Pager(APIView): def get(self,request,*args,**kwargs): # 获取所有数据 ret=models.Book.objects.all() # 创建分页对象 page=CursorPagination() page.ordering='nid' # 在数据库中获取分页的数据 page_list=page.paginate_queryset(ret,request,view=self) # 对分页进行序列化 ser=BookSerializer1(instance=page_list,many=True) # 可以避免页码被猜到 return page.get_paginated_response(ser.data) 8.响应器（渲染器） 作用 1根据 用户请求URL 或 用户可接受的类型，筛选出合适的 渲染组件。 内置渲染器 ①默认显示格式：BrowsableAPIRenderer（可以修改它的html文件） http://127.0.0.1:8000/test/?format=api http://127.0.0.1:8000/test.api ②显示json格式：JSONRenderer http://127.0.0.1:8000/test/?format=json http://127.0.0.1:8000/test.json ③表格方式：AdminRenderer http://127.0.0.1:8000/test/?format=admin http://127.0.0.1:8000/test.admin ④form表单方式：HTMLFormRenderer http://127.0.0.1:8000/test/?format=form http://127.0.0.1:8000/test.form 局部使用 1renderer_classes = [HTMLFormRenderer,BrowsableAPIRenderer ] 9.URL控制器 自定义路由（原始方式） 123456from django.conf.urls import urlfrom app01 import viewsurlpatterns = [ url(r'^books/$', views.BookView.as_view()), url(r'^books/(?P&lt;pk&gt;\\d+)$', views.BookDetailView.as_view()),] 半自动路由（视图继承ModelViewSet） 123456789urls.pyfrom django.conf.urls import urlfrom app01 import viewsurlpatterns = [ url(r'^publish/$', views.PublishView.as_view(&#123;'get':'list','post':'create'&#125;)), url(r'^publish/(?P&lt;pk&gt;\\d+)/$', views.PublishView.as_view(&#123;'get':'retrieve','put':'update','delete':'destroy'&#125;)),] 123456views.pyfrom rest_framework.viewsets import ModelViewSetclass PublishView(ModelViewSet): queryset=models.Publish.objects.all() serializer_class=PublishSerializers 全自动路由（自动生成路由） 123456789101112131415161718192021urls.pyfrom django.conf.urls import url,includefrom app01 import viewsfrom rest_framework import routersrouter=routers.DefaultRouter()# 两个参数，一个是匹配的路由，一个是视图中写的CBV的类router.register('publish',views.PublishView)urlpatterns = [ # http://127.0.0.1:8000/publish/format=json(渲染器通过这个判断，返回渲染的页面) # url(r'^publish/', views.PublishView.as_view(&#123;'get':'list','post':'create'&#125;)), # http://127.0.0.1:8000/publish.json(渲染器通过这个判断，返回渲染的页面) # url(r'^publish\\.(?P&lt;format&gt;\\w+)$', views.PublishView.as_view(&#123;'get':'list','post':'create'&#125;)), # 可以用 以下方式访问 # 1 http://127.0.0.1:8000/publish/ # 2 http://127.0.0.1:8000/publish.json # 3 http://127.0.0.1:8000/publish/3 # 4 http://127.0.0.1:8000/publish/3.json url(r'',include(router.urls))] 123456views.pyfrom rest_framework.viewsets import ModelViewSetclass PublishView(ModelViewSet): queryset=models.Publish.objects.all() serializer_class=PublishSerializers 10.版本控制 内置的版本控制类 1234567from rest_framework.versioning import QueryParameterVersioning,AcceptHeaderVersioning,NamespaceVersioning,URLPathVersioning#基于url的get传参方式：QueryParameterVersioning------&gt;如：/users?version=v1#基于url的正则方式：URLPathVersioning------&gt;/v1/users/#基于 accept 请求头方式：AcceptHeaderVersioning------&gt;Accept: application/json; version=1.0#基于主机名方法：HostNameVersioning------&gt;v1.example.com#基于django路由系统的namespace：NamespaceVersioning------&gt;example.com/v1/users/ 局部使用 12#在CBV类中加入versioning_class = URLPathVersioning 全局使用 123456REST_FRAMEWORK = &#123; 'DEFAULT_VERSIONING_CLASS':'rest_framework.versioning.QueryParameterVersioning', 'DEFAULT_VERSION': 'v1', # 默认版本(从request对象里取不到，显示的默认值) 'ALLOWED_VERSIONS': ['v1', 'v2'], # 允许的版本 'VERSION_PARAM': 'version' # URL中获取值的key&#125; 源码分析12345678910#执行determine_version，返回两个值，放到request对象里version, scheme = self.determine_version(request, *args, **kwargs)request.version, request.versioning_scheme = version, schemedef determine_version(self, request, *args, **kwargs): #当配置上版本类之后，就会实例化 if self.versioning_class is None: return (None, None) scheme = self.versioning_class() return (scheme.determine_version(request, *args, **kwargs), scheme) 八、settings.py配置1.APPEND_SLASH12APPEND_SLASH=True是否开启URL访问地址后面不为/跳转至带有/的路径的配置项 2.static（css文件，js文件，图片文件 ）1234STATIC_URL = '/static/'STATICFILES_DIRS = [ os.path.join(BASE_DIR, 'static'),] html页面对static静态文件的使用 12&lt;link rel=\"stylesheet\" href=\"/static/mycss.css\"&gt; &lt;script src=\"/static/jquery-3.3.1.js\"&gt;&lt;/script&gt; 3 数据库配置12345678910111213141516171819202122232425262728DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'lqz', 'USER': 'root', 'PASSWORD': '123456', 'HOST': '127.0.0.1', 'PORT': 3306, 'ATOMIC_REQUEST': True, 'OPTIONS': &#123; \"init_command\": \"SET storage_engine=MyISAM\", &#125; &#125;&#125;''''NAME':要连接的数据库，连接前需要创建好'USER':连接数据库的用户名'PASSWORD':连接数据库的密码'HOST':连接主机，默认本机'PORT':端口 默认3306'ATOMIC_REQUEST': True,设置为True统一个http请求对应的所有sql都放在一个事务中执行（要么所有都成功，要么所有都失败）。是全局性的配置， 如果要对某个http请求放水（然后自定义事务），可以用non_atomic_requests修饰器 'OPTIONS': &#123; \"init_command\": \"SET storage_engine=MyISAM\", &#125;设置创建表的存储引擎为MyISAM，INNODB''' 1234567891011# 注意1： 在mysql连接数据库前必须已经创建数据库，而上面的sqlite数据库下的db.sqlite3则是项目自动创建 USER和PASSWORD分别是数据库的用户名和密码。设置完后，再启动我们的Django项目前，我们需要激活我们的mysql。然后，启动项目，会报错：no module named MySQLdb 。这是因为django默认你导入的驱动是MySQLdb，可是MySQLdb 对于py3有很大问题，所以我们需要的驱动是PyMySQL 所以，我们只需要找到项目名文件下的__init__,在里面写入：import pymysqlpymysql.install_as_MySQLdb() 通过两条数据库迁移命令即可在指定的数据库中创建表python manage.py makemigrationspython manage.py migrate# 注意2: 确保配置文件中的INSTALLED_APPS中写入我们创建的app名称 打印orm转换过程中的sql 12345678910111213141516171819202122LOGGING = &#123; 'version': 1, 'disable_existing_loggers': False, 'handlers': &#123; 'console':&#123; 'level':'DEBUG', 'class':'logging.StreamHandler', &#125;, &#125;, 'loggers': &#123; 'django.db.backends': &#123; 'handlers': ['console'], 'propagate': True, 'level':'DEBUG', &#125;, &#125;&#125;or# 操作数据库时取出的对象objprint(obj.query) 九、创建Django0 安装Django 1pip install django 1 创建一个 Django project 1django-admin.py startproject mysite 2 在mysite目录下创建应用 1python manage.py startapp app01 3 启动Django项目 1python manage.py runserver http://ip:8000 十、跨域请求（同源策略） 定义 12345同源策略（Same origin policy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说Web是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现同一个 http://ip:port(假设是 http://127.0.0.1:8000)当使用http://127.0.0.1:8001访问时，会抛出错误 已拦截跨源请求：同源策略禁止读取位于 http://127.0.0.1:8001/SendAjax/ 的远程资源。（原因：CORS 头缺少 &apos;Access-Control-Allow-Origin&apos;）。 跨域资源共享（CORS）基本流程 123浏览器将CORS请求分成两类：简单请求（simple request）和非简单请求（not-so-simple request）。浏览器发出CORS简单请求，只需要在头信息之中增加一个Origin字段。浏览器发出CORS非简单请求，会在正式通信之前，增加一次HTTP查询请求，称为&quot;预检&quot;请求（preflight）。浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。 CORS简单请求 12345678910（1) 请求方法是以下三种方法之一：HEADGETPOST（2）HTTP的头信息不超出以下几种字段：AcceptAccept-LanguageContent-LanguageLast-Event-IDContent-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain CORS非简单请求 1凡是不同时满足CORS简单请求条件，就属于非简单请求。 123456789101112两种请求的区别： 简单请求：一次请求 非简单请求：两次请求，在发送数据之前会先发一次请求用于做“预检”，只有“预检”通过后才再发送一次请求用于数据传输。 关于“预检”- 请求方式：OPTIONS- “预检”其实做检查，检查如果通过则允许传输数据，检查不通过则不再发送真正想要发送的消息- 如何“预检” =&gt; 如果复杂请求是PUT等请求，则服务端需要设置允许某请求，否则“预检”不通过 Access-Control-Request-Method =&gt; 如果复杂请求设置了请求头，则服务端需要设置允许某请求头，否则“预检”不通过 Access-Control-Request-Headers Django项目支持CORS ① 在返回的结果中加入允许信息（简单请求） 123456def test(request): import json obj=HttpResponse(json.dumps(&#123;'name':'lqz'&#125;)) # obj['Access-Control-Allow-Origin']='*' obj['Access-Control-Allow-Origin']='http://127.0.0.1:8004' return obj ② 放到中间件处理复杂和简单请求 1234567from django.utils.deprecation import MiddlewareMixinclass CorsMiddleWare(MiddlewareMixin): def process_response(self,request,response): if request.method==\"OPTIONS\": response[\"Access-Control-Allow-Headers\"]=\"Content-Type\" response[\"Access-Control-Allow-Origin\"] = \"http://localhost:8080\" return response 十一、Django中使用Redis方式一①新建utils文件夹，并在该文件夹下建立redis_pool.py 12import redisPOOL = redis.ConnectionPool(host='127.0.0.1', port=6379,password='1234',max_connections=1000) ②视图函数中使用 1234567891011121314import redisfrom django.shortcuts import render,HttpResponsefrom utils.redis_pool import POOLdef index(request): conn = redis.Redis(connection_pool=POOL) conn.hset('kkk','age',18) return HttpResponse('设置成功')def order(request): conn = redis.Redis(connection_pool=POOL) conn.hget('kkk','age') return HttpResponse('获取成功') 方式二①安装django-redis 1pip3 install django-redis ②setting里配置： 123456789101112# redis配置CACHES = &#123; \"default\": &#123; \"BACKEND\": \"django_redis.cache.RedisCache\", \"LOCATION\": \"redis://127.0.0.1:6379\", \"OPTIONS\": &#123; \"CLIENT_CLASS\": \"django_redis.client.DefaultClient\", \"CONNECTION_POOL_KWARGS\": &#123;\"max_connections\": 100&#125; # \"PASSWORD\": \"123\", &#125; &#125;&#125; ③视图函数 123from django_redis import get_redis_connectionconn = get_redis_connection('default')print(conn.hgetall('xxx')) 十二、Django缓存机制1.三个粒度1234567891011121314151617181920211 全站缓存 用中间件： MIDDLEWARE = [ # 'django.middleware.cache.UpdateCacheMiddleware', 'django.middleware.security.SecurityMiddleware', ... # 'django.middleware.cache.FetchFromCacheMiddleware' ] # CACHE_MIDDLEWARE_SECONDS=102 单视图： 用装饰器 from django.views.decorators.cache import cache_page @cache_page(24*60*60) def index(request): pass3 局部页面： &#123;% load cache %&#125; &#123;% cache 5 'test' %&#125; 两个参数：时间，唯一标识 &#123;&#123; ctime &#125;&#125; &#123;% endcache %&#125;","categories":[{"name":"Django","slug":"Django","permalink":"https://www.ice5.vip/categories/Django/"}],"tags":[{"name":"MTV","slug":"MTV","permalink":"https://www.ice5.vip/tags/MTV/"},{"name":"restframework","slug":"restframework","permalink":"https://www.ice5.vip/tags/restframework/"}]}]}